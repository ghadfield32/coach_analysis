{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact/percentile_count_trade_impact.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact/percentile_count_trade_impact.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from nba_api.stats.endpoints import leaguegamefinder, playergamelogs\n",
    "from nba_api.stats.static import teams, players\n",
    "\n",
    "# Constants\n",
    "RELEVANT_STATS = ['PTS', 'AST', 'TOV', 'STL', 'BLK', 'OREB', 'DREB', 'FGM', 'FG3M', 'FGA']\n",
    "PERCENTILE_THRESHOLDS = [1, 2, 3, 4, 5, 10, 25, 50]\n",
    "CACHE_FILE_PATH = '../data/processed/top_percentile_cache.csv'\n",
    "\n",
    "# Helper Functions\n",
    "def load_team_data():\n",
    "    nba_teams = teams.get_teams()\n",
    "    team_df = pd.DataFrame(nba_teams)\n",
    "    return team_df[['id', 'full_name', 'abbreviation']]\n",
    "\n",
    "def load_saved_percentile_counts():\n",
    "    \"\"\"Load saved top percentile counts from a CSV cache file.\"\"\"\n",
    "    if os.path.exists(CACHE_FILE_PATH):\n",
    "        return pd.read_csv(CACHE_FILE_PATH)\n",
    "    else:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no cache file exists\n",
    "\n",
    "def save_percentile_counts(percentile_counts_df):\n",
    "    \"\"\"Save top percentile counts to a CSV cache file.\"\"\"\n",
    "    if not percentile_counts_df.empty:\n",
    "        percentile_counts_df.to_csv(CACHE_FILE_PATH, index=False)\n",
    "        print(f\"Top percentile counts saved to {CACHE_FILE_PATH}\")\n",
    "\n",
    "def get_champion_for_percentile(season, debug=False):\n",
    "    \"\"\"Fetch the champion team for a given NBA season with cache and retries.\"\"\"\n",
    "    from trade_impact.utils.nba_api_utils import get_champion_team_name, normalize_season\n",
    "    season_norm = normalize_season(season)\n",
    "    winner = get_champion_team_name(season_norm, timeout=90, retries=3, use_live=True, debug=debug)\n",
    "    if debug:\n",
    "        print(f\"Champion for season {season_norm}: {winner}\")\n",
    "    return winner\n",
    "\n",
    "\n",
    "def get_champions_for_percentile(start_year, end_year, debug=False):\n",
    "    \"\"\"Fetch champions for each season from start_year to end_year.\"\"\"\n",
    "    champions = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        champ_name = get_champion_for_percentile(season, debug)\n",
    "        if champ_name:\n",
    "            champions.append({'Season': season, 'ChampionTeamName': champ_name})\n",
    "        elif debug:\n",
    "            print(f\"Champion data not available for season {season}\")\n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    return pd.DataFrame(champions)\n",
    "\n",
    "# Updated get_champion_percentiles function to work with cached data\n",
    "def get_champion_percentiles(seasons, debug=False):\n",
    "    \"\"\"Fetch or load champion percentiles for the given seasons.\"\"\"\n",
    "    saved_percentiles_df = load_saved_percentile_counts()\n",
    "    \n",
    "    # Determine which seasons are missing from the cache\n",
    "    existing_seasons = saved_percentiles_df['Season'].unique() if not saved_percentiles_df.empty else []\n",
    "    new_seasons = [season for season in seasons if season not in existing_seasons]\n",
    "    \n",
    "    if new_seasons:\n",
    "        if debug:\n",
    "            print(f\"Fetching new data for seasons: {new_seasons}\")\n",
    "        \n",
    "        # Fetch new data only for missing seasons\n",
    "        champion_info = get_champions_for_percentile(int(new_seasons[0].split('-')[0]), int(new_seasons[-1].split('-')[0]), debug)\n",
    "        player_stats, league_percentiles, league_percentiles_ref = fetch_and_process_season_data(new_seasons, debug)\n",
    "\n",
    "        # Calculate champion percentiles for new seasons\n",
    "        champion_percentiles = calculate_champion_percentiles(league_percentiles, champion_info, debug)\n",
    "        new_top_percentile_counts = champion_percentiles.groupby(['TEAM_NAME', 'Season']).apply(\n",
    "            lambda x: count_top_percentiles(x, league_percentiles_ref, x.iloc[0]['TEAM_NAME'], x.iloc[0]['Season'], debug)\n",
    "        ).apply(pd.Series).reset_index()\n",
    "        \n",
    "        # Append new data to saved cache\n",
    "        updated_percentiles_df = pd.concat([saved_percentiles_df, new_top_percentile_counts], ignore_index=True)\n",
    "        \n",
    "        # Save the updated cache\n",
    "        save_percentile_counts(updated_percentiles_df)\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"All requested seasons are already saved: {existing_seasons}\")\n",
    "        updated_percentiles_df = saved_percentiles_df\n",
    "    \n",
    "    # Filter the saved or updated data for the requested seasons\n",
    "    filtered_percentiles_df = updated_percentiles_df[updated_percentiles_df['Season'].isin(seasons)]\n",
    "\n",
    "    # Calculate the average percentiles across the requested seasons\n",
    "    average_top_percentiles_df = calculate_average_top_percentiles(filtered_percentiles_df, debug)\n",
    "    \n",
    "    return average_top_percentiles_df\n",
    "\n",
    "def calculate_champion_percentiles(league_percentiles, champions, debug=False):\n",
    "    \"\"\"Extract percentiles for players in champion teams based on league percentiles.\"\"\"\n",
    "    champion_data = league_percentiles[league_percentiles['TEAM_NAME'].isin(champions['ChampionTeamName'])].copy()\n",
    "    \n",
    "    # Merge with champions to get the Season associated with each champion team\n",
    "    champion_data = pd.merge(champion_data, champions, left_on='TEAM_NAME', right_on='ChampionTeamName')\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Champion Data Percentiles with Season:\")\n",
    "        print(champion_data[['TEAM_NAME', 'Season', 'PLAYER_NAME']].head())\n",
    "    \n",
    "    return champion_data\n",
    "\n",
    "def fetch_and_process_season_data(seasons, debug=False):\n",
    "    \"\"\"Fetch player data and process it to calculate stats and percentiles.\"\"\"\n",
    "    all_player_data = fetch_all_player_data(seasons, debug)\n",
    "    \n",
    "    # Calculate player-level stats\n",
    "    player_stats = calculate_player_stats(all_player_data, debug)\n",
    "    \n",
    "    # Calculate percentiles for all players in the league\n",
    "    league_percentiles, league_percentiles_ref = calculate_player_percentiles(player_stats, debug)\n",
    "    \n",
    "    return player_stats, league_percentiles, league_percentiles_ref\n",
    "\n",
    "def fetch_all_player_data(seasons, debug=False):\n",
    "    \"\"\"Fetch player game logs data for all players across multiple seasons with retries/cache.\"\"\"\n",
    "    from trade_impact.utils.nba_api_utils import get_playergamelogs_df, normalize_season\n",
    "    all_data = pd.DataFrame()\n",
    "    for season in seasons:\n",
    "        season_norm = normalize_season(season)\n",
    "        try:\n",
    "            logs = get_playergamelogs_df(season_norm, timeout=90, retries=3, use_live=True, debug=debug)\n",
    "            all_data = pd.concat([all_data, logs], ignore_index=True)\n",
    "            if debug:\n",
    "                print(f\"Fetched {len(logs)} player logs for the league in season {season_norm}\")\n",
    "            # gentle pacing to avoid rate limiting\n",
    "            time.sleep(0.5)\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"Error fetching player data for season {season_norm}: {e}\")\n",
    "            # do not fill; continue so we can see exactly which seasons failed\n",
    "    if debug:\n",
    "        print(f\"Total logs fetched across requested seasons: {len(all_data)}\")\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def calculate_player_stats(player_data, debug=False):\n",
    "    \"\"\"Calculate average player statistics from game logs.\"\"\"\n",
    "    # Calculate stats per game for players\n",
    "    player_stats = player_data.groupby(['SEASON', 'TEAM_NAME', 'PLAYER_NAME'])[RELEVANT_STATS].mean().reset_index()\n",
    "    \n",
    "    # Rename columns to include '_per_game'\n",
    "    for stat in RELEVANT_STATS:\n",
    "        player_stats.rename(columns={stat: f'{stat}_per_game'}, inplace=True)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Sample player stats (entire league):\")\n",
    "        print(player_stats.head())  # Show head of the player stats\n",
    "    return player_stats\n",
    "\n",
    "def calculate_player_percentiles(stats_df, debug=False):\n",
    "    \"\"\"Calculate percentile ranks for each stat in the DataFrame by season.\"\"\"\n",
    "    percentiles = {}\n",
    "\n",
    "    for col in RELEVANT_STATS:\n",
    "        col_per_game = f'{col}_per_game'\n",
    "        if col_per_game in stats_df.columns:\n",
    "            # Calculate percentiles across the entire dataset\n",
    "            stats_df[f'{col}_percentile'] = stats_df[col_per_game].rank(pct=True, method='min')\n",
    "            # Ensure no NaN values before calculating percentiles\n",
    "            if not stats_df[col_per_game].isna().any():\n",
    "                percentiles[col] = np.percentile(stats_df[col_per_game], [100 - t for t in PERCENTILE_THRESHOLDS])\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"NaN values found in {col_per_game} column.\")\n",
    "            if debug:\n",
    "                print(f\"Calculated percentiles for {col_per_game}:\")\n",
    "                print(stats_df[['TEAM_NAME', 'PLAYER_NAME', col_per_game, f'{col}_percentile']].head())\n",
    "    return stats_df, percentiles\n",
    "\n",
    "def count_top_percentiles(player_percentiles, percentiles, team_name, season, debug=False):\n",
    "    \"\"\"Count how many players in a specific team fall within top percentiles, filtered by season.\"\"\"\n",
    "    top_counts = {f'{stat}_Top_{threshold}_count': 0 for stat in RELEVANT_STATS for threshold in PERCENTILE_THRESHOLDS}\n",
    "    \n",
    "    # Filter the data by team and season\n",
    "    team_data = player_percentiles[(player_percentiles['TEAM_NAME'] == team_name) & (player_percentiles['SEASON'] == season)]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\n{team_name} player percentiles data for season {season}:\\n{team_data[['PLAYER_NAME', 'FG3M_per_game', 'FG3M_percentile']]}\")\n",
    "    \n",
    "    for col in RELEVANT_STATS:\n",
    "        col_per_game = f'{col}_per_game'\n",
    "        if col in percentiles:  # Ensure we have valid percentiles calculated\n",
    "            for idx, threshold in enumerate(PERCENTILE_THRESHOLDS):\n",
    "                count_key = f'{col}_Top_{threshold}_count'\n",
    "                top_counts[count_key] = (team_data[col_per_game] >= percentiles[col][idx]).sum()\n",
    "\n",
    "                if debug and col == 'FG3M':\n",
    "                    print(f\"{col} Top {threshold}% Count for season {season}: {top_counts[count_key]}\")\n",
    "                    print(f\"Players in Top {threshold}% for {col} in season {season}: {team_data[team_data[col_per_game] >= percentiles[col][idx]][['PLAYER_NAME', col_per_game, f'{col}_percentile']]}\")\n",
    "\n",
    "    return top_counts\n",
    "\n",
    "# Function to simulate trades and recalculate percentiles\n",
    "def simulate_trade(player_stats, players_from_team_a, players_from_team_b, team_a_name, team_b_name, debug=False):\n",
    "    \"\"\"Simulate a trade by swapping players between two teams.\"\"\"\n",
    "    if debug:\n",
    "        print(\"\\nBefore trade simulation:\")\n",
    "        print(player_stats[(player_stats['PLAYER_NAME'].isin(players_from_team_a + players_from_team_b))][['PLAYER_NAME', 'TEAM_NAME']])\n",
    "    \n",
    "    # Swap players between the two teams\n",
    "    player_stats.loc[player_stats['PLAYER_NAME'].isin(players_from_team_a), 'TEAM_NAME'] = team_b_name\n",
    "    player_stats.loc[player_stats['PLAYER_NAME'].isin(players_from_team_b), 'TEAM_NAME'] = team_a_name\n",
    "    \n",
    "    if debug:\n",
    "        print(\"\\nAfter trade simulation:\")\n",
    "        print(player_stats[(player_stats['PLAYER_NAME'].isin(players_from_team_a + players_from_team_b))][['PLAYER_NAME', 'TEAM_NAME']])\n",
    "    \n",
    "    return player_stats\n",
    "\n",
    "def calculate_average_top_percentiles(top_percentile_counts_df, debug=False):\n",
    "    \"\"\"Calculate the average percentiles for all champion teams, grouped by season.\"\"\"\n",
    "    average_percentiles = {}\n",
    "\n",
    "    for col in RELEVANT_STATS:\n",
    "        for threshold in PERCENTILE_THRESHOLDS:\n",
    "            count_key = f'{col}_Top_{threshold}_count'\n",
    "            avg_key = f'{col}_Avg_Top_{threshold}_percentile'\n",
    "            \n",
    "            # Calculate the mean of counts grouped by 'Season' and then average these means\n",
    "            avg_value = top_percentile_counts_df.groupby('Season')[count_key].mean().mean()\n",
    "            \n",
    "            avg_value = avg_value if pd.notnull(avg_value) else 0\n",
    "            average_percentiles[avg_key] = avg_value\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"{col} Avg Top {threshold}% Count across seasons: {avg_value}\")\n",
    "    \n",
    "    return pd.DataFrame([average_percentiles])\n",
    "\n",
    "def create_comparison_table(before_trade, after_trade, average_percentiles, team_name):\n",
    "    \"\"\"Create a comparison table for a team before and after the trade.\"\"\"\n",
    "    data = {'Team': [team_name] * len(PERCENTILE_THRESHOLDS), 'Percentile': PERCENTILE_THRESHOLDS}\n",
    "    \n",
    "    for stat in RELEVANT_STATS:\n",
    "        before_counts = [before_trade[f'{stat}_Top_{threshold}_count'] for threshold in PERCENTILE_THRESHOLDS]\n",
    "        after_counts = [after_trade[f'{stat}_Top_{threshold}_count'] for threshold in PERCENTILE_THRESHOLDS]\n",
    "        champ_avg = [average_percentiles[f'{stat}_Avg_Top_{threshold}_percentile'][0] for threshold in PERCENTILE_THRESHOLDS]\n",
    "        \n",
    "        data[f'{stat}_Before'] = before_counts\n",
    "        data[f'{stat}_After'] = after_counts\n",
    "        data[f'{stat}_Champ_Avg'] = champ_avg\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.set_index('Percentile', inplace=True)\n",
    "    return df\n",
    "\n",
    "def compare_teams_before_after_trade(season, team_a_name, team_b_name, players_from_team_a, players_from_team_b, debug=False):\n",
    "    # Use cached champion percentile data\n",
    "    player_stats, league_percentiles, league_percentiles_ref = fetch_and_process_season_data([season], debug)\n",
    "    \n",
    "    # Count top percentiles before the trade\n",
    "    team_a_top_percentile_counts = count_top_percentiles(league_percentiles, league_percentiles_ref, team_a_name, season, debug)\n",
    "    team_b_top_percentile_counts = count_top_percentiles(league_percentiles, league_percentiles_ref, team_b_name, season, debug)\n",
    "    \n",
    "    # Simulate the trade\n",
    "    player_stats = simulate_trade(player_stats, players_from_team_a, players_from_team_b, team_a_name, team_b_name, debug)\n",
    "    \n",
    "    # Recalculate percentiles after the trade\n",
    "    league_percentiles_after_trade, _ = calculate_player_percentiles(player_stats, debug)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"\\nAfter trade percentiles calculation:\")\n",
    "        print(league_percentiles_after_trade[['TEAM_NAME', 'PLAYER_NAME', 'FG3M_per_game', 'FG3M_percentile']])\n",
    "    \n",
    "    # Count top percentiles after the trade\n",
    "    team_a_top_percentile_counts_after = count_top_percentiles(league_percentiles_after_trade, league_percentiles_ref, team_a_name, season, debug)\n",
    "    team_b_top_percentile_counts_after = count_top_percentiles(league_percentiles_after_trade, league_percentiles_ref, team_b_name, season, debug)\n",
    "    \n",
    "    return team_a_top_percentile_counts, team_a_top_percentile_counts_after, team_b_top_percentile_counts, team_b_top_percentile_counts_after\n",
    "\n",
    "# Function to generate comparison tables using updated champion percentile data\n",
    "def generate_comparison_tables(season, team_a_name, team_b_name, players_from_team_a, players_from_team_b, average_top_percentiles_df, debug=False):\n",
    "    team_a_top_before, team_a_top_after, team_b_top_before, team_b_top_after = compare_teams_before_after_trade(\n",
    "        season, team_a_name, team_b_name, players_from_team_a, players_from_team_b, debug\n",
    "    )\n",
    "    \n",
    "    # Create comparison tables with champion average percentiles\n",
    "    celtics_comparison_table = create_comparison_table(team_a_top_before, team_a_top_after, average_top_percentiles_df, team_a_name)\n",
    "    warriors_comparison_table = create_comparison_table(team_b_top_before, team_b_top_after, average_top_percentiles_df, team_b_name)\n",
    "    \n",
    "    return celtics_comparison_table, warriors_comparison_table\n",
    "\n",
    "def main(debug=False):\n",
    "    seasons = [\"2019-20\", \"2020-21\", \"2021-22\", \"2022-23\", \"2023-24\"]\n",
    "\n",
    "    # Fetch champion percentiles and calculate averages using cached data\n",
    "    average_top_percentiles_df = get_champion_percentiles(seasons, debug)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"\\nAverage Champion Percentiles:\")\n",
    "        print(average_top_percentiles_df)\n",
    "    \n",
    "    team_a_name = \"Boston Celtics\"\n",
    "    team_b_name = \"Atlanta Hawks\"\n",
    "    team_a_players = [\"Jaylen Brown\"]\n",
    "    team_b_players = [\"Trae Young\"]\n",
    "    \n",
    "    # Generate comparison tables before and after the trade\n",
    "    celtics_comparison_table, warriors_comparison_table = generate_comparison_tables(\n",
    "        seasons[-1], team_a_name, team_b_name, team_a_players, team_b_players, average_top_percentiles_df, debug\n",
    "    )\n",
    "    \n",
    "    # Display tables\n",
    "    print(\"\\nTeam A Comparison Table:\")\n",
    "    print(celtics_comparison_table)\n",
    "    \n",
    "    print(\"\\nTeam B Comparison Table:\")\n",
    "    print(warriors_comparison_table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculations\n",
    "\n",
    "final comparison: \n",
    "pre trade games / post trade games / no trade games / pre trade metric / post trade metric / no trade metric / champion metic / pre trade percentile / post trade percentile / no trade percentile / champion percentile \n",
    "\n",
    "\n",
    "1. Pre-Trade Scenario:\n",
    "\n",
    "    Definition: This period includes all games played by the teams before the trade date.\n",
    "    Process:\n",
    "        Data Collection: Filter the season data to include only games that occurred before the specified trade date.\n",
    "        Statistical Calculations: Calculate the total points and the number of games played for each team during this period.\n",
    "        Averaging: Compute the average points per game for each team during the pre-trade period.\n",
    "        Percentile Ranking: Rank the teams based on their average points per game during this period.\n",
    "\n",
    "2. Post-Trade Scenario:\n",
    "\n",
    "    Definition: This period includes all games played by the teams after the trade date.\n",
    "    Process:\n",
    "        Data Collection: Filter the season data to include only games that occurred on or after the specified trade date.\n",
    "        Player Averages: Calculate the average points for traded players based on their performance post-trade.\n",
    "        Simulating Game Logs:\n",
    "            Use the calculated player averages to simulate additional game logs for the post-trade period. This simulates the impact of the traded players joining new teams.\n",
    "            Each game log is based on the new team's schedule after the trade date.\n",
    "        Statistical Calculations:\n",
    "            Combine the simulated game logs with the actual post-trade data.\n",
    "            Calculate the total points and the number of games played by each team.\n",
    "        Averaging: Compute the average points per game for each team during the post-trade period, including the simulated data.\n",
    "        Percentile Ranking: Rank the teams based on their average points per game during this period.\n",
    "\n",
    "3. No-Trade Scenario:\n",
    "\n",
    "    Definition: This period considers the entire season as if no trades occurred.\n",
    "    Process:\n",
    "        Data Collection: Use the full season data, without filtering based on the trade date.\n",
    "        Statistical Calculations: Calculate the total points and the number of games played for each team across the entire season.\n",
    "        Averaging: Compute the average points per game for each team for the full season.\n",
    "        Percentile Ranking: Rank the teams based on their average points per game for the entire season.\n",
    "\n",
    "4. Final Comparison:\n",
    "\n",
    "    Data Aggregation: Collect and organize the results from the pre-trade, post-trade, and no-trade scenarios for each team involved in the trade.\n",
    "    Metrics Compared:\n",
    "        Total Points: Sum of points scored during the respective period.\n",
    "        Games Played: Number of games played during the respective period.\n",
    "        Average Points per Game: Total points divided by the number of games played.\n",
    "        Percentile Ranking: How each team's average points per game rank within the league during that period.\n",
    "        Champion Metric: The average points per game of the championship team in that season, used as a benchmark for comparison.\n",
    "\n",
    "5. Documentation:\n",
    "\n",
    "    The rules and processes described above should be documented thoroughly to ensure clarity and reproducibility. This includes the rationale behind each step, the handling of edge cases (e.g., missing data, incomplete records), and any assumptions made during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact/overall_team_trade_impact.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact/overall_team_trade_impact.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nba_api.stats.endpoints import playergamelogs, leaguegamefinder\n",
    "from nba_api.stats.static import players, teams\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Set the cache directory and file path\n",
    "CACHE_DIR = \"../data/processed/\"\n",
    "CACHE_FILE = os.path.join(CACHE_DIR, \"champion_stats_cache.pkl\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    os.makedirs(CACHE_DIR)\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Load the cached champion stats if available.\"\"\"\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        with open(CACHE_FILE, 'rb') as f:\n",
    "            cache = pickle.load(f)\n",
    "        return cache\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    \"\"\"Save the champion stats to cache.\"\"\"\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(cache, f)\n",
    "\n",
    "def get_champion(season, debug=False):\n",
    "    \"\"\"Fetch the champion team for a given NBA season (cached + retried).\"\"\"\n",
    "    from trade_impact.utils.nba_api_utils import get_champion_team_name, normalize_season\n",
    "    season_norm = normalize_season(season)\n",
    "    winner = get_champion_team_name(season_norm, timeout=90, retries=3, use_live=True, debug=debug)\n",
    "    if debug:\n",
    "        print(f\"Champion for season {season_norm}: {winner}\")\n",
    "    return winner\n",
    "\n",
    "\n",
    "def get_champion_team_stats(seasons, relevant_stats, debug=False):\n",
    "    \"\"\"Fetch and process champion team stats for the selected seasons, using caching.\"\"\"\n",
    "    # Load the cache\n",
    "    cache = load_cache()\n",
    "\n",
    "    all_team_stats = pd.DataFrame()\n",
    "\n",
    "    # List of seasons that need to be fetched (not in cache)\n",
    "    missing_seasons = [season for season in seasons if season not in cache]\n",
    "\n",
    "    if missing_seasons:\n",
    "        if debug:\n",
    "            print(f\"Fetching data for missing seasons: {missing_seasons}\")\n",
    "        \n",
    "        # Fetch data for missing seasons\n",
    "        for season in missing_seasons:\n",
    "            season_data = fetch_season_data_by_year(season, debug)\n",
    "            if season_data is None:\n",
    "                continue  # Skip if no data\n",
    "\n",
    "            team_stats = calculate_team_stats(season_data, 'No-trade', relevant_stats, debug)\n",
    "            team_stats = calculate_percentiles(team_stats, relevant_stats, debug)\n",
    "            \n",
    "            # Identify the champion team\n",
    "            champ_name = get_champion(season, debug)\n",
    "            if champ_name:\n",
    "                champ_stats = team_stats[team_stats['TEAM_NAME'] == champ_name]\n",
    "                cache[season] = champ_stats  # Store the stats in the cache\n",
    "\n",
    "        # Save the updated cache\n",
    "        save_cache(cache)\n",
    "\n",
    "    # Collect data from the cache for the requested seasons\n",
    "    for season in seasons:\n",
    "        if season in cache:\n",
    "            all_team_stats = pd.concat([all_team_stats, cache[season]])\n",
    "\n",
    "    # Calculate average champion stats\n",
    "    if not all_team_stats.empty:\n",
    "        numeric_cols = all_team_stats.select_dtypes(include=[np.number]).columns\n",
    "        average_champion = all_team_stats[numeric_cols].mean().to_frame().T\n",
    "        average_champion['TEAM_NAME'] = 'Average Champion'\n",
    "        average_champion['SEASON'] = 'Multiple Seasons'\n",
    "        all_team_stats = pd.concat([all_team_stats, average_champion])\n",
    "\n",
    "    return all_team_stats\n",
    "\n",
    "\n",
    "def fetch_player_id_by_name(player_name, debug=False):\n",
    "    try:\n",
    "        player = players.find_players_by_full_name(player_name)[0]\n",
    "        if debug:\n",
    "            print(f\"Fetched ID for player {player_name}: {player['id']}\")\n",
    "        return player['id']\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error fetching ID for player {player_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_season_data_by_year(year, debug=False):\n",
    "    \"\"\"Fetch league-wide player game logs for a given year or season string using retries/cache.\"\"\"\n",
    "    from trade_impact.utils.nba_api_utils import get_playergamelogs_df, normalize_season\n",
    "    season_norm = normalize_season(year)\n",
    "    if debug:\n",
    "        print(f\"Fetching data for season: {season_norm}\")\n",
    "    try:\n",
    "        player_logs = get_playergamelogs_df(season_norm, timeout=90, retries=3, use_live=True, debug=debug)\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error fetching data for season {season_norm}: {e}\")\n",
    "        return None\n",
    "    player_logs['SEASON'] = season_norm\n",
    "    player_logs['GAME_DATE'] = pd.to_datetime(player_logs['GAME_DATE'])\n",
    "    if debug:\n",
    "        print(f\"Fetched season data with {len(player_logs)} records.\")\n",
    "    return player_logs\n",
    "\n",
    "\n",
    "\n",
    "def calculate_team_stats(player_data, period, relevant_stats, debug=False):\n",
    "    if player_data.empty:\n",
    "        if debug:\n",
    "            print(f\"No data available for {period}. Returning 'N/A' values.\")\n",
    "        return pd.DataFrame({\"SEASON\": [\"N/A\"], \"TEAM_NAME\": [\"N/A\"], \"GAMES_PLAYED\": [\"N/A\"], **{f'{stat}_per_game': [\"N/A\"] for stat in relevant_stats}})\n",
    "\n",
    "    missing_stats = [stat for stat in relevant_stats if stat not in player_data.columns]\n",
    "    if missing_stats:\n",
    "        raise KeyError(f\"Missing columns in player_data: {missing_stats}\")\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Calculating {period} team-level statistics.\")\n",
    "    \n",
    "    valid_player_data = player_data.dropna(subset=relevant_stats)\n",
    "    \n",
    "    if valid_player_data.empty:\n",
    "        if debug:\n",
    "            print(f\"No valid data after dropping NA for {period}. Returning 'N/A' values.\")\n",
    "        return pd.DataFrame({\"SEASON\": [\"N/A\"], \"TEAM_NAME\": [\"N/A\"], \"GAMES_PLAYED\": [\"N/A\"], **{f'{stat}_per_game': [\"N/A\"] for stat in relevant_stats}})\n",
    "    \n",
    "    team_stats = (\n",
    "        valid_player_data.groupby(['SEASON', 'TEAM_NAME'])[relevant_stats]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    games_played = valid_player_data.groupby(['SEASON', 'TEAM_NAME'])['GAME_ID'].nunique().reset_index(name='GAMES_PLAYED')\n",
    "    \n",
    "    team_stats = pd.merge(team_stats, games_played, on=['SEASON', 'TEAM_NAME'])\n",
    "    for stat in relevant_stats:\n",
    "        team_stats[f'{stat}_per_game'] = team_stats[stat] / team_stats['GAMES_PLAYED']\n",
    "    \n",
    "    team_stats['PERIOD'] = period\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"{period} team-level statistics:\")\n",
    "        display_cols = ['SEASON', 'TEAM_NAME', 'GAMES_PLAYED'] + [f'{stat}_per_game' for stat in relevant_stats]\n",
    "        print(team_stats[display_cols].head(), \"\\n\")\n",
    "    \n",
    "    return team_stats\n",
    "\n",
    "\n",
    "def calculate_percentiles(stats_df, relevant_stats, debug=False):\n",
    "    if debug:\n",
    "        print(\"Calculating percentiles for each team and season.\\n\")\n",
    "    \n",
    "    for season in stats_df['SEASON'].unique():\n",
    "        season_data = stats_df[stats_df['SEASON'] == season]\n",
    "        for stat in relevant_stats:\n",
    "            stat_per_game = f'{stat}_per_game'\n",
    "            if stat_per_game in season_data.columns:\n",
    "                percentile_col = f'{stat}_percentile'\n",
    "                stats_df.loc[stats_df['SEASON'] == season, percentile_col] = season_data[stat_per_game].rank(pct=True)\n",
    "                if debug:\n",
    "                    print(f\"Calculated percentiles for {stat} in season {season}:\")\n",
    "                    print(stats_df.loc[stats_df['SEASON'] == season, [stat_per_game, percentile_col]].head(), \"\\n\")\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "\n",
    "def calculate_player_averages(post_trade_data, traded_players, relevant_stats, debug=False):\n",
    "    player_averages = {}\n",
    "    for player_name, new_team_name in traded_players.items():\n",
    "        player_id = fetch_player_id_by_name(player_name, debug)\n",
    "        if player_id is None:\n",
    "            if debug:\n",
    "                print(f\"Skipping player {player_name} due to missing ID.\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate average stats for the player post-trade\n",
    "        player_data = post_trade_data[post_trade_data['PLAYER_ID'] == player_id]\n",
    "        if player_data.empty:\n",
    "            if debug:\n",
    "                print(f\"No post-trade data found for player {player_name}.\")\n",
    "            continue\n",
    "        \n",
    "        avg_stats = player_data[relevant_stats].mean()\n",
    "        player_averages[player_id] = avg_stats\n",
    "        if debug:\n",
    "            print(f\"Averages for {player_name} after trade: {avg_stats.to_dict()}\")\n",
    "    \n",
    "    return player_averages\n",
    "\n",
    "def simulate_game_logs(post_trade_data, player_averages, traded_players, no_trade_data, trade_date, relevant_stats, debug=False):\n",
    "    simulated_logs_list = []  # Use a list to collect simulated logs\n",
    "    \n",
    "    for player_name, new_team_name in traded_players.items():\n",
    "        player_id = fetch_player_id_by_name(player_name, debug)\n",
    "        if player_id is None or player_id not in player_averages:\n",
    "            if debug:\n",
    "                print(f\"Skipping simulation for player {player_name}.\")\n",
    "            continue\n",
    "        \n",
    "        # Remove original player's logs from the post-trade dataset\n",
    "        post_trade_data = post_trade_data[post_trade_data['PLAYER_ID'] != player_id]\n",
    "        \n",
    "        # Get the team's unique schedule post-trade (one entry per game)\n",
    "        team_schedule = no_trade_data[\n",
    "            (no_trade_data['TEAM_NAME'] == new_team_name) & \n",
    "            (no_trade_data['GAME_DATE'] >= trade_date)\n",
    "        ].drop_duplicates(subset=['GAME_ID', 'TEAM_NAME'])\n",
    "        \n",
    "        if team_schedule.empty:\n",
    "            if debug:\n",
    "                print(f\"No games found for team {new_team_name} after trade date {trade_date}.\")\n",
    "            continue\n",
    "        \n",
    "        # Create simulated logs based on the player's average stats\n",
    "        for _, game in team_schedule.iterrows():\n",
    "            simulated_log = {\n",
    "                'SEASON': game['SEASON'],\n",
    "                'PLAYER_ID': player_id,\n",
    "                'PLAYER_NAME': player_name,\n",
    "                'TEAM_ID': game['TEAM_ID'],\n",
    "                'TEAM_ABBREVIATION': game['TEAM_ABBREVIATION'],\n",
    "                'TEAM_NAME': new_team_name,\n",
    "                'GAME_ID': game['GAME_ID'],\n",
    "                'GAME_DATE': game['GAME_DATE'],\n",
    "                'MATCHUP': game['MATCHUP'],\n",
    "                **{stat: player_averages[player_id][stat] for stat in relevant_stats}\n",
    "            }\n",
    "            simulated_logs_list.append(simulated_log)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Simulated {len(team_schedule)} logs for {player_name} with {new_team_name}.\\n\")\n",
    "    \n",
    "    # Combine the simulated logs with the original post-trade data\n",
    "    if simulated_logs_list:\n",
    "        simulated_logs = pd.DataFrame(simulated_logs_list)\n",
    "        if debug:\n",
    "            print(f\"Total simulated logs created: {len(simulated_logs)}\")\n",
    "            print(simulated_logs.head(), \"\\n\")\n",
    "        \n",
    "        post_trade_data = pd.concat([post_trade_data, simulated_logs], ignore_index=True)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Post-trade data now has {len(post_trade_data)} records after simulation.\\n\")\n",
    "    \n",
    "    return post_trade_data\n",
    "\n",
    "\n",
    "\n",
    "def trade_impact_analysis(start_season, end_season, trade_date, traded_players, team_a_name, team_b_name, champion_seasons, relevant_stats, debug=False):\n",
    "    player_data = pd.DataFrame()\n",
    "\n",
    "    # Fetch full season data\n",
    "    start_year = int(start_season.split('-')[0])\n",
    "    end_year = int(end_season.split('-')[0])\n",
    "    for season in range(start_year, end_year + 1):\n",
    "        season_str = f\"{season}-{str(season + 1)[-2:]}\"\n",
    "        data = fetch_season_data_by_year(season_str, debug)\n",
    "        if data is not None:\n",
    "            player_data = pd.concat([player_data, data], ignore_index=True)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"\\nTotal player data records: {len(player_data)}\")\n",
    "        print(f\"Sample data:\\n{player_data.head()}\\n\")\n",
    "    \n",
    "    # Convert trade date to datetime\n",
    "    trade_date = pd.to_datetime(trade_date)\n",
    "    trade_month = trade_date.month\n",
    "    \n",
    "    # NBA season typically runs from October (month 10) to June (month 6)\n",
    "    in_season_trade = trade_month in [10, 11, 12, 1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    # Determine if the trade is during the season or offseason\n",
    "    if not in_season_trade:\n",
    "        if debug:\n",
    "            print(\"Trade date is in the offseason. Considering the full season for analysis.\")\n",
    "        pre_trade_data = pd.DataFrame()  # No pre-trade data since it's offseason\n",
    "        post_trade_data = player_data.copy()  # Consider the full season as post-trade\n",
    "    else:\n",
    "        # Step 1: Create pre-trade and post-trade datasets\n",
    "        pre_trade_data = player_data[player_data['GAME_DATE'] < trade_date].copy()\n",
    "        post_trade_data = player_data[player_data['GAME_DATE'] >= trade_date].copy()\n",
    "\n",
    "        if debug:\n",
    "            pre_trade_points = pre_trade_data['PTS'].sum()\n",
    "            pre_trade_games = pre_trade_data['GAME_ID'].nunique()\n",
    "            print(\"Pre-trade Dataset:\")\n",
    "            print(f\"Total Points: {pre_trade_points}\")\n",
    "            print(f\"Total Games Played: {pre_trade_games}\")\n",
    "        \n",
    "            post_trade_points = post_trade_data['PTS'].sum()\n",
    "            post_trade_games = post_trade_data['GAME_ID'].nunique()\n",
    "            print(\"Post-trade Dataset:\")\n",
    "            print(f\"Total Points: {post_trade_points}\")\n",
    "            print(f\"Total Games Played: {post_trade_games}\\n\")\n",
    "    \n",
    "    if pre_trade_data.empty and in_season_trade:\n",
    "        print(\"No data available before the trade date.\")\n",
    "        pre_trade_stats = pd.DataFrame({\"TEAM_NAME\": [team_a_name, team_b_name], \"GAMES_PLAYED\": [\"N/A\", \"N/A\"], **{f\"{stat}_per_game\": [\"N/A\", \"N/A\"] for stat in relevant_stats}})\n",
    "    else:\n",
    "        pre_trade_stats = calculate_team_stats(pre_trade_data, 'Pre-trade', relevant_stats, debug)\n",
    "        pre_trade_stats = calculate_percentiles(pre_trade_stats, relevant_stats, debug)\n",
    "\n",
    "    # Get champion data for the selected seasons\n",
    "    champion_team_data = get_champion_team_stats(champion_seasons, relevant_stats, debug)\n",
    "    \n",
    "    # Step 2: Calculate and simulate player averages post-trade\n",
    "    for player_name, new_team_name in traded_players.items():\n",
    "        player_averages = calculate_player_averages(post_trade_data, {player_name: new_team_name}, relevant_stats, debug)\n",
    "        post_trade_data = simulate_game_logs(post_trade_data, player_averages, {player_name: new_team_name}, player_data, trade_date, relevant_stats, debug)\n",
    "    \n",
    "    # Step 3: Recalculate team statistics after all player simulations\n",
    "    post_trade_stats = calculate_team_stats(post_trade_data, 'Post-trade', relevant_stats, debug)\n",
    "    post_trade_stats = calculate_percentiles(post_trade_stats, relevant_stats, debug)\n",
    "\n",
    "    no_trade_stats = calculate_team_stats(player_data, 'No-trade', relevant_stats, debug)\n",
    "    no_trade_stats = calculate_percentiles(no_trade_stats, relevant_stats, debug)\n",
    "\n",
    "    overall_trade_stats = calculate_team_stats(pd.concat([pre_trade_data, post_trade_data]), 'Overall-trade', relevant_stats, debug)\n",
    "    overall_trade_stats = calculate_percentiles(overall_trade_stats, relevant_stats, debug)\n",
    "    \n",
    "    # Step 4: Final Comparison - Create a separate table for each metric\n",
    "    comparison_tables = {}\n",
    "\n",
    "    for stat in relevant_stats:\n",
    "        comparison_data = []\n",
    "\n",
    "        for team in [team_a_name, team_b_name]:\n",
    "            pre_trade = pre_trade_stats[pre_trade_stats['TEAM_NAME'] == team]\n",
    "            post_trade = post_trade_stats[post_trade_stats['TEAM_NAME'] == team]\n",
    "            no_trade = no_trade_stats[no_trade_stats['TEAM_NAME'] == team]\n",
    "            overall_trade = overall_trade_stats[overall_trade_stats['TEAM_NAME'] == team]\n",
    "            \n",
    "            if pre_trade.empty:\n",
    "                pre_trade = pd.DataFrame({\"GAMES_PLAYED\": [\"N/A\"], f'{stat}_per_game': [\"N/A\"], f'{stat}_percentile': [\"N/A\"]})\n",
    "            if post_trade.empty:\n",
    "                post_trade = pd.DataFrame({\"GAMES_PLAYED\": [\"N/A\"], f'{stat}_per_game': [\"N/A\"], f'{stat}_percentile': [\"N/A\"]})\n",
    "            if no_trade.empty:\n",
    "                no_trade = pd.DataFrame({\"GAMES_PLAYED\": [\"N/A\"], f'{stat}_per_game': [\"N/A\"], f'{stat}_percentile': [\"N/A\"]})\n",
    "            if overall_trade.empty:\n",
    "                overall_trade = pd.DataFrame({\"GAMES_PLAYED\": [\"N/A\"], f'{stat}_per_game': [\"N/A\"], f'{stat}_percentile': [\"N/A\"]})\n",
    "\n",
    "            # Build the comparison data\n",
    "            comparison_entry = {\n",
    "                'Team': team,\n",
    "                'Pre-trade Metric': pre_trade[f'{stat}_per_game'].values[0],\n",
    "                'Post-trade Metric': post_trade[f'{stat}_per_game'].values[0],\n",
    "                'Overall-trade Metric': overall_trade[f'{stat}_per_game'].values[0],\n",
    "                'No-trade Metric': no_trade[f'{stat}_per_game'].values[0],\n",
    "                'Champion Metric': champion_team_data[champion_team_data['TEAM_NAME'] == 'Average Champion'][f'{stat}_per_game'].max(),\n",
    "                'Pre-trade Percentile': pre_trade[f'{stat}_percentile'].values[0],\n",
    "                'Post-trade Percentile': post_trade[f'{stat}_percentile'].values[0],\n",
    "                'Overall-trade Percentile': overall_trade[f'{stat}_percentile'].values[0],\n",
    "                'No-trade Percentile': no_trade[f'{stat}_percentile'].values[0],\n",
    "                'Champion Percentile': champion_team_data[champion_team_data['TEAM_NAME'] == 'Average Champion'][f'{stat}_percentile'].max(),\n",
    "            }\n",
    "            \n",
    "            # Optionally include games and totals if debug is true\n",
    "            if debug:\n",
    "                comparison_entry.update({\n",
    "                    'Pre-trade Games': pre_trade['GAMES_PLAYED'].values[0],\n",
    "                    'Post-trade Games': post_trade['GAMES_PLAYED'].values[0],\n",
    "                    'Overall-trade Games': overall_trade['GAMES_PLAYED'].values[0],\n",
    "                    'No-trade Games': no_trade['GAMES_PLAYED'].values[0],\n",
    "                    'Pre-trade Total': pre_trade[stat].sum() if stat in pre_trade.columns else \"N/A\",\n",
    "                    'Post-trade Total': post_trade[stat].sum() if stat in post_trade.columns else \"N/A\",\n",
    "                    'Overall-trade Total': overall_trade[stat].sum() if stat in overall_trade.columns else \"N/A\",\n",
    "                    'No-trade Total': no_trade[stat].sum() if stat in no_trade.columns else \"N/A\",\n",
    "                })\n",
    "\n",
    "            comparison_data.append(comparison_entry)\n",
    "        \n",
    "        comparison_tables[stat] = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Comparison Table for {stat}:\")\n",
    "            print(comparison_tables[stat], \"\\n\")\n",
    "    \n",
    "    return comparison_tables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(debug=True):\n",
    "    start_season = \"2023-24\"\n",
    "    end_season = \"2023-24\"\n",
    "    trade_date = '2023-09-20'  # Adjusted trade date to be within the season\n",
    "    \n",
    "    # Team A and Team B selection\n",
    "    team_a_name = \"Dallas Mavericks\"\n",
    "    team_b_name = \"Charlotte Hornets\"\n",
    "    \n",
    "    # Fetch players for each team\n",
    "    players_from_team_a = get_players_for_team(team_a_name, start_season)\n",
    "    players_from_team_b = get_players_for_team(team_b_name, start_season)\n",
    "    \n",
    "    # Player selection - ensure these are split into lists\n",
    "    selected_players_team_a = [\"Grant Williams\", \"Seth Curry\"]  # List of players from Dallas Mavericks\n",
    "    selected_players_team_b = [\"P.J. Washington\"]  # List of players from Charlotte Hornets\n",
    "    \n",
    "    # Combine selected players into the traded_players dictionary\n",
    "    traded_players = {player: team_b_name for player in selected_players_team_a}\n",
    "    traded_players.update({player: team_a_name for player in selected_players_team_b})\n",
    "    \n",
    "    # Specify the seasons to consider for champions\n",
    "    champion_seasons = [\"2014-15\", \"2015-16\", \"2016-17\", \"2017-18\", \"2018-19\", \"2019-20\", \"2021-22\", \"2022-23\", \"2023-24\"]\n",
    "    \n",
    "    # Adjust the relevant stats to analyze\n",
    "    relevant_stats = ['PTS']  # This can be modified\n",
    "    \n",
    "    # Perform the trade impact analysis\n",
    "    comparison_tables = trade_impact_analysis(\n",
    "        start_season, end_season, trade_date, traded_players, team_a_name, team_b_name, champion_seasons, relevant_stats, debug=debug\n",
    "    )\n",
    "    \n",
    "    # Print all comparison tables\n",
    "    for stat, table in comparison_tables.items():\n",
    "        print(f\"Comparison Table for {stat}:\")\n",
    "        print(table)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(debug=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hoopsrumors.com/2023/09/salary-matching-rules-for-trades-during-2023-24-season.html\n",
    "\n",
    "for trade rules\n",
    "\n",
    "\n",
    "FIRST_TAX_APRON = 172_346_000\n",
    "\n",
    "def check_salary_matching_rules(outgoing_salary, incoming_salary, team_salary_before_trade):\n",
    "    if team_salary_before_trade < FIRST_TAX_APRON:\n",
    "        if outgoing_salary <= 7_500_000:\n",
    "            max_incoming_salary = 2 * outgoing_salary + 250_000\n",
    "        elif outgoing_salary <= 29_000_000:\n",
    "            max_incoming_salary = outgoing_salary + 7_500_000\n",
    "        else:\n",
    "            max_incoming_salary = 1.25 * outgoing_salary + 250_000\n",
    "    else:\n",
    "        max_incoming_salary = 1.10 * outgoing_salary\n",
    "\n",
    "    return incoming_salary <= max_incoming_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact/nba_rules_trade_impact.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact/nba_rules_trade_impact.py\n",
    "\n",
    "# https://www.hoopsrumors.com/2023/09/salary-matching-rules-for-trades-during-2023-24-season.html\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Constants for the 2023/24 season\n",
    "FIRST_TAX_APRON_2023 = 172_346_000\n",
    "SALARY_CAP_2023 = 136_021_000\n",
    "\n",
    "# Percentages based on rules\n",
    "UP_TO_7500K_MULTIPLIER = 2.0\n",
    "UP_TO_7500K_BONUS = 250_000 / SALARY_CAP_2023\n",
    "BETWEEN_7501K_AND_29M_BONUS = 7_500_000 / SALARY_CAP_2023\n",
    "ABOVE_29M_MULTIPLIER = 1.25\n",
    "ABOVE_29M_BONUS = 250_000 / SALARY_CAP_2023\n",
    "ABOVE_FIRST_APRON_MULTIPLIER = 1.10\n",
    "\n",
    "def check_salary_matching_rules(outgoing_salary, incoming_salary, team_salary_before_trade, salary_cap, first_tax_apron, debug=False):\n",
    "    debug_info = []\n",
    "    if debug:\n",
    "        debug_info.append(f\"Debug: Checking salary matching rules:\")\n",
    "        debug_info.append(f\"  Outgoing Salary: ${outgoing_salary:,.2f}\")\n",
    "        debug_info.append(f\"  Incoming Salary: ${incoming_salary:,.2f}\")\n",
    "        debug_info.append(f\"  Team Salary Before Trade: ${team_salary_before_trade:,.2f}\")\n",
    "        debug_info.append(f\"  Salary Cap: ${salary_cap:,.2f}\")\n",
    "        debug_info.append(f\"  First Tax Apron: ${first_tax_apron:,.2f}\")\n",
    "\n",
    "    if team_salary_before_trade < first_tax_apron:\n",
    "        if outgoing_salary <= 7_500_000:\n",
    "            max_incoming_salary = (UP_TO_7500K_MULTIPLIER * outgoing_salary + UP_TO_7500K_BONUS * salary_cap)\n",
    "            rule = \"200% of outgoing + 250,000 (up to 7,500,000)\"\n",
    "            percentage_limit = (UP_TO_7500K_MULTIPLIER * outgoing_salary + UP_TO_7500K_BONUS * salary_cap) / outgoing_salary\n",
    "        elif outgoing_salary <= 29_000_000:\n",
    "            max_incoming_salary = outgoing_salary + BETWEEN_7501K_AND_29M_BONUS * salary_cap\n",
    "            rule = \"outgoing + 7,500,000 (7,500,001 to 29,000,000)\"\n",
    "            percentage_limit = (outgoing_salary + BETWEEN_7501K_AND_29M_BONUS * salary_cap) / outgoing_salary\n",
    "        else:\n",
    "            max_incoming_salary = (ABOVE_29M_MULTIPLIER * outgoing_salary + ABOVE_29M_BONUS * salary_cap)\n",
    "            rule = \"125% of outgoing + 250,000 (above 29,000,000)\"\n",
    "            percentage_limit = (ABOVE_29M_MULTIPLIER * outgoing_salary + ABOVE_29M_BONUS * salary_cap) / outgoing_salary\n",
    "    else:\n",
    "        max_incoming_salary = ABOVE_FIRST_APRON_MULTIPLIER * outgoing_salary\n",
    "        rule = \"110% of outgoing (above first tax apron)\"\n",
    "        percentage_limit = ABOVE_FIRST_APRON_MULTIPLIER\n",
    "\n",
    "    if debug:\n",
    "        debug_info.append(f\"  Max Incoming Salary Allowed: ${max_incoming_salary:,.2f}\")\n",
    "        debug_info.append(f\"  Rule Applied: {rule}\")\n",
    "        debug_info.append(f\"  Percentage Limit: {percentage_limit:.2f}\")\n",
    "\n",
    "    return incoming_salary <= max_incoming_salary, max_incoming_salary, rule, percentage_limit, \"\\n\".join(debug_info)\n",
    "\n",
    "def analyze_trade_scenario(players1, players2, predictions_df, season, debug=False):\n",
    "    debug_info = []\n",
    "\n",
    "    # Convert the season (e.g., 2023-24) to just the first four characters (e.g., 2023)\n",
    "    season_filter = str(season)[:4]\n",
    "\n",
    "    # Ensure the Season column is treated as a string\n",
    "    predictions_df['Season'] = predictions_df['Season'].astype(str)\n",
    "    \n",
    "    # Filter the dataframe for the specified season\n",
    "    season_data = predictions_df[predictions_df['Season'].str.startswith(season_filter)]\n",
    "\n",
    "    # Ensure all players in each list are from the same team\n",
    "    teams1 = season_data[season_data['Player'].isin(players1)]['Team'].unique()\n",
    "    teams2 = season_data[season_data['Player'].isin(players2)]['Team'].unique()\n",
    "\n",
    "    # Check if players are found in the dataset\n",
    "    for player in players1:\n",
    "        if player not in season_data['Player'].values:\n",
    "            return None, f\"Error: Player {player} is not found in the dataset.\"\n",
    "\n",
    "    for player in players2:\n",
    "        if player not in season_data['Player'].values:\n",
    "            return None, f\"Error: Player {player} is not found in the dataset.\"\n",
    "\n",
    "    if len(teams1) != 1:\n",
    "        missing_players = [player for player in players1 if player not in season_data[season_data['Team'].isin(teams1)]['Player'].values]\n",
    "        if missing_players:\n",
    "            return None, f\"Error: Player {', '.join(missing_players)} not found on team {teams1[0]}.\"\n",
    "        else:\n",
    "            return None, \"Error: All players in the first list must be from the same team.\"\n",
    "\n",
    "    if len(teams2) != 1:\n",
    "        missing_players = [player for player in players2 if player not in season_data[season_data['Team'].isin(teams2)]['Player'].values]\n",
    "        if missing_players:\n",
    "            return None, f\"Error: Player {', '.join(missing_players)} not found on team {teams2[0]}.\"\n",
    "        else:\n",
    "            return None, \"Error: All players in the second list must be from the same team.\"\n",
    "\n",
    "    team1 = teams1[0]\n",
    "    team2 = teams2[0]\n",
    "\n",
    "    if team1 == team2:\n",
    "        return None, \"Error: The two teams involved in the trade must be different.\"\n",
    "\n",
    "    # Calculate total salaries for each group of players\n",
    "    outgoing_salary_team1 = season_data[season_data['Player'].isin(players1)]['Salary'].sum()\n",
    "    incoming_salary_team1 = season_data[season_data['Player'].isin(players2)]['Salary'].sum()\n",
    "\n",
    "    outgoing_salary_team2 = season_data[season_data['Player'].isin(players2)]['Salary'].sum()\n",
    "    incoming_salary_team2 = season_data[season_data['Player'].isin(players1)]['Salary'].sum()\n",
    "\n",
    "    # Check salary matching rules for both teams\n",
    "    team1_salary_before_trade = season_data[season_data['Team'] == team1]['Salary'].sum()\n",
    "    team2_salary_before_trade = season_data[season_data['Team'] == team2]['Salary'].sum()\n",
    "\n",
    "    # Determine tax apron status\n",
    "    team1_tax_apron_status = \"Below\" if team1_salary_before_trade < FIRST_TAX_APRON_2023 else \"Above\"\n",
    "    team2_tax_apron_status = \"Below\" if team2_salary_before_trade < FIRST_TAX_APRON_2023 else \"Above\"\n",
    "\n",
    "    trade_works_for_team1, team1_max_incoming_salary, team1_rule, team1_percentage_limit, team1_debug = check_salary_matching_rules(\n",
    "        outgoing_salary_team1, incoming_salary_team1, team1_salary_before_trade, SALARY_CAP_2023, FIRST_TAX_APRON_2023, debug\n",
    "    )\n",
    "    trade_works_for_team2, team2_max_incoming_salary, team2_rule, team2_percentage_limit, team2_debug = check_salary_matching_rules(\n",
    "        outgoing_salary_team2, incoming_salary_team2, team2_salary_before_trade, SALARY_CAP_2023, FIRST_TAX_APRON_2023, debug\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        debug_info.append(team1_debug)\n",
    "        debug_info.append(team2_debug)\n",
    "        debug_info.append(\"\\nDebug: Trade Analysis Results:\")\n",
    "        debug_info.append(f\"Team 1 ({team1}):\")\n",
    "        debug_info.append(f\"  Total Outgoing Salary: ${outgoing_salary_team1:,.2f}\")\n",
    "        debug_info.append(f\"  Max Incoming Salary Allowed: ${team1_max_incoming_salary:,.2f} (Rule: {team1_rule})\")\n",
    "        debug_info.append(f\"  Percentage Limit: {team1_percentage_limit:.2f}\")\n",
    "        debug_info.append(f\"Team 2 ({team2}):\")\n",
    "        debug_info.append(f\"  Total Outgoing Salary: ${outgoing_salary_team2:,.2f}\")\n",
    "        debug_info.append(f\"  Max Incoming Salary Allowed: ${team2_max_incoming_salary:,.2f} (Rule: {team2_rule})\")\n",
    "        debug_info.append(f\"  Percentage Limit: {team2_percentage_limit:.2f}\")\n",
    "\n",
    "    trade_status = True\n",
    "    if not trade_works_for_team1:\n",
    "        debug_info.append(f\"Trade Works for Team 1: No\")\n",
    "        debug_info.append(f\"  Trade fails for Team 1 because incoming salary exceeds max allowed under rule: {team1_rule}\")\n",
    "        debug_info.append(f\"  Team 1 is {team1_tax_apron_status} the First Tax Apron.\")\n",
    "        trade_status = False\n",
    "    else:\n",
    "        debug_info.append(f\"Trade Works for Team 1: Yes\")\n",
    "\n",
    "    if not trade_works_for_team2:\n",
    "        debug_info.append(f\"Trade Works for Team 2: No\")\n",
    "        debug_info.append(f\"  Trade fails for Team 2 because incoming salary exceeds max allowed under rule: {team2_rule}\")\n",
    "        debug_info.append(f\"  Team 2 is {team2_tax_apron_status} the First Tax Apron.\")\n",
    "        trade_status = False\n",
    "    else:\n",
    "        debug_info.append(f\"Trade Works for Team 2: Yes\")\n",
    "\n",
    "    if trade_status:\n",
    "        debug_info.append(\"The trade is valid according to salary matching rules.\")\n",
    "    else:\n",
    "        debug_info.append(\"The trade does not satisfy salary matching rules.\")\n",
    "\n",
    "    return trade_status, \"\\n\".join(debug_info)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the real predictions dataframe\n",
    "    predictions_df = pd.read_csv('../data/processed/predictions_df.csv')\n",
    "\n",
    "    # Specify two lists of players for the trade scenario\n",
    "    players1 = [\"Anthony Davis\", \"LeBron James\"]\n",
    "    players2 = [\"Jayson Tatum\", \"Jaylen Brown\"]\n",
    "\n",
    "    # Analyze the trade scenario for the specified season with debugging enabled\n",
    "    season = \"2023-24\"\n",
    "    print(f\"Analyzing trade for the {season} season:\")\n",
    "    results, debug_output = analyze_trade_scenario(players1, players2, predictions_df, season, debug=True)\n",
    "    print(\"results =\", debug_output)\n",
    "    print(\"results =\", results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact/combined_trade_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact/combined_trade_analysis.py\n",
    "\n",
    "import pandas as pd\n",
    "from trade_impact.percentile_count_trade_impact import get_champion_percentiles, generate_comparison_tables\n",
    "from trade_impact.overall_team_trade_impact import trade_impact_analysis\n",
    "from trade_impact.nba_rules_trade_impact import analyze_trade_scenario\n",
    "from trade_impact.shot_chart.nba_efficiency import calculate_compatibility_between_players\n",
    "from trade_impact.shot_chart.nba_shots import fetch_shots_for_multiple_players\n",
    "\n",
    "def analyze_player_salaries(players, predictions_df):\n",
    "    \"\"\"Analyze if the selected players are overpaid or underpaid based on predicted salaries.\"\"\"\n",
    "    player_salary_analysis = []\n",
    "\n",
    "    for player in players:\n",
    "        player_data = predictions_df[predictions_df['Player'] == player]\n",
    "        if not player_data.empty:\n",
    "            actual_salary = player_data['Salary'].values[0]\n",
    "            salary_cap = player_data['Salary_Cap_Inflated'].values[0]\n",
    "            predicted_salary = player_data['Predicted_Salary'].values[0] * salary_cap\n",
    "            difference = actual_salary - predicted_salary\n",
    "            status = \"Overpaid\" if difference > 0 else \"Underpaid\" if difference < 0 else \"Fairly Paid\"\n",
    "            player_salary_analysis.append({\n",
    "                'Player': player,\n",
    "                'Actual Salary': actual_salary,\n",
    "                'Predicted Salary': predicted_salary,\n",
    "                'Difference': difference,\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(player_salary_analysis)\n",
    "\n",
    "def combined_trade_analysis(team_a_name, team_b_name, selected_players_team_a, selected_players_team_b, \n",
    "                            trade_date, champion_seasons, trade_season, relevant_stats, predictions_df, debug=False):\n",
    "    \"\"\"\n",
    "    Perform a comprehensive analysis of the trade impact on the involved teams.\n",
    "    \"\"\"\n",
    "    # Step 1: Analyze the trade scenario using NBA salary matching rules\n",
    "    trade_valid, trade_analysis_debug = analyze_trade_scenario(\n",
    "        selected_players_team_a, selected_players_team_b, predictions_df=predictions_df, season=trade_season, debug=debug\n",
    "    )\n",
    "\n",
    "    # Step 2: Fetch champion percentiles and calculate averages\n",
    "    average_top_percentiles_df = get_champion_percentiles(champion_seasons, debug)\n",
    "\n",
    "    # Step 3: Generate comparison tables before and after the trade for the trade season\n",
    "    team_a_comparison_table, team_b_comparison_table = generate_comparison_tables(\n",
    "        trade_season, team_a_name, team_b_name, selected_players_team_a, selected_players_team_b, \n",
    "        average_top_percentiles_df, debug\n",
    "    )\n",
    "\n",
    "    # Step 4: Perform the trade impact analysis for the trade season\n",
    "    traded_players = {player: team_b_name for player in selected_players_team_a}\n",
    "    traded_players.update({player: team_a_name for player in selected_players_team_b})\n",
    "\n",
    "    comparison_tables = trade_impact_analysis(\n",
    "        start_season=trade_season, end_season=trade_season, trade_date=trade_date, \n",
    "        traded_players=traded_players, \n",
    "        team_a_name=team_a_name, team_b_name=team_b_name, \n",
    "        champion_seasons=champion_seasons, relevant_stats=relevant_stats, debug=debug\n",
    "    )\n",
    "\n",
    "    # Step 5: Analyze player salaries to determine if they are overpaid or underpaid\n",
    "    all_players = selected_players_team_a + selected_players_team_b\n",
    "    salary_analysis_df = analyze_player_salaries(all_players, predictions_df)\n",
    "\n",
    "    # Step 6: Calculate compatibility between the players being traded based on their shooting areas\n",
    "    player_shots = fetch_shots_for_multiple_players(all_players, season=trade_season, court_areas='all')\n",
    "    compatibility_df = calculate_compatibility_between_players(player_shots)\n",
    "\n",
    "    return {\n",
    "        'average_champion_percentiles': average_top_percentiles_df,\n",
    "        'team_a_comparison_table': team_a_comparison_table,\n",
    "        'team_b_comparison_table': team_b_comparison_table,\n",
    "        'comparison_tables': comparison_tables,\n",
    "        'trade_analysis': trade_analysis_debug,  # Include the trade scenario analysis output\n",
    "        'trade_valid': trade_valid,  # Include the trade validity status\n",
    "        'salary_analysis': salary_analysis_df,  # Include player salary analysis output\n",
    "        'compatibility_analysis': compatibility_df  # Include player compatibility analysis output\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Load the predictions data\n",
    "    predictions_df = pd.read_csv('../data/processed/predictions_df.csv')\n",
    "\n",
    "    # Define parameters for the test\n",
    "    team_a_name = \"Los Angeles Lakers\"\n",
    "    team_b_name = \"Atlanta Hawks\"\n",
    "    selected_players_team_a = [\"LeBron James\", \"Anthony Davis\"]\n",
    "    selected_players_team_b = [\"Dejounte Murray\"]\n",
    "    trade_date = \"2023-09-15\"  # Example trade date\n",
    "    champion_seasons = [\"2020-21\", \"2021-22\", \"2022-23\"]\n",
    "    trade_season = \"2023-24\"\n",
    "    relevant_stats = [\"PTS\", \"AST\", \"REB\", \"STL\", \"BLK\"]\n",
    "    debug = True  # Set to True to see debug information\n",
    "\n",
    "    # Call the combined_trade_analysis function\n",
    "    results = combined_trade_analysis(\n",
    "        team_a_name, team_b_name, selected_players_team_a, selected_players_team_b, \n",
    "        trade_date, champion_seasons, trade_season, relevant_stats, predictions_df, debug\n",
    "    )\n",
    "\n",
    "    # Print the trade scenario analysis result\n",
    "    print(\"Trade Analysis Debug Info:\\n\", results['trade_analysis'])\n",
    "    \n",
    "    # Check if the trade is valid\n",
    "    if results['trade_valid']:\n",
    "        print(\"The trade satisfies NBA salary matching rules.\")\n",
    "    else:\n",
    "        print(\"The trade does NOT satisfy NBA salary matching rules.\")\n",
    "\n",
    "    # Print the other results\n",
    "    print(\"Average Champion Percentiles:\\n\", results['average_champion_percentiles'])\n",
    "    print(f\"{team_a_name} Comparison Table:\\n\", results['team_a_comparison_table'])\n",
    "    print(f\"{team_b_name} Comparison Table:\\n\", results['team_b_comparison_table'])\n",
    "    for stat, table in results['comparison_tables'].items():\n",
    "        print(f\"Comparison Table for {stat}:\\n\", table)\n",
    "    \n",
    "    # Print the salary analysis results\n",
    "    print(\"\\nPlayer Salary Analysis:\")\n",
    "    print(results['salary_analysis'])\n",
    "\n",
    "    # Print the compatibility analysis results\n",
    "    print(\"\\nPlayer Compatibility Analysis:\")\n",
    "    print(results['compatibility_analysis'])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact/utils/nba_api_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact/utils/nba_api_utils.py\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nba_api.stats.static import teams as static_teams\n",
    "from nba_api.stats.endpoints import (\n",
    "    playergamelogs as _playergamelogs,\n",
    "    commonteamroster as _commonteamroster,\n",
    "    leaguegamefinder as _leaguegamefinder,\n",
    ")\n",
    "\n",
    "# ---- optional global HTTP response cache (safe no-op if lib missing) ----\n",
    "try:\n",
    "    from requests_cache import install_cache\n",
    "    from datetime import timedelta\n",
    "    _HTTP_CACHE_PATH = os.path.join(_CACHE_DIR, \"http_cache_sqlite\")\n",
    "    install_cache(cache_name=_HTTP_CACHE_PATH, backend=\"sqlite\", expire_after=timedelta(hours=12))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---- optional Streamlit cache decorators (work outside Streamlit too) ----\n",
    "try:\n",
    "    import streamlit as st\n",
    "    def _st_cache_data(**kw):\n",
    "        return st.cache_data(**kw)\n",
    "except Exception:\n",
    "    def _st_cache_data(**kw):\n",
    "        # no-op decorator outside Streamlit\n",
    "        def deco(fn): return fn\n",
    "        return deco\n",
    "\n",
    "# -------------------------\n",
    "# Paths & simple disk cache\n",
    "# -------------------------\n",
    "_CACHE_DIR = os.path.join(\"..\", \"data\", \"processed\", \"cache_nba_api\")\n",
    "os.makedirs(_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "def _cache_path(key: str) -> str:\n",
    "    safe = key.replace(\"/\", \"_\").replace(\"\\\\\", \"_\").replace(\" \", \"_\")\n",
    "    return os.path.join(_CACHE_DIR, f\"{safe}.csv\")\n",
    "\n",
    "def _load_cache_df(key: str) -> Optional[pd.DataFrame]:\n",
    "    path = _cache_path(key)\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            return pd.read_csv(path)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _save_cache_df(key: str, df: pd.DataFrame) -> None:\n",
    "    if df is None or df.empty:\n",
    "        return\n",
    "    df.to_csv(_cache_path(key), index=False)\n",
    "\n",
    "# -------------------------\n",
    "# Season normalization\n",
    "# -------------------------\n",
    "def normalize_season(season_or_year: str | int) -> str:\n",
    "    \"\"\"\n",
    "    Accepts '2023-24' or 2023 or '2023' and returns '2023-24'.\n",
    "    \"\"\"\n",
    "    if isinstance(season_or_year, int):\n",
    "        y = season_or_year\n",
    "        return f\"{y}-{str(y + 1)[-2:]}\"\n",
    "    s = str(season_or_year)\n",
    "    if \"-\" in s and len(s) >= 7:\n",
    "        return s  # already 'YYYY-YY'\n",
    "    if s.isdigit():\n",
    "        y = int(s)\n",
    "        return f\"{y}-{str(y + 1)[-2:]}\"\n",
    "    raise ValueError(f\"Unrecognized season format: {season_or_year}\")\n",
    "\n",
    "# -------------------------\n",
    "# Retry helper\n",
    "# -------------------------\n",
    "def _with_retries(fn, *, retries=3, base_delay=1.5, jitter=0.75, debug=False):\n",
    "    last_err = None\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            return fn()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if debug:\n",
    "                print(f\"[nba_api_utils] attempt {attempt} failed: {e}\")\n",
    "            if attempt < retries:\n",
    "                delay = base_delay * attempt + random.random() * jitter\n",
    "                time.sleep(delay)\n",
    "    raise last_err\n",
    "\n",
    "# -------------------------\n",
    "# Team lookup\n",
    "# -------------------------\n",
    "def get_team_id_by_full_name(team_full_name: str) -> Optional[int]:\n",
    "    tlist = static_teams.get_teams()\n",
    "    for t in tlist:\n",
    "        if t.get(\"full_name\") == team_full_name:\n",
    "            return int(t[\"id\"])\n",
    "    return None\n",
    "\n",
    "# -------------------------\n",
    "# Light roster fetch (preferred for populating UI)\n",
    "# -------------------------\n",
    "@_st_cache_data(persist=\"disk\", ttl=60*60*12, max_entries=128)\n",
    "def get_commonteamroster_df(team_id: int, season: str | int,\n",
    "                            *, timeout=60, retries=3, use_live=True, debug=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Light roster fetch with CSV cache, Streamlit cache, retries, and cache fallback.\n",
    "    \"\"\"\n",
    "    season_norm = normalize_season(season)\n",
    "    cache_key = f\"commonteamroster_{team_id}_{season_norm}\"\n",
    "    if not use_live:\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    def _call():\n",
    "        df = _commonteamroster.CommonTeamRoster(\n",
    "            team_id=team_id,\n",
    "            season=season_norm,\n",
    "            timeout=timeout,\n",
    "        ).get_data_frames()[0]\n",
    "        return df\n",
    "\n",
    "    try:\n",
    "        df = _with_retries(_call, retries=retries, debug=debug)\n",
    "        _save_cache_df(cache_key, df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"[nba_api_utils] roster live fetch failed for team_id={team_id} season={season_norm}: {e}\")\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if cached is not None:\n",
    "            if debug:\n",
    "                print(f\"[nba_api_utils] Using cached roster for {team_id} {season_norm}\")\n",
    "            return cached\n",
    "        # final: return empty DF with expected columns so caller can degrade gracefully\n",
    "        return pd.DataFrame(columns=[\"PLAYER\", \"TEAM_ID\", \"SEASON\"])\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Heavier logs fetch (only when truly needed)\n",
    "# -------------------------\n",
    "@_st_cache_data(persist=\"disk\", ttl=60*60*12, max_entries=32)\n",
    "def get_playergamelogs_df(season: str | int,\n",
    "                          *, timeout=90, retries=3, use_live=True, debug=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    League-wide player game logs with CSV cache, Streamlit cache, and retries.\n",
    "    \"\"\"\n",
    "    season_norm = normalize_season(season)\n",
    "    cache_key = f\"playergamelogs_league_{season_norm}\"\n",
    "    if not use_live:\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    def _call():\n",
    "        df = _playergamelogs.PlayerGameLogs(\n",
    "            season_nullable=season_norm,\n",
    "            timeout=timeout,\n",
    "        ).get_data_frames()[0]\n",
    "        df[\"SEASON\"] = season_norm\n",
    "        return df\n",
    "\n",
    "    try:\n",
    "        df = _with_retries(_call, retries=retries, debug=debug)\n",
    "        _save_cache_df(cache_key, df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"[nba_api_utils] logs live fetch failed for season={season_norm}: {e}\")\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if cached is not None:\n",
    "            if debug:\n",
    "                print(f\"[nba_api_utils] Using cached logs for {season_norm}\")\n",
    "            return cached\n",
    "        # final: empty DF with expected shape\n",
    "        return pd.DataFrame(columns=[\"SEASON\",\"TEAM_NAME\",\"PLAYER_NAME\",\"GAME_DATE\",\"GAME_ID\"])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Champion helper with cache\n",
    "# -------------------------\n",
    "def get_champion_team_name(season: str | int, *, timeout=90, retries=3, use_live=True, debug=False) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Uses playoff games to identify the winner of the final game.\n",
    "    \"\"\"\n",
    "    season_norm = normalize_season(season)\n",
    "    cache_key = f\"champion_team_{season_norm}\"\n",
    "\n",
    "    if not use_live:\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if isinstance(cached, pd.DataFrame) and not cached.empty and \"TEAM_NAME\" in cached:\n",
    "            return cached[\"TEAM_NAME\"].iloc[0]\n",
    "\n",
    "    def _call():\n",
    "        df = _leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season_norm,\n",
    "            season_type_nullable=\"Playoffs\",\n",
    "            timeout=timeout,\n",
    "        ).get_data_frames()[0]\n",
    "        df[\"GAME_DATE\"] = pd.to_datetime(df[\"GAME_DATE\"])\n",
    "        last_two = df.sort_values(\"GAME_DATE\").iloc[-2:]\n",
    "        winner_row = last_two[last_two[\"WL\"] == \"W\"].iloc[0]\n",
    "        return pd.DataFrame([{\"TEAM_NAME\": winner_row[\"TEAM_NAME\"]}])\n",
    "\n",
    "    try:\n",
    "        winner_df = _with_retries(_call, retries=retries, debug=debug)\n",
    "        _save_cache_df(cache_key, winner_df)\n",
    "        return winner_df[\"TEAM_NAME\"].iloc[0]\n",
    "    except Exception as e:\n",
    "        cached = _load_cache_df(cache_key)\n",
    "        if isinstance(cached, pd.DataFrame) and not cached.empty and \"TEAM_NAME\" in cached:\n",
    "            if debug:\n",
    "                print(f\"[nba_api_utils] Using cached champion for {season_norm} due to error: {e}\")\n",
    "            return cached[\"TEAM_NAME\"].iloc[0]\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/streamlit_app_helpers.py\n",
    "\"\"\"\n",
    "Fast player list accessors for Streamlit app.\n",
    "Replaces heavy gamelog calls with lightweight season index lookups.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from salary_nba_data_pull.data_utils import read_season_player_index\n",
    "from salary_nba_data_pull.fetch_utils import network_env_diagnostics, fetch_season_players\n",
    "\n",
    "\n",
    "def get_players_for_season_fast(season: str,\n",
    "                                *,\n",
    "                                debug: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    UI helper: tiny DataFrame [Player, PlayerID, Team, TeamID] for the season.\n",
    "\n",
    "    Priority:\n",
    "      1) local season index (instant)\n",
    "      2) ONE roster call via nba_api (diagnostics only; Team=None by design)\n",
    "\n",
    "    No filling; returns empty DataFrame if nothing can be fetched.\n",
    "    \"\"\"\n",
    "    from salary_nba_data_pull.data_utils import read_season_player_index\n",
    "    from salary_nba_data_pull.fetch_utils import network_env_diagnostics, fetch_season_players\n",
    "    import pandas as pd\n",
    "\n",
    "    idx = read_season_player_index(season, debug=debug)\n",
    "    if not idx.empty:\n",
    "        out = (idx[[\"Player\",\"PlayerID\",\"Team\",\"TeamID\"]]\n",
    "               .drop_duplicates()\n",
    "               .reset_index(drop=True))\n",
    "        if debug:\n",
    "            print(f\"[players-fast] season={season} source=index rows={len(out)}\")\n",
    "            if \"Team\" in out.columns:\n",
    "                print(f\"[players-fast] Team sample: {out['Team'].dropna().astype(str).unique()[:12]}\")\n",
    "        return out\n",
    "\n",
    "    diag = network_env_diagnostics(timeout_sec=5)\n",
    "    if diag.get(\"nba_stats\") not in (200, 301, 302):\n",
    "        if debug:\n",
    "            print(f\"[players-fast] stats.nba.com not reachable (diag={diag}); returning empty result.\")\n",
    "        return pd.DataFrame(columns=[\"Player\",\"PlayerID\",\"Team\",\"TeamID\"])\n",
    "\n",
    "    roster = fetch_season_players(season, debug=debug)\n",
    "    rows = [{\"Player\": key.upper(),\n",
    "             \"PlayerID\": meta.get(\"player_id\"),\n",
    "             \"Team\": None,\n",
    "             \"TeamID\": meta.get(\"team_id\")} for key, meta in roster.items()]\n",
    "    out = pd.DataFrame(rows)\n",
    "    if debug:\n",
    "        print(f\"[players-fast] season={season} source=roster rows={len(out)}; Team is None; TeamID populated variably.\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_season_list_fast(*, debug: bool = True) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get list of available seasons from the season index directory.\n",
    "    Fast local lookup, no network calls.\n",
    "    \"\"\"\n",
    "    from pathlib import Path\n",
    "    from salary_nba_data_pull.settings import DATA_PROCESSED_DIR\n",
    "    \n",
    "    index_dir = Path(DATA_PROCESSED_DIR) / \"season_index\"\n",
    "    if not index_dir.exists():\n",
    "        if debug:\n",
    "            print(f\"[season-list] index directory not found at {index_dir}\")\n",
    "        return []\n",
    "    \n",
    "    seasons = []\n",
    "    for parquet_file in index_dir.glob(\"season=*.parquet\"):\n",
    "        season = parquet_file.stem.replace(\"season=\", \"\")\n",
    "        seasons.append(season)\n",
    "    \n",
    "    seasons.sort(reverse=True)  # newest first\n",
    "    if debug:\n",
    "        print(f\"[season-list] found {len(seasons)} seasons: {seasons[:5]}...\")\n",
    "    return seasons\n",
    "\n",
    "\n",
    "def check_network_connectivity(*, debug: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Check if the app can reach external services.\n",
    "    Returns diagnostic information for troubleshooting.\n",
    "    \"\"\"\n",
    "    return network_env_diagnostics(timeout_sec=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/trade_impact_section_st_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/trade_impact_section_st_app.py\n",
    "\n",
    "# Required imports\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from nba_api.stats.static import teams\n",
    "from datetime import date\n",
    "from trade_impact.combined_trade_analysis import combined_trade_analysis\n",
    "from streamlit_app_helpers import get_players_for_season_fast, check_network_connectivity\n",
    "\n",
    "# --- REPLACE this helper; keep the name used by the app ---\n",
    "def convert_season_format(year):\n",
    "    \"\"\"\n",
    "    Converts an input year (e.g., 2023 or '2023') to the season format (e.g., '2023-24').\n",
    "    If the input is already 'YYYY-YY', returns it unchanged.\n",
    "    \"\"\"\n",
    "    from trade_impact.utils.nba_api_utils import normalize_season\n",
    "    return normalize_season(year)\n",
    "\n",
    "\n",
    "def get_players_for_team(team_name, season=\"2023-24\", *, use_live: bool = True, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Fast + robust players list for a specific team in a season.\n",
    "    Priority:\n",
    "      1) Season index (local parquet): [Player, PlayerID, Team, TeamID]\n",
    "      2) Authoritative fallback: CommonTeamRoster(team_id, season)\n",
    "    No filling/masking. Heavily instrumented for diagnostics.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from nba_api.stats.static import teams as _static_teams\n",
    "    from trade_impact.utils.nba_api_utils import normalize_season\n",
    "    from streamlit_app_helpers import get_players_for_season_fast\n",
    "    from salary_nba_data_pull.fetch_utils import fetch_team_roster\n",
    "\n",
    "    season_norm = normalize_season(season)\n",
    "\n",
    "    # Resolve team metadata\n",
    "    all_teams = _static_teams.get_teams()\n",
    "    by_full = {t[\"full_name\"].casefold(): t for t in all_teams}\n",
    "    by_abbr = {t[\"abbreviation\"].casefold(): t for t in all_teams}\n",
    "    meta = by_full.get(team_name.casefold()) or by_abbr.get(team_name.casefold())\n",
    "    if meta is None:\n",
    "        if debug:\n",
    "            print(f\"[get_players_for_team] cannot resolve team metadata for '{team_name}'\")\n",
    "        return []\n",
    "    team_id = int(meta[\"id\"]); abbr = meta[\"abbreviation\"]; full = meta[\"full_name\"]\n",
    "\n",
    "    # Try the season index first (fast path)\n",
    "    idx = get_players_for_season_fast(season_norm, debug=debug).copy()\n",
    "    if not idx.empty:\n",
    "        if debug:\n",
    "            print(f\"[get_players_for_team] source=index  rows={len(idx)}  \"\n",
    "                  f\"cols={list(idx.columns)}  season={season_norm} team={full}({team_id})\")\n",
    "        players = []\n",
    "        try:\n",
    "            mask = pd.Series(False, index=idx.index)\n",
    "            if \"TeamID\" in idx.columns and idx[\"TeamID\"].notna().any():\n",
    "                mask |= (idx[\"TeamID\"].astype(\"Int64\") == team_id)\n",
    "            if (not mask.any()) and (\"Team\" in idx.columns):\n",
    "                tser = idx[\"Team\"].astype(str)\n",
    "                mask |= tser.str.casefold().eq(full.casefold()) | tser.str.upper().eq(abbr.upper())\n",
    "            players = (idx.loc[mask, [\"Player\", \"PlayerID\"]]\n",
    "                          .dropna(subset=[\"Player\"])\n",
    "                          .drop_duplicates()\n",
    "                          .sort_values(\"Player\")[\"Player\"].tolist())\n",
    "            if debug:\n",
    "                via_id = int((idx.get(\"TeamID\", pd.Series(dtype=\"Int64\")).astype(\"Int64\") == team_id).sum()) if \"TeamID\" in idx.columns else -1\n",
    "                via_lbl = 0\n",
    "                if \"Team\" in idx.columns:\n",
    "                    tser = idx[\"Team\"].astype(str)\n",
    "                    via_lbl = int((tser.str.casefold().eq(full.casefold()) | tser.str.upper().eq(abbr.upper())).sum())\n",
    "                print(f\"[get_players_for_team] index-match via TeamID={via_id}, via label{via_lbl}, final={len(players)}\")\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"[get_players_for_team][index-path][ERROR] {e}\")\n",
    "            players = []\n",
    "        # Check if index returned a reasonable team size\n",
    "        MIN_TEAM_SIZE = 8  # Reasonable minimum for a full roster\n",
    "        if len(players) >= MIN_TEAM_SIZE:\n",
    "            if debug:\n",
    "                print(f\"[get_players_for_team] using index result ({len(players)} players)\")\n",
    "            return players\n",
    "        elif len(players) > 0:\n",
    "            if debug:\n",
    "                print(f\"[get_players_for_team] index returned only {len(players)} players, trying roster fallback\")\n",
    "\n",
    "    # Authoritative fallback: CommonTeamRoster\n",
    "    if debug:\n",
    "        print(f\"[get_players_for_team] source=CommonTeamRoster fallback  season={season_norm} team={full}({team_id})\")\n",
    "    roster = fetch_team_roster(team_id=team_id, season=season_norm, debug=debug)\n",
    "    if roster.empty:\n",
    "        if debug:\n",
    "            print(f\"[get_players_for_team] roster fallback returned 0 rows\")\n",
    "        # Return whatever the index had as last resort\n",
    "        return players if 'players' in locals() else []\n",
    "    \n",
    "    name_col = \"PLAYER\" if \"PLAYER\" in roster.columns else None\n",
    "    if name_col is None:\n",
    "        if debug:\n",
    "            print(f\"[get_players_for_team] roster columns unexpected: {list(roster.columns)}\")\n",
    "        # Return whatever the index had as last resort\n",
    "        return players if 'players' in locals() else []\n",
    "    \n",
    "    roster_players = roster[[name_col]].dropna().drop_duplicates().sort_values(name_col)[name_col].tolist()\n",
    "    if debug:\n",
    "        print(f\"[get_players_for_team] roster fallback returned {len(roster_players)} players\")\n",
    "    \n",
    "    # Prefer roster result if it's substantial, otherwise fall back to index\n",
    "    if len(roster_players) >= MIN_TEAM_SIZE:\n",
    "        return roster_players\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"[get_players_for_team] roster fallback also sparse ({len(roster_players)}), using index result\")\n",
    "        return players if 'players' in locals() else roster_players\n",
    "\n",
    "\n",
    "def get_trade_season(trade_date):\n",
    "    year = trade_date.year\n",
    "    if trade_date.month in [10, 11, 12]:\n",
    "        return f\"{year}-{str(year + 1)[-2:]}\"\n",
    "    else:\n",
    "        return f\"{year - 1}-{str(year)[-2:]}\"\n",
    "\n",
    "\n",
    "def get_last_n_seasons(current_season, n=10):\n",
    "    current_year = int(current_season.split('-')[0])\n",
    "    seasons = [f\"{year}-{str(year + 1)[-2:]}\" for year in range(current_year - n + 1, current_year + 1)]\n",
    "    return seasons  # Return in ascending order\n",
    "\n",
    "\n",
    "def display_trade_impact_results(results, team_a_name, team_b_name):\n",
    "    st.write(\"### Trade Scenario Analysis:\")\n",
    "    st.text(results['trade_analysis'])\n",
    "\n",
    "    st.write(\"### Average Champion Percentiles:\")\n",
    "    st.dataframe(results['average_champion_percentiles'])\n",
    "\n",
    "    st.write(f\"### {team_a_name} Comparison Table:\")\n",
    "    st.dataframe(results['team_a_comparison_table'])\n",
    "\n",
    "    st.write(f\"### {team_b_name} Comparison Table:\")\n",
    "    st.dataframe(results['team_b_comparison_table'])\n",
    "\n",
    "    for stat, table in results['comparison_tables'].items():\n",
    "        st.write(f\"### Comparison Table for {stat}:\")\n",
    "        st.dataframe(table)\n",
    "\n",
    "    st.write(\"### Overpaid/Underpaid Player Analysis:\")\n",
    "    st.dataframe(results['salary_analysis'])\n",
    "\n",
    "    st.write(\"### Player Compatibility Analysis:\")\n",
    "    st.dataframe(results['compatibility_analysis'])\n",
    "\n",
    "\n",
    "def get_unique_game_dates(season, *, use_live: bool = True, debug: bool = False):\n",
    "    \"\"\"\n",
    "    Return sorted unique game dates (date objects) for the given season.\n",
    "    Uses league-wide PlayerGameLogs via utils to leverage retries/cache.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from trade_impact.utils.nba_api_utils import get_playergamelogs_df, normalize_season\n",
    "\n",
    "    season_norm = normalize_season(season)\n",
    "    logs = get_playergamelogs_df(season_norm, use_live=use_live, debug=debug)\n",
    "    \n",
    "    if \"GAME_DATE\" not in logs.columns or logs.empty:\n",
    "        if debug:\n",
    "            print(f\"[get_unique_game_dates] No game dates found for {season_norm}\")\n",
    "        return []\n",
    "    \n",
    "    # Convert to date objects and get unique sorted dates\n",
    "    dates = pd.to_datetime(logs[\"GAME_DATE\"]).dt.date.unique()\n",
    "    return sorted(dates)\n",
    "\n",
    "\n",
    "\n",
    "def trade_impact_simulator_app(selected_season=\"2023\"):\n",
    "    from trade_impact.utils.nba_api_utils import normalize_season\n",
    "    formatted_season = normalize_season(selected_season)\n",
    "\n",
    "    st.title(f\"NBA Trade Impact Analysis - {formatted_season}\")\n",
    "\n",
    "    st.sidebar.subheader(\"Data Source\")\n",
    "    use_live_api = st.sidebar.checkbox(\"Use live NBA API\", value=True,\n",
    "        help=\"Uncheck to use cached data only. If live calls fail, cached data will be used when available.\")\n",
    "    \n",
    "    # Debug option for troubleshooting\n",
    "    debug_mode = st.sidebar.checkbox(\"Enable Debug Mode\", value=False,\n",
    "        help=\"Show detailed debug information in the console/logs for troubleshooting team player loading issues.\")\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "    ## About This App\n",
    "\n",
    "    This application allows you to analyze the impact of a trade between two NBA teams. It includes the following components:\n",
    "\n",
    "    ### 1. Trade Scenario Analysis:\n",
    "    - Ensure the trade satisfies NBA salary matching rules based on the provided player salaries.\n",
    "\n",
    "    ### 2. Percentile Counts:\n",
    "    - The count of top 1, 2, 3, 4, 5, 10, 25, 50 percentiles of the team's performance before and after the trade, compared to the last 'n' seasons selected in the champion season filter.\n",
    "\n",
    "    ### 3. Overall Trade Impact:\n",
    "    - **Pre-Trade Scenario**:\n",
    "        * **Data Collection:** Filter season data to include only games before the trade date.\n",
    "        * **Statistical Calculations:** Calculate total points and games played before the trade.\n",
    "        * **Averaging:** Calculate average points per game before the trade.\n",
    "        * **Percentile Ranking:** Rank teams based on pre-trade performance.\n",
    "\n",
    "    - **Post-Trade Scenario**:\n",
    "        * **Data Collection:** Filter season data for games on or after the trade date.\n",
    "        * **Player Averages:** Calculate average points for traded players post-trade.\n",
    "        * **Simulating Game Logs:** Simulate additional game logs using calculated player averages.\n",
    "        * **Statistical Calculations:** Combine simulated and actual post-trade data for calculations.\n",
    "        * **Averaging:** Calculate average points per game post-trade.\n",
    "        * **Percentile Ranking:** Rank teams based on post-trade performance.\n",
    "\n",
    "    - **No-Trade Scenario**:\n",
    "        * **Data Collection:** Use full season data assuming no trades occurred.\n",
    "        * **Statistical Calculations:** Calculate total points and games played for the entire season.\n",
    "        * **Averaging:** Calculate average points per game for the full season.\n",
    "        * **Percentile Ranking:** Rank teams based on full-season performance.\n",
    "\n",
    "    - **Final Comparison**:\n",
    "        * **Aggregation:** Organize pre-trade, post-trade, and no-trade results.\n",
    "        * **Metrics Compared:** Total points, games played, average points per game, and percentile rankings.\n",
    "\n",
    "    ### 4. Overpaid/Underpaid Player Analysis:\n",
    "    - Analyze whether the players involved in the trade are overpaid or underpaid based on predicted salaries.\n",
    "\n",
    "    ### 5. Player Compatibility Analysis:\n",
    "    - Calculate the compatibility between the players being traded based on their shooting areas.\n",
    "    \"\"\")\n",
    "\n",
    "    # Load predictions (unchanged)\n",
    "    predictions_df = pd.read_csv('data/processed/predictions_df.csv')\n",
    "\n",
    "    # Team and player selectors\n",
    "    all_teams = [team['full_name'] for team in teams.get_teams()]\n",
    "    team_a_name = st.selectbox(\"Select Team A\", all_teams, key=\"team_a\")\n",
    "    team_b_name = st.selectbox(\"Select Team B\", [t for t in all_teams if t != team_a_name], key=\"team_b\")\n",
    "\n",
    "    # Safely populate player lists using cached, lightweight calls\n",
    "    try:\n",
    "        players_a_options = get_players_for_team(team_a_name, formatted_season, use_live=use_live_api, debug=debug_mode)\n",
    "    except Exception as e:\n",
    "        players_a_options = []\n",
    "        st.warning(f\"Could not load roster for {team_a_name}: {e}\")\n",
    "\n",
    "    try:\n",
    "        players_b_options = get_players_for_team(team_b_name, formatted_season, use_live=use_live_api, debug=debug_mode)\n",
    "    except Exception as e:\n",
    "        players_b_options = []\n",
    "        st.warning(f\"Could not load roster for {team_b_name}: {e}\")\n",
    "\n",
    "    players_from_team_a = st.multiselect(f\"Select Players from {team_a_name}\", players_a_options)\n",
    "    players_from_team_b = st.multiselect(f\"Select Players from {team_b_name}\", players_b_options)\n",
    "\n",
    "    # Champion seasons\n",
    "    def get_last_n_seasons(current_season, n=10):\n",
    "        y = int(str(current_season)[:4])\n",
    "        return [f\"{yr}-{str(yr+1)[-2:]}\" for yr in range(y - n + 1, y + 1)]\n",
    "\n",
    "    last_10_seasons = get_last_n_seasons(formatted_season)\n",
    "    champion_seasons = st.multiselect(\"Select Champion Seasons for Comparison\", last_10_seasons, default=last_10_seasons)\n",
    "    champion_seasons = sorted(champion_seasons)\n",
    "\n",
    "    analysis_option = st.radio(\"Select Analysis Period\", options=[\"Full Season\", \"Specific Date\"])\n",
    "\n",
    "    if analysis_option == \"Specific Date\":\n",
    "        try:\n",
    "            unique_dates = get_unique_game_dates(formatted_season, use_live=use_live_api, debug=True)\n",
    "            trade_date = st.selectbox(\"Select Trade Date\", unique_dates)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Could not load game dates for {formatted_season}: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        y = int(str(formatted_season)[:4])\n",
    "        from datetime import date\n",
    "        trade_date = date(y, 8, 15)  # offseason default\n",
    "\n",
    "    st.write(f\"### Analysis Criteria:\\n- **Team A:** {team_a_name}\\n- **Team B:** {team_b_name}\\n- **Season:** {formatted_season}\\n- **Champion Seasons:** {', '.join(champion_seasons)}\")\n",
    "\n",
    "    include_debug_columns = st.checkbox(\"Include Debug Columns (Games and Totals)\", value=False)\n",
    "\n",
    "    if st.button(\"Analyze Trade Impact\"):\n",
    "        if not players_from_team_a or not players_from_team_b:\n",
    "            st.error(\"Please select at least one player from each team.\")\n",
    "            return\n",
    "\n",
    "        with st.spinner('Analyzing trade impact...'):\n",
    "            try:\n",
    "                results = combined_trade_analysis(\n",
    "                    team_a_name, team_b_name, players_from_team_a, players_from_team_b,\n",
    "                    trade_date, champion_seasons, formatted_season,\n",
    "                    ['PTS', 'AST', 'TOV', 'STL', 'BLK', 'OREB', 'DREB', 'FGM', 'FG3M', 'FGA'],\n",
    "                    predictions_df, debug=include_debug_columns\n",
    "                )\n",
    "                display_trade_impact_results(results, team_a_name, team_b_name)\n",
    "            except Exception as e:\n",
    "                st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trade_impact_simulator_app()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
