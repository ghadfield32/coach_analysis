{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_predict/updated/data_loader_preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_predict/updated/data_loader_preprocessor.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Data loaded. Shape:\", data.shape)\n",
    "    return data\n",
    "\n",
    "def format_season(data):\n",
    "    # Convert season format to a single year for easier numerical analysis\n",
    "    data['Season'] = data['Season'].apply(lambda x: int(x.split('-')[0]))\n",
    "    print(\"Seasons in data:\", data['Season'].unique())\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    # Drop columns that may not contribute significantly to the model\n",
    "    data_clean = data.copy()\n",
    "    columns_to_drop = ['Injury_Periods', '2nd Apron', 'Wins', 'Losses']\n",
    "    data_clean.drop(columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
    "    \n",
    "    # Handle missing percentage data by filling with column mean\n",
    "    percentage_cols = ['3P%', '2P%', 'FT%', 'TS%']\n",
    "    for col in percentage_cols:\n",
    "        if col in data_clean.columns:\n",
    "            data_clean[col] = data_clean[col].fillna(data_clean[col].mean())\n",
    "    \n",
    "    # Drop remaining NaNs\n",
    "    data_clean = data_clean.dropna()\n",
    "    print(\"Data cleaned. Remaining shape:\", data_clean.shape)\n",
    "    return data_clean\n",
    "\n",
    "def engineer_features(data):\n",
    "    # Calculate per-game statistics to normalize performance data\n",
    "    per_game_cols = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "    for col in per_game_cols:\n",
    "        data[f'{col[0]}PG'] = data[col] / data['GP']\n",
    "    \n",
    "    # Derive additional features to capture important aspects of a player's performance\n",
    "    data['Availability'] = data['GP'] / 82\n",
    "    data['SalaryPct'] = data['Salary'] / data['Salary_Cap_Inflated']\n",
    "    data['Efficiency'] = (data['PTS'] + data['TRB'] + data['AST'] + data['STL'] + data['BLK']) / (data['FGA'] + data['FTA'] + data['TOV'] + 1)\n",
    "    data['ValueOverReplacement'] = data['VORP'] / (data['Salary'] + 1)\n",
    "    data['ExperienceSquared'] = data['Years of Service'] ** 2\n",
    "    data['Days_Injured_Percentage'] = data['Total_Days_Injured'] / data['GP']\n",
    "    data['WSPG'] = data['WS'] / data['GP']\n",
    "    data['DWSPG'] = data['DWS'] / data['GP']\n",
    "    data['OWSPG'] = data['OWS'] / data['GP']\n",
    "    data['PFPG'] = data['PF'] / data['GP']\n",
    "    data['ORPG'] = data['ORB'] / data['GP']\n",
    "    data['DRPG'] = data['DRB'] / data['GP']\n",
    "    \n",
    "    # Drop columns used in feature creation or deemed less relevant\n",
    "    columns_to_drop = ['GP', '2PA', 'OBPM', 'BPM', 'DBPM', '2P', 'GS', 'PTS', 'AST', 'TRB', 'STL', 'BLK',\n",
    "                       'TOV', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '2P', '2PA', 'FT', 'FTA', 'ORB', 'DRB', 'TRB',\n",
    "                       'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'Luxury Tax', '1st Apron', 'BAE',\n",
    "                       'Standard /Non-Taxpayer', 'Taxpayer', 'Team Room /Under Cap', 'WS', 'DWS', 'WS/48', 'PF', 'OWS', 'Injured']\n",
    "    data.drop(columns_to_drop, axis=1, errors='ignore', inplace=True)\n",
    "    print(\"New features added.\")\n",
    "    return data\n",
    "\n",
    "def encode_injury_risk(data):\n",
    "    # Encode injury risk levels for model training\n",
    "    risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(risk_mapping).fillna(1)  # Default to Medium if unknown\n",
    "    return data, risk_mapping\n",
    "\n",
    "def encode_categorical(data, columns):\n",
    "    # Encode categorical columns using one-hot encoding\n",
    "    encoders = {}\n",
    "    for col in columns:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        encoded = encoder.fit_transform(data[[col]])\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=data.index)\n",
    "        data = pd.concat([data.drop(col, axis=1), encoded_df], axis=1)\n",
    "        encoders[col] = encoder\n",
    "    return data, encoders\n",
    "\n",
    "def encode_data(data, encoders=None, player_encoder=None):\n",
    "    print(\"Columns before encoding:\", data.columns)\n",
    "\n",
    "    # Encode Injury_Risk\n",
    "    risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(risk_mapping).fillna(1)  # Default to Medium if unknown\n",
    "\n",
    "    # Encode Player column if it's present\n",
    "    if 'Player' in data.columns:\n",
    "        if player_encoder is None:\n",
    "            player_encoder = LabelEncoder()\n",
    "            data['Player_Encoded'] = player_encoder.fit_transform(data['Player'])\n",
    "        else:\n",
    "            data['Player_Encoded'] = player_encoder.transform(data['Player'])\n",
    "        data.drop('Player', axis=1, inplace=True)  # Drop original Player column after encoding\n",
    "    \n",
    "    # Identify initial numeric columns\n",
    "    initial_numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Encode categorical variables (excluding Season)\n",
    "    categorical_cols = ['Position', 'Team']\n",
    "    if encoders is None:\n",
    "        encoders = {}\n",
    "        for col in categorical_cols:\n",
    "            encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "            encoded = encoder.fit_transform(data[[col]])\n",
    "            encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([col]), index=data.index)\n",
    "            data = pd.concat([data.drop(col, axis=1), encoded_df], axis=1)\n",
    "            encoders[col] = encoder\n",
    "    else:\n",
    "        for col in categorical_cols:\n",
    "            encoded = encoders[col].transform(data[[col]])\n",
    "            encoded_df = pd.DataFrame(encoded, columns=encoders[col].get_feature_names_out([col]), index=data.index)\n",
    "            data = pd.concat([data.drop(col, axis=1), encoded_df], axis=1)\n",
    "\n",
    "    # Identify final numeric columns (excluding one-hot encoded columns and 'Season')\n",
    "    numeric_cols = [col for col in initial_numeric_cols if col not in ['Season', 'Injury_Risk', 'Player_Encoded']]\n",
    "\n",
    "    # Scale numeric features (excluding 'Player_Encoded')\n",
    "    scaler = StandardScaler()\n",
    "    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "    print(\"Encoded data shape:\", data.shape)\n",
    "    print(\"Columns after encoding:\", data.columns)\n",
    "\n",
    "    return data, risk_mapping, encoders, scaler, numeric_cols, player_encoder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scale_features(data, numeric_cols):\n",
    "    scaler = StandardScaler()\n",
    "    data[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "    return data, scaler\n",
    "\n",
    "def decode_data(encoded_data, injury_risk_mapping, encoders, scaler, numeric_cols, player_encoder):\n",
    "    decoded_data = encoded_data.copy()\n",
    "    \n",
    "    # Decode Injury_Risk\n",
    "    inv_injury_risk_mapping = {v: k for k, v in injury_risk_mapping.items()}\n",
    "    decoded_data['Injury_Risk'] = decoded_data['Injury_Risk'].map(inv_injury_risk_mapping)\n",
    "    \n",
    "    # Decode Player column\n",
    "    if 'Player_Encoded' in decoded_data.columns:\n",
    "        decoded_data['Player'] = player_encoder.inverse_transform(decoded_data['Player_Encoded'])\n",
    "        decoded_data.drop('Player_Encoded', axis=1, inplace=True)\n",
    "    \n",
    "    # Decode categorical variables\n",
    "    for col, encoder in encoders.items():\n",
    "        encoded_cols = [c for c in decoded_data.columns if c.startswith(f\"{col}_\")]\n",
    "        decoded_col = encoder.inverse_transform(decoded_data[encoded_cols])\n",
    "        decoded_data[col] = decoded_col.ravel()  # Flatten the 2D array to 1D\n",
    "        decoded_data.drop(encoded_cols, axis=1, inplace=True)\n",
    "    \n",
    "    # Inverse transform scaled features\n",
    "    decoded_data[numeric_cols] = scaler.inverse_transform(decoded_data[numeric_cols])\n",
    "    \n",
    "    return decoded_data\n",
    "\n",
    "def select_top_features(X, y, k=10):\n",
    "    # Select top features based on statistical significance\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    selector.fit(X, y)\n",
    "    top_features = X.columns[selector.get_support()].tolist()\n",
    "    print(f\"Top {k} features:\", top_features)\n",
    "    return top_features\n",
    "\n",
    "def calculate_tree_feature_importance(X, y):\n",
    "    # Calculate feature importance using a Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    importances = rf.feature_importances_\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importances.head(20))\n",
    "    plt.title('Top 20 Feature Importances from Random Forest')\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importances\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    data = load_data(file_path)\n",
    "    data = format_season(data)\n",
    "    data = clean_data(data)\n",
    "    data = engineer_features(data)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(['SalaryPct', 'Salary'], axis=1)\n",
    "    y = data['SalaryPct']\n",
    "\n",
    "    # Encode data\n",
    "    encoded_data, injury_risk_mapping, encoders, scaler, numeric_cols, player_encoder = encode_data(X)\n",
    "\n",
    "    print(\"\\nInjury Risk Mapping:\", injury_risk_mapping)\n",
    "    print(\"Encoded Injury Risk range:\", encoded_data['Injury_Risk'].min(), \"-\", encoded_data['Injury_Risk'].max())\n",
    "    print(\"\\nNumeric columns for scaling:\", numeric_cols)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    feature_importances = calculate_tree_feature_importance(encoded_data, y)\n",
    "    print(\"\\nTree-based feature importances:\")\n",
    "    print(feature_importances.head(20))\n",
    "\n",
    "    # Select top features\n",
    "    top_features = select_top_features(encoded_data, y)\n",
    "    print(\"\\nTop features selected using statistical methods:\", top_features)\n",
    "\n",
    "    # Decoding example\n",
    "    print(\"\\nDecoding Example:\")\n",
    "    decoded_data = decode_data(encoded_data, injury_risk_mapping, encoders, scaler, numeric_cols, player_encoder)\n",
    "    \n",
    "    print(\"\\nFirst few rows of decoded data:\")\n",
    "    print(decoded_data[['Player', 'Injury_Risk', 'Position', 'Team', 'Season'] + top_features].head())\n",
    "\n",
    "    print(\"\\nData types after decoding:\")\n",
    "    print(decoded_data.dtypes)\n",
    "\n",
    "    print(\"\\nData preprocessing completed. Ready for model training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_predict/updated/model_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_predict/updated/model_trainer.py\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def inspect_data_types(X):\n",
    "    print(\"Data types of features:\")\n",
    "    print(X.dtypes)\n",
    "    object_columns = X.select_dtypes(include=['object']).columns\n",
    "    if not object_columns.empty:\n",
    "        print(\"Columns with object data types:\", object_columns.tolist())\n",
    "    else:\n",
    "        print(\"No columns with object data types.\")\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "    print(f\"Best score for {model.__class__.__name__}: {-grid_search.best_score_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def train_and_save_models(X_train, y_train, model_save_path, scaler, feature_names, encoders, player_encoder, numeric_cols):\n",
    "    # Inspect data types before training\n",
    "    inspect_data_types(X_train)\n",
    "\n",
    "    # Initialize models with default parameters\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    xgb_model = xgb.XGBRegressor(random_state=42, enable_categorical=True)\n",
    "\n",
    "    # Define parameter grids for grid search\n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    # Perform grid search\n",
    "    best_rf_model = perform_grid_search(rf_model, rf_param_grid, X_train, y_train)\n",
    "    best_xgb_model = perform_grid_search(xgb_model, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "    # Train models with best parameters\n",
    "    best_rf_model.fit(X_train, y_train)\n",
    "    best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Scale the features used for training\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Save models, scaler, feature names, encoders, and other artifacts\n",
    "    joblib.dump(best_rf_model, f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    joblib.dump(best_xgb_model, f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "    joblib.dump(scaler, f\"{model_save_path}/scaler.pkl\")\n",
    "    joblib.dump(feature_names, f\"{model_save_path}/feature_names.pkl\")\n",
    "    joblib.dump(encoders, f\"{model_save_path}/encoders.pkl\")\n",
    "    joblib.dump(injury_risk_mapping, f\"{model_save_path}/injury_risk_mapping.pkl\")\n",
    "    joblib.dump(numeric_cols, f\"{model_save_path}/numeric_cols.pkl\")\n",
    "\n",
    "    joblib.dump(player_encoder, f\"{model_save_path}/player_encoder.pkl\")\n",
    "    print(\"Models, scaler, feature names, encoders, and other artifacts trained and saved successfully.\")\n",
    "\n",
    "def evaluate_models(X_test, y_test, model_save_path):\n",
    "    # Load models, scaler, and feature names\n",
    "    rf_model = joblib.load(f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "\n",
    "    # Make predictions\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "    # Evaluate models using multiple metrics\n",
    "    metrics = {'Random Forest': rf_predictions, 'XGBoost': xgb_predictions}\n",
    "\n",
    "    for model_name, predictions in metrics.items():\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        print(f\"\\n{model_name} Evaluation:\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Data preprocessing\n",
    "def load_and_preprocess_data(file_path, predict_season):\n",
    "    data = load_data(file_path)\n",
    "    data = format_season(data)\n",
    "    _, prior_seasons_data = filter_seasons(data, predict_season)\n",
    "    prior_seasons_data = clean_data(prior_seasons_data)\n",
    "    prior_seasons_data = engineer_features(prior_seasons_data)\n",
    "    return prior_seasons_data\n",
    "\n",
    "# Feature selection\n",
    "def select_features(data, target_column, additional_features=[]):\n",
    "    top_features = ['PPG', 'APG', 'RPG', 'SPG', 'TOPG', 'Years of Service', 'PER', 'VORP', 'WSPG', 'OWSPG']\n",
    "    \n",
    "    # Add 'Injury_Risk', 'Position', and 'Team' to ensure they're included for encoding\n",
    "    top_features += ['Injury_Risk', 'Position', 'Team']\n",
    "    \n",
    "    # Add any additional features\n",
    "    top_features += additional_features\n",
    "    \n",
    "    # Ensure all selected features are in the dataset\n",
    "    available_features = [col for col in top_features if col in data.columns]\n",
    "    \n",
    "    print(\"Available features for modeling:\", available_features)  # Debug statement\n",
    "\n",
    "    X = data[available_features]\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2023\n",
    "    target_column = 'SalaryPct'\n",
    "\n",
    "    # Load and preprocess data\n",
    "    preprocessed_data = load_and_preprocess_data(file_path, predict_season)\n",
    "    print(\"Columns after preprocessing:\", preprocessed_data.columns)\n",
    "\n",
    "    # Select features\n",
    "    X, y = select_features(preprocessed_data, target_column)\n",
    "    print(\"Columns after feature selection:\", X.columns)\n",
    "\n",
    "    # Encode data\n",
    "    encoded_data, injury_risk_mapping, encoders, scaler, numeric_cols, player_encoder = encode_data(X)\n",
    "    print(\"Columns after encoding:\", encoded_data.columns)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(encoded_data, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train and evaluate models\n",
    "    model_save_path = '../data/models'\n",
    "    train_and_save_models(X_train, y_train, model_save_path, scaler, encoded_data.columns, encoders, injury_risk_mapping, numeric_cols)\n",
    "    evaluate_models(X_test, y_test, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_predict/updated/model_predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_predict/updated/model_predictor.py\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "def load_models_and_utils(model_save_path):\n",
    "    rf_model = joblib.load(f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "    scaler = joblib.load(f\"{model_save_path}/scaler.pkl\")\n",
    "    feature_names = joblib.load(f\"{model_save_path}/feature_names.pkl\")\n",
    "    encoders = joblib.load(f\"{model_save_path}/encoders.pkl\")\n",
    "    injury_risk_mapping = joblib.load(f\"{model_save_path}/injury_risk_mapping.pkl\")\n",
    "    numeric_cols = joblib.load(f\"{model_save_path}/numeric_cols.pkl\")\n",
    "    player_encoder = joblib.load(f\"{model_save_path}/player_encoder.pkl\")\n",
    "    return rf_model, xgb_model, scaler, feature_names, encoders, injury_risk_mapping, numeric_cols, player_encoder\n",
    "\n",
    "def predict(data, model_save_path):\n",
    "    rf_model, xgb_model, scaler, feature_names, encoders, _, _, player_encoder = load_models_and_utils(model_save_path)\n",
    "    \n",
    "    print(\"Original data shape:\", data.shape)\n",
    "    print(\"Original data columns:\", data.columns.tolist())\n",
    "\n",
    "    # Preserve player names\n",
    "    player_names = data['Player'] if 'Player' in data.columns else None\n",
    "    \n",
    "    # Drop the player column before encoding\n",
    "    data = data.drop(columns=['Player'], errors='ignore')\n",
    "    \n",
    "    # Encode the data using the loaded encoders\n",
    "    encoded_data, _, _, _, _, _ = encode_data(data, encoders, player_encoder)\n",
    "    \n",
    "    print(\"Encoded data shape:\", encoded_data.shape)\n",
    "    print(\"Encoded data columns:\", encoded_data.columns.tolist())\n",
    "    \n",
    "    # Handle missing features: Add missing columns and set them to zero\n",
    "    for col in feature_names:\n",
    "        if col not in encoded_data.columns:\n",
    "            encoded_data[col] = 0\n",
    "\n",
    "    # Ensure encoded_data only has feature_names columns\n",
    "    encoded_data = encoded_data[feature_names]\n",
    "    \n",
    "    print(\"Selected features shape:\", encoded_data.shape)\n",
    "    print(\"Selected features:\", encoded_data.columns.tolist())\n",
    "    print(\"Expected features:\", feature_names)\n",
    "    \n",
    "    # Scale the encoded data\n",
    "    encoded_data_scaled = scaler.transform(encoded_data)\n",
    "    \n",
    "    # Make predictions\n",
    "    rf_predictions = rf_model.predict(encoded_data_scaled)\n",
    "    xgb_predictions = xgb_model.predict(encoded_data_scaled)\n",
    "    \n",
    "    # Create a DataFrame for predictions\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'RF_Predictions': rf_predictions,\n",
    "        'XGB_Predictions': xgb_predictions,\n",
    "        'Predicted_Salary': (rf_predictions + xgb_predictions) / 2\n",
    "    })\n",
    "    \n",
    "    # Attach player names back to the predictions\n",
    "    if player_names is not None:\n",
    "        predictions_df['Player'] = player_names.values\n",
    "\n",
    "    # Combine the predictions with the original data (excluding player names)\n",
    "    result = pd.concat([data.reset_index(drop=True), predictions_df], axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2023\n",
    "    data = load_data(file_path)\n",
    "    data = format_season(data)\n",
    "    current_season_data, _ = filter_seasons(data, predict_season)\n",
    "    current_season_data = clean_data(current_season_data)\n",
    "    current_season_data = engineer_features(current_season_data)\n",
    "    model_save_path = '../data/models'\n",
    "    predictions_df = predict(current_season_data, model_save_path)  # Save predictions as predictions_df\n",
    "    print(predictions_df.head())\n",
    "    \n",
    "    # Save predictions_df for later use\n",
    "    predictions_df.to_csv('../data/processed/predictions_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.hoopsrumors.com/2023/09/salary-matching-rules-for-trades-during-2023-24-season.html\n",
    "\n",
    "for trade rules\n",
    "\n",
    "\n",
    "FIRST_TAX_APRON = 172_346_000\n",
    "\n",
    "def check_salary_matching_rules(outgoing_salary, incoming_salary, team_salary_before_trade):\n",
    "    if team_salary_before_trade < FIRST_TAX_APRON:\n",
    "        if outgoing_salary <= 7_500_000:\n",
    "            max_incoming_salary = 2 * outgoing_salary + 250_000\n",
    "        elif outgoing_salary <= 29_000_000:\n",
    "            max_incoming_salary = outgoing_salary + 7_500_000\n",
    "        else:\n",
    "            max_incoming_salary = 1.25 * outgoing_salary + 250_000\n",
    "    else:\n",
    "        max_incoming_salary = 1.10 * outgoing_salary\n",
    "\n",
    "    return incoming_salary <= max_incoming_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for season 2022-23\n",
      "Fetching data for season 2023-24\n",
      "Champions Player Data (Past 10 Seasons):\n",
      "    PLAYER_ID               PLAYER_NAME     TEAM_ID       TEAM_NAME  \\\n",
      "0      201145                Jeff Green  1610612743  Denver Nuggets   \n",
      "1      201599            DeAndre Jordan  1610612743  Denver Nuggets   \n",
      "2      202397                 Ish Smith  1610612743  Denver Nuggets   \n",
      "3      202704            Reggie Jackson  1610612743  Denver Nuggets   \n",
      "4      203484  Kentavious Caldwell-Pope  1610612743  Denver Nuggets   \n",
      "5      203932              Aaron Gordon  1610612743  Denver Nuggets   \n",
      "6      203999              Nikola Jokic  1610612743  Denver Nuggets   \n",
      "7     1627750              Jamal Murray  1610612743  Denver Nuggets   \n",
      "8     1628418             Thomas Bryant  1610612743  Denver Nuggets   \n",
      "9     1628427             Vlatko Cancar  1610612743  Denver Nuggets   \n",
      "10    1628432                Davon Reed  1610612743  Denver Nuggets   \n",
      "11    1628971               Bruce Brown  1610612743  Denver Nuggets   \n",
      "12    1629008        Michael Porter Jr.  1610612743  Denver Nuggets   \n",
      "13    1630192                Zeke Nnaji  1610612743  Denver Nuggets   \n",
      "14    1630538              Bones Hyland  1610612743  Denver Nuggets   \n",
      "15    1631128           Christian Braun  1610612743  Denver Nuggets   \n",
      "16    1631212             Peyton Watson  1610612743  Denver Nuggets   \n",
      "17    1631298                Jack White  1610612743  Denver Nuggets   \n",
      "18     201143                Al Horford  1610612738  Boston Celtics   \n",
      "19     201950              Jrue Holiday  1610612738  Boston Celtics   \n",
      "20     204001        Kristaps Porzingis  1610612738  Boston Celtics   \n",
      "21    1627759              Jaylen Brown  1610612738  Boston Celtics   \n",
      "22    1628369              Jayson Tatum  1610612738  Boston Celtics   \n",
      "23    1628401             Derrick White  1610612738  Boston Celtics   \n",
      "24    1628436               Luke Kornet  1610612738  Boston Celtics   \n",
      "25    1629004            Svi Mykhailiuk  1610612738  Boston Celtics   \n",
      "26    1629052            Oshae Brissett  1610612738  Boston Celtics   \n",
      "27    1629674             Neemias Queta  1610612738  Boston Celtics   \n",
      "28    1630202          Payton Pritchard  1610612738  Boston Celtics   \n",
      "29    1630205             Lamar Stevens  1610612738  Boston Celtics   \n",
      "30    1630214            Xavier Tillman  1610612738  Boston Celtics   \n",
      "31    1630531            Jaden Springer  1610612738  Boston Celtics   \n",
      "32    1630573                Sam Hauser  1610612738  Boston Celtics   \n",
      "33    1630625             Dalano Banton  1610612738  Boston Celtics   \n",
      "34    1631120                JD Davison  1610612738  Boston Celtics   \n",
      "35    1641775              Jordan Walsh  1610612738  Boston Celtics   \n",
      "36    1641809             Drew Peterson  1610612738  Boston Celtics   \n",
      "\n",
      "          PTS       AST       TOV       STL       BLK      OREB      DREB  \\\n",
      "0    7.803571  1.232143  0.821429  0.321429  0.303571  0.678571  1.892857   \n",
      "1    5.102564  0.871795  1.230769  0.307692  0.589744  1.333333  3.846154   \n",
      "2    2.511628  2.325581  1.023256  0.186047  0.162791  0.116279  1.139535   \n",
      "3    7.937500  3.125000  1.187500  0.562500  0.062500  0.187500  1.562500   \n",
      "4   10.815789  2.407895  1.131579  1.473684  0.460526  0.460526  2.276316   \n",
      "5   16.308824  2.985294  1.441176  0.794118  0.750000  2.411765  4.147059   \n",
      "6   24.492754  9.826087  3.579710  1.260870  0.681159  2.420290  9.420290   \n",
      "7   19.969231  6.153846  2.230769  1.015385  0.246154  0.738462  3.215385   \n",
      "8    4.611111  0.111111  0.555556  0.111111  0.388889  1.055556  2.277778   \n",
      "9    4.950000  1.333333  0.616667  0.366667  0.233333  0.400000  1.733333   \n",
      "10   2.314286  0.542857  0.571429  0.371429  0.114286  0.257143  1.314286   \n",
      "11  11.537500  3.350000  1.537500  1.087500  0.637500  0.787500  3.312500   \n",
      "12  17.419355  1.048387  1.096774  0.596774  0.467742  1.032258  4.467742   \n",
      "13   5.226415  0.339623  0.584906  0.320755  0.433962  1.226415  1.377358   \n",
      "14  12.095238  2.976190  1.595238  0.666667  0.309524  0.238095  1.809524   \n",
      "15   4.736842  0.776316  0.460526  0.539474  0.223684  0.631579  1.750000   \n",
      "16   3.260870  0.478261  0.347826  0.086957  0.478261  0.347826  1.260870   \n",
      "17   1.235294  0.235294  0.117647  0.176471  0.117647  0.352941  0.647059   \n",
      "18   8.646154  2.584615  0.738462  0.584615  0.953846  1.261538  5.092308   \n",
      "19  12.463768  4.826087  1.797101  0.884058  0.768116  1.217391  4.188406   \n",
      "20  20.087719  2.017544  1.561404  0.736842  1.947368  1.701754  5.473684   \n",
      "21  23.000000  3.557143  2.371429  1.185714  0.528571  1.200000  4.328571   \n",
      "22  26.851351  4.918919  2.540541  1.013514  0.581081  0.905405  7.216216   \n",
      "23  15.164384  5.164384  1.534247  1.013699  1.191781  0.698630  3.547945   \n",
      "24   5.301587  1.063492  0.333333  0.365079  0.968254  1.873016  2.269841   \n",
      "25   3.951220  0.853659  0.292683  0.268293  0.024390  0.268293  0.975610   \n",
      "26   3.654545  0.800000  0.363636  0.345455  0.145455  1.109091  1.800000   \n",
      "27   5.500000  0.714286  0.464286  0.464286  0.750000  1.892857  2.464286   \n",
      "28   9.597561  3.426829  0.743902  0.475610  0.073171  0.853659  2.378049   \n",
      "29   2.789474  0.421053  0.473684  0.315789  0.263158  0.631579  1.000000   \n",
      "30   4.000000  1.000000  0.250000  0.450000  0.450000  0.700000  2.000000   \n",
      "31   2.058824  0.529412  0.470588  0.647059  0.235294  0.470588  0.705882   \n",
      "32   9.012658  1.037975  0.405063  0.506329  0.316456  0.569620  2.924051   \n",
      "33   2.333333  0.791667  0.416667  0.208333  0.125000  0.500000  0.958333   \n",
      "34   2.000000  1.250000  0.250000  0.125000  0.125000  0.250000  1.000000   \n",
      "35   1.666667  0.555556  0.333333  0.555556  0.111111  0.555556  1.666667   \n",
      "36   3.666667  0.333333  0.333333  0.666667  0.000000  0.000000  0.333333   \n",
      "\n",
      "         FGM      FG3M        FGA      eFG%   SEASON  \n",
      "0   2.857143  0.535714   5.857143  0.533537  2022-23  \n",
      "1   2.256410  0.025641   2.948718  0.769565  2022-23  \n",
      "2   1.209302  0.046512   3.046512  0.404580  2022-23  \n",
      "3   3.062500  1.187500   8.000000  0.457031  2022-23  \n",
      "4   3.842105  1.776316   8.315789  0.568829  2022-23  \n",
      "5   6.308824  0.882353  11.191176  0.603154  2022-23  \n",
      "6   9.362319  0.826087  14.811594  0.659980  2022-23  \n",
      "7   7.276923  2.646154  16.015385  0.536984  2022-23  \n",
      "8   1.833333  0.222222   3.777778  0.514706  2022-23  \n",
      "9   1.800000  0.716667   3.783333  0.570485  2022-23  \n",
      "10  0.714286  0.457143   2.285714  0.412500  2022-23  \n",
      "11  4.475000  1.137500   9.262500  0.544534  2022-23  \n",
      "12  6.419355  3.032258  13.177419  0.602203  2022-23  \n",
      "13  2.075472  0.320755   3.698113  0.604592  2022-23  \n",
      "14  4.119048  2.166667  10.333333  0.503456  2022-23  \n",
      "15  1.881579  0.447368   3.802632  0.553633  2022-23  \n",
      "16  1.260870  0.260870   2.565217  0.542373  2022-23  \n",
      "17  0.470588  0.176471   1.117647  0.500000  2022-23  \n",
      "18  3.292308  1.661538   6.446154  0.639618  2023-24  \n",
      "19  4.797101  2.000000   9.985507  0.580552  2023-24  \n",
      "20  6.807018  1.929825  13.192982  0.589096  2023-24  \n",
      "21  8.957143  2.071429  17.942857  0.556927  2023-24  \n",
      "22  9.081081  3.094595  19.270270  0.551543  2023-24  \n",
      "23  5.301370  2.684932  11.493151  0.578069  2023-24  \n",
      "24  2.253968  0.015873   3.222222  0.701970  2023-24  \n",
      "25  1.390244  1.024390   3.341463  0.569343  2023-24  \n",
      "26  1.236364  0.272727   2.781818  0.493464  2023-24  \n",
      "27  2.392857  0.000000   3.714286  0.644231  2023-24  \n",
      "28  3.621951  1.792683   7.743902  0.583465  2023-24  \n",
      "29  1.105263  0.157895   2.368421  0.500000  2023-24  \n",
      "30  1.700000  0.400000   3.300000  0.575758  2023-24  \n",
      "31  0.764706  0.117647   1.764706  0.466667  2023-24  \n",
      "32  3.151899  2.493671   7.063291  0.622760  2023-24  \n",
      "33  0.791667  0.083333   2.125000  0.392157  2023-24  \n",
      "34  0.625000  0.375000   1.500000  0.541667  2023-24  \n",
      "35  0.666667  0.222222   1.666667  0.466667  2023-24  \n",
      "36  1.333333  1.000000   2.000000  0.916667  2023-24  \n",
      "\n",
      "Current Season Player Data:\n",
      "    PLAYER_ID        PLAYER_NAME     TEAM_ID            TEAM_NAME        PTS  \\\n",
      "0      202684   Tristan Thompson  1610612739  Cleveland Cavaliers   3.285714   \n",
      "1      202694  Marcus Morris Sr.  1610612739  Cleveland Cavaliers   5.750000   \n",
      "2     1627745       Damian Jones  1610612739  Cleveland Cavaliers   2.743590   \n",
      "3     1627747       Caris LeVert  1610612739  Cleveland Cavaliers  14.000000   \n",
      "4     1627777      Georges Niang  1610612739  Cleveland Cavaliers   9.365854   \n",
      "..        ...                ...         ...                  ...        ...   \n",
      "652   1630591        Jalen Suggs  1610612753        Orlando Magic  12.573333   \n",
      "653   1631094     Paolo Banchero  1610612753        Orlando Magic  22.550000   \n",
      "654   1631216      Caleb Houstan  1610612753        Orlando Magic   4.288136   \n",
      "655   1641710      Anthony Black  1610612753        Orlando Magic   4.579710   \n",
      "656   1641724        Jett Howard  1610612753        Orlando Magic   1.611111   \n",
      "\n",
      "          AST       TOV       STL       BLK      OREB      DREB       FGM  \\\n",
      "0    1.040816  0.591837  0.244898  0.285714  1.489796  2.061224  1.489796   \n",
      "1    0.833333  0.916667  0.166667  0.166667  0.416667  1.666667  2.166667   \n",
      "2    0.384615  0.333333  0.179487  0.333333  0.512821  1.076923  1.102564   \n",
      "3    5.088235  1.720588  1.117647  0.500000  0.573529  3.544118  5.073529   \n",
      "4    1.195122  0.878049  0.365854  0.219512  0.268293  3.121951  3.463415   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "652  2.733333  1.760000  1.413333  0.626667  0.640000  2.413333  4.480000   \n",
      "653  5.387500  3.087500  0.887500  0.587500  1.025000  5.900000  8.000000   \n",
      "654  0.491525  0.271186  0.254237  0.067797  0.474576  0.949153  1.355932   \n",
      "655  1.318841  0.811594  0.507246  0.304348  0.478261  1.536232  1.666667   \n",
      "656  0.333333  0.166667  0.111111  0.111111  0.055556  0.333333  0.555556   \n",
      "\n",
      "         FG3M        FGA      eFG%   SEASON  \n",
      "0    0.000000   2.428571  0.613445  2023-24  \n",
      "1    1.000000   4.916667  0.542373  2023-24  \n",
      "2    0.076923   1.846154  0.618056  2023-24  \n",
      "3    1.588235  12.058824  0.486585  2023-24  \n",
      "4    1.817073   7.707317  0.567247  2023-24  \n",
      "..        ...        ...       ...      ...  \n",
      "652  2.040000   9.520000  0.577731  2023-24  \n",
      "653  1.487500  17.587500  0.497157  2023-24  \n",
      "654  1.220339   3.491525  0.563107  2023-24  \n",
      "655  0.536232   3.579710  0.540486  2023-24  \n",
      "656  0.388889   1.666667  0.450000  2023-24  \n",
      "\n",
      "[657 rows x 16 columns]\n",
      "\n",
      "Predictions DataFrame (first few rows):\n",
      "   Season Position   Age Team        TeamID  Years of Service   3P%   2P%  \\\n",
      "0    2023    Guard  24.0  MIL  1.610613e+09               1.0  0.41  0.52   \n",
      "1    2023  Forward  20.0  ATL  1.610613e+09               1.0  0.26  0.35   \n",
      "2    2023    Guard  23.0  DAL  1.610613e+09               1.0  0.26  0.58   \n",
      "3    2023  Forward  28.0  DEN  1.610613e+09               9.0  0.29  0.62   \n",
      "4    2023    Guard  27.0  HOU  1.610613e+09               5.0  0.39  0.51   \n",
      "\n",
      "   eFG%   FT%  ...      WSPG     DWSPG     OWSPG      PFPG      ORPG  \\\n",
      "0  0.60  0.89  ...  0.019643  0.005357  0.012500  0.875000  0.160714   \n",
      "1  0.37  1.00  ... -0.020000  0.000000 -0.020000  0.300000  0.100000   \n",
      "2  0.50  0.65  ...  0.004762  0.007143  0.000000  0.523810  0.333333   \n",
      "3  0.58  0.66  ...  0.097260  0.035616  0.061644  1.945205  2.383562   \n",
      "4  0.55  0.92  ...  0.032051  0.015385  0.016667  1.602564  0.294872   \n",
      "\n",
      "       DRPG  RF_Predictions  XGB_Predictions  Predicted_Salary         Player  \n",
      "0  0.982143        0.010495         0.011069          0.010782       AJ Green  \n",
      "1  0.800000        0.010952         0.007285          0.009119     AJ Griffin  \n",
      "2  0.857143        0.009151         0.008311          0.008731      AJ Lawson  \n",
      "3  4.068493        0.168832         0.169603          0.169218   Aaron Gordon  \n",
      "4  1.282051        0.038270         0.033122          0.035696  Aaron Holiday  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "\n",
      "Team Data Before Trade:\n",
      "    PLAYER_ID          PLAYER_NAME     TEAM_ID           TEAM_NAME        PTS  \\\n",
      "56       2544         LeBron James  1610612747  Los Angeles Lakers  25.661972   \n",
      "57     203076        Anthony Davis  1610612747  Los Angeles Lakers  24.684211   \n",
      "58     203915    Spencer Dinwiddie  1610612747  Los Angeles Lakers   6.821429   \n",
      "59    1626156     D'Angelo Russell  1610612747  Los Angeles Lakers  18.013158   \n",
      "60    1626174       Christian Wood  1610612747  Los Angeles Lakers   6.940000   \n",
      "61    1627752       Taurean Prince  1610612747  Los Angeles Lakers   8.935897   \n",
      "62    1628385      Harry Giles III  1610612747  Los Angeles Lakers   0.285714   \n",
      "63    1629020    Jarred Vanderbilt  1610612747  Los Angeles Lakers   5.172414   \n",
      "64    1629060        Rui Hachimura  1610612747  Los Angeles Lakers  13.573529   \n",
      "65    1629216         Gabe Vincent  1610612747  Los Angeles Lakers   3.090909   \n",
      "66    1629629          Cam Reddish  1610612747  Los Angeles Lakers   5.416667   \n",
      "67    1629637         Jaxson Hayes  1610612747  Los Angeles Lakers   4.328571   \n",
      "68    1629685        Dylan Windler  1610612747  Los Angeles Lakers   1.500000   \n",
      "69    1630219          Skylar Mays  1610612747  Los Angeles Lakers   1.294118   \n",
      "70    1630559        Austin Reaves  1610612747  Los Angeles Lakers  15.853659   \n",
      "71    1630658      Colin Castleton  1610612747  Los Angeles Lakers   1.500000   \n",
      "72    1631108         Max Christie  1610612747  Los Angeles Lakers   4.238806   \n",
      "73    1641720  Jalen Hood-Schifino  1610612747  Los Angeles Lakers   1.619048   \n",
      "74    1641721        Maxwell Lewis  1610612747  Los Angeles Lakers   0.323529   \n",
      "75    1641788           Alex Fudge  1610612747  Los Angeles Lakers   1.000000   \n",
      "76    1641793          D'Moi Hodge  1610612747  Los Angeles Lakers   2.000000   \n",
      "351    201143           Al Horford  1610612738      Boston Celtics   8.646154   \n",
      "352    201950         Jrue Holiday  1610612738      Boston Celtics  12.463768   \n",
      "353    204001   Kristaps Porzingis  1610612738      Boston Celtics  20.087719   \n",
      "354   1627759         Jaylen Brown  1610612738      Boston Celtics  23.000000   \n",
      "355   1628369         Jayson Tatum  1610612738      Boston Celtics  26.851351   \n",
      "356   1628401        Derrick White  1610612738      Boston Celtics  15.164384   \n",
      "357   1628436          Luke Kornet  1610612738      Boston Celtics   5.301587   \n",
      "358   1629004       Svi Mykhailiuk  1610612738      Boston Celtics   3.951220   \n",
      "359   1629052       Oshae Brissett  1610612738      Boston Celtics   3.654545   \n",
      "360   1629674        Neemias Queta  1610612738      Boston Celtics   5.500000   \n",
      "361   1630202     Payton Pritchard  1610612738      Boston Celtics   9.597561   \n",
      "362   1630205        Lamar Stevens  1610612738      Boston Celtics   2.789474   \n",
      "363   1630214       Xavier Tillman  1610612738      Boston Celtics   4.000000   \n",
      "364   1630531       Jaden Springer  1610612738      Boston Celtics   2.058824   \n",
      "365   1630573           Sam Hauser  1610612738      Boston Celtics   9.012658   \n",
      "366   1630625        Dalano Banton  1610612738      Boston Celtics   2.333333   \n",
      "367   1631120           JD Davison  1610612738      Boston Celtics   2.000000   \n",
      "368   1641775         Jordan Walsh  1610612738      Boston Celtics   1.666667   \n",
      "369   1641809        Drew Peterson  1610612738      Boston Celtics   3.666667   \n",
      "\n",
      "          AST       TOV       STL       BLK      OREB      DREB       FGM  \\\n",
      "56   8.295775  3.450704  1.253521  0.535211  0.859155  6.436620  9.647887   \n",
      "57   3.500000  2.092105  1.197368  2.342105  3.144737  9.500000  9.381579   \n",
      "58   2.428571  1.035714  0.464286  0.464286  0.142857  1.535714  2.000000   \n",
      "59   6.342105  2.052632  0.907895  0.473684  0.368421  2.736842  6.473684   \n",
      "60   0.980000  1.000000  0.320000  0.660000  0.780000  4.300000  2.460000   \n",
      "61   1.525641  0.935897  0.743590  0.448718  0.269231  2.679487  3.243590   \n",
      "62   0.000000  0.000000  0.142857  0.000000  0.000000  0.571429  0.142857   \n",
      "63   1.241379  0.965517  1.241379  0.172414  1.413793  3.344828  2.034483   \n",
      "64   1.191176  0.676471  0.602941  0.367647  0.852941  3.470588  5.338235   \n",
      "65   1.909091  0.454545  0.818182  0.000000  0.363636  0.454545  1.363636   \n",
      "66   1.000000  0.645833  0.979167  0.291667  0.562500  1.500000  1.895833   \n",
      "67   0.471429  0.614286  0.485714  0.414286  0.985714  2.028571  1.800000   \n",
      "68   0.750000  0.000000  0.000000  0.000000  0.000000  0.375000  0.500000   \n",
      "69   0.588235  0.117647  0.411765  0.058824  0.058824  0.294118  0.588235   \n",
      "70   5.487805  2.121951  0.804878  0.304878  0.695122  3.597561  5.573171   \n",
      "71   0.187500  0.187500  0.125000  0.000000  0.375000  0.375000  0.562500   \n",
      "72   0.895522  0.522388  0.298507  0.253731  0.223881  1.895522  1.537313   \n",
      "73   0.380952  0.428571  0.142857  0.095238  0.095238  0.523810  0.476190   \n",
      "74   0.176471  0.294118  0.058824  0.029412  0.058824  0.058824  0.117647   \n",
      "75   0.000000  0.250000  0.000000  0.000000  0.500000  0.000000  0.250000   \n",
      "76   0.714286  0.142857  0.142857  0.142857  0.000000  0.000000  0.714286   \n",
      "351  2.584615  0.738462  0.584615  0.953846  1.261538  5.092308  3.292308   \n",
      "352  4.826087  1.797101  0.884058  0.768116  1.217391  4.188406  4.797101   \n",
      "353  2.017544  1.561404  0.736842  1.947368  1.701754  5.473684  6.807018   \n",
      "354  3.557143  2.371429  1.185714  0.528571  1.200000  4.328571  8.957143   \n",
      "355  4.918919  2.540541  1.013514  0.581081  0.905405  7.216216  9.081081   \n",
      "356  5.164384  1.534247  1.013699  1.191781  0.698630  3.547945  5.301370   \n",
      "357  1.063492  0.333333  0.365079  0.968254  1.873016  2.269841  2.253968   \n",
      "358  0.853659  0.292683  0.268293  0.024390  0.268293  0.975610  1.390244   \n",
      "359  0.800000  0.363636  0.345455  0.145455  1.109091  1.800000  1.236364   \n",
      "360  0.714286  0.464286  0.464286  0.750000  1.892857  2.464286  2.392857   \n",
      "361  3.426829  0.743902  0.475610  0.073171  0.853659  2.378049  3.621951   \n",
      "362  0.421053  0.473684  0.315789  0.263158  0.631579  1.000000  1.105263   \n",
      "363  1.000000  0.250000  0.450000  0.450000  0.700000  2.000000  1.700000   \n",
      "364  0.529412  0.470588  0.647059  0.235294  0.470588  0.705882  0.764706   \n",
      "365  1.037975  0.405063  0.506329  0.316456  0.569620  2.924051  3.151899   \n",
      "366  0.791667  0.416667  0.208333  0.125000  0.500000  0.958333  0.791667   \n",
      "367  1.250000  0.250000  0.125000  0.125000  0.250000  1.000000  0.625000   \n",
      "368  0.555556  0.333333  0.555556  0.111111  0.555556  1.666667  0.666667   \n",
      "369  0.333333  0.333333  0.666667  0.000000  0.000000  0.333333  1.333333   \n",
      "\n",
      "         FG3M        FGA      eFG%   SEASON  \n",
      "56   2.098592  17.873239  0.598503  2023-24  \n",
      "57   0.381579  16.881579  0.567030  2023-24  \n",
      "58   1.250000   5.035714  0.521277  2023-24  \n",
      "59   2.973684  14.210526  0.560185  2023-24  \n",
      "60   0.700000   5.280000  0.532197  2023-24  \n",
      "61   1.807692   7.333333  0.565559  2023-24  \n",
      "62   0.000000   0.857143  0.166667  2023-24  \n",
      "63   0.275862   3.931034  0.552632  2023-24  \n",
      "64   1.441176   9.941176  0.609467  2023-24  \n",
      "65   0.272727   4.454545  0.336735  2023-24  \n",
      "66   0.770833   4.875000  0.467949  2023-24  \n",
      "67   0.000000   2.500000  0.720000  2023-24  \n",
      "68   0.500000   1.125000  0.666667  2023-24  \n",
      "69   0.117647   1.235294  0.523810  2023-24  \n",
      "70   1.878049  11.463415  0.568085  2023-24  \n",
      "71   0.000000   1.000000  0.562500  2023-24  \n",
      "72   0.626866   3.597015  0.514523  2023-24  \n",
      "73   0.095238   2.142857  0.244444  2023-24  \n",
      "74   0.029412   0.617647  0.214286  2023-24  \n",
      "75   0.000000   1.500000  0.166667  2023-24  \n",
      "76   0.428571   2.142857  0.433333  2023-24  \n",
      "351  1.661538   6.446154  0.639618  2023-24  \n",
      "352  2.000000   9.985507  0.580552  2023-24  \n",
      "353  1.929825  13.192982  0.589096  2023-24  \n",
      "354  2.071429  17.942857  0.556927  2023-24  \n",
      "355  3.094595  19.270270  0.551543  2023-24  \n",
      "356  2.684932  11.493151  0.578069  2023-24  \n",
      "357  0.015873   3.222222  0.701970  2023-24  \n",
      "358  1.024390   3.341463  0.569343  2023-24  \n",
      "359  0.272727   2.781818  0.493464  2023-24  \n",
      "360  0.000000   3.714286  0.644231  2023-24  \n",
      "361  1.792683   7.743902  0.583465  2023-24  \n",
      "362  0.157895   2.368421  0.500000  2023-24  \n",
      "363  0.400000   3.300000  0.575758  2023-24  \n",
      "364  0.117647   1.764706  0.466667  2023-24  \n",
      "365  2.493671   7.063291  0.622760  2023-24  \n",
      "366  0.083333   2.125000  0.392157  2023-24  \n",
      "367  0.375000   1.500000  0.541667  2023-24  \n",
      "368  0.222222   1.666667  0.466667  2023-24  \n",
      "369  1.000000   2.000000  0.916667  2023-24  \n",
      "\n",
      "Team Data After Trade:\n",
      "    PLAYER_ID          PLAYER_NAME     TEAM_ID           TEAM_NAME        PTS  \\\n",
      "56       2544         LeBron James  1610612747  Los Angeles Lakers  25.661972   \n",
      "58     203915    Spencer Dinwiddie  1610612747  Los Angeles Lakers   6.821429   \n",
      "59    1626156     D'Angelo Russell  1610612747  Los Angeles Lakers  18.013158   \n",
      "60    1626174       Christian Wood  1610612747  Los Angeles Lakers   6.940000   \n",
      "61    1627752       Taurean Prince  1610612747  Los Angeles Lakers   8.935897   \n",
      "62    1628385      Harry Giles III  1610612747  Los Angeles Lakers   0.285714   \n",
      "63    1629020    Jarred Vanderbilt  1610612747  Los Angeles Lakers   5.172414   \n",
      "64    1629060        Rui Hachimura  1610612747  Los Angeles Lakers  13.573529   \n",
      "65    1629216         Gabe Vincent  1610612747  Los Angeles Lakers   3.090909   \n",
      "66    1629629          Cam Reddish  1610612747  Los Angeles Lakers   5.416667   \n",
      "67    1629637         Jaxson Hayes  1610612747  Los Angeles Lakers   4.328571   \n",
      "68    1629685        Dylan Windler  1610612747  Los Angeles Lakers   1.500000   \n",
      "69    1630219          Skylar Mays  1610612747  Los Angeles Lakers   1.294118   \n",
      "70    1630559        Austin Reaves  1610612747  Los Angeles Lakers  15.853659   \n",
      "71    1630658      Colin Castleton  1610612747  Los Angeles Lakers   1.500000   \n",
      "72    1631108         Max Christie  1610612747  Los Angeles Lakers   4.238806   \n",
      "73    1641720  Jalen Hood-Schifino  1610612747  Los Angeles Lakers   1.619048   \n",
      "74    1641721        Maxwell Lewis  1610612747  Los Angeles Lakers   0.323529   \n",
      "75    1641788           Alex Fudge  1610612747  Los Angeles Lakers   1.000000   \n",
      "76    1641793          D'Moi Hodge  1610612747  Los Angeles Lakers   2.000000   \n",
      "351    201143           Al Horford  1610612738      Boston Celtics   8.646154   \n",
      "352    201950         Jrue Holiday  1610612738      Boston Celtics  12.463768   \n",
      "353    204001   Kristaps Porzingis  1610612738      Boston Celtics  20.087719   \n",
      "354   1627759         Jaylen Brown  1610612738      Boston Celtics  23.000000   \n",
      "356   1628401        Derrick White  1610612738      Boston Celtics  15.164384   \n",
      "357   1628436          Luke Kornet  1610612738      Boston Celtics   5.301587   \n",
      "358   1629004       Svi Mykhailiuk  1610612738      Boston Celtics   3.951220   \n",
      "359   1629052       Oshae Brissett  1610612738      Boston Celtics   3.654545   \n",
      "360   1629674        Neemias Queta  1610612738      Boston Celtics   5.500000   \n",
      "361   1630202     Payton Pritchard  1610612738      Boston Celtics   9.597561   \n",
      "362   1630205        Lamar Stevens  1610612738      Boston Celtics   2.789474   \n",
      "363   1630214       Xavier Tillman  1610612738      Boston Celtics   4.000000   \n",
      "364   1630531       Jaden Springer  1610612738      Boston Celtics   2.058824   \n",
      "365   1630573           Sam Hauser  1610612738      Boston Celtics   9.012658   \n",
      "366   1630625        Dalano Banton  1610612738      Boston Celtics   2.333333   \n",
      "367   1631120           JD Davison  1610612738      Boston Celtics   2.000000   \n",
      "368   1641775         Jordan Walsh  1610612738      Boston Celtics   1.666667   \n",
      "369   1641809        Drew Peterson  1610612738      Boston Celtics   3.666667   \n",
      "57     203076        Anthony Davis  1610612747  Los Angeles Lakers  24.684211   \n",
      "\n",
      "          AST       TOV       STL       BLK      OREB      DREB       FGM  \\\n",
      "56   8.295775  3.450704  1.253521  0.535211  0.859155  6.436620  9.647887   \n",
      "58   2.428571  1.035714  0.464286  0.464286  0.142857  1.535714  2.000000   \n",
      "59   6.342105  2.052632  0.907895  0.473684  0.368421  2.736842  6.473684   \n",
      "60   0.980000  1.000000  0.320000  0.660000  0.780000  4.300000  2.460000   \n",
      "61   1.525641  0.935897  0.743590  0.448718  0.269231  2.679487  3.243590   \n",
      "62   0.000000  0.000000  0.142857  0.000000  0.000000  0.571429  0.142857   \n",
      "63   1.241379  0.965517  1.241379  0.172414  1.413793  3.344828  2.034483   \n",
      "64   1.191176  0.676471  0.602941  0.367647  0.852941  3.470588  5.338235   \n",
      "65   1.909091  0.454545  0.818182  0.000000  0.363636  0.454545  1.363636   \n",
      "66   1.000000  0.645833  0.979167  0.291667  0.562500  1.500000  1.895833   \n",
      "67   0.471429  0.614286  0.485714  0.414286  0.985714  2.028571  1.800000   \n",
      "68   0.750000  0.000000  0.000000  0.000000  0.000000  0.375000  0.500000   \n",
      "69   0.588235  0.117647  0.411765  0.058824  0.058824  0.294118  0.588235   \n",
      "70   5.487805  2.121951  0.804878  0.304878  0.695122  3.597561  5.573171   \n",
      "71   0.187500  0.187500  0.125000  0.000000  0.375000  0.375000  0.562500   \n",
      "72   0.895522  0.522388  0.298507  0.253731  0.223881  1.895522  1.537313   \n",
      "73   0.380952  0.428571  0.142857  0.095238  0.095238  0.523810  0.476190   \n",
      "74   0.176471  0.294118  0.058824  0.029412  0.058824  0.058824  0.117647   \n",
      "75   0.000000  0.250000  0.000000  0.000000  0.500000  0.000000  0.250000   \n",
      "76   0.714286  0.142857  0.142857  0.142857  0.000000  0.000000  0.714286   \n",
      "351  2.584615  0.738462  0.584615  0.953846  1.261538  5.092308  3.292308   \n",
      "352  4.826087  1.797101  0.884058  0.768116  1.217391  4.188406  4.797101   \n",
      "353  2.017544  1.561404  0.736842  1.947368  1.701754  5.473684  6.807018   \n",
      "354  3.557143  2.371429  1.185714  0.528571  1.200000  4.328571  8.957143   \n",
      "356  5.164384  1.534247  1.013699  1.191781  0.698630  3.547945  5.301370   \n",
      "357  1.063492  0.333333  0.365079  0.968254  1.873016  2.269841  2.253968   \n",
      "358  0.853659  0.292683  0.268293  0.024390  0.268293  0.975610  1.390244   \n",
      "359  0.800000  0.363636  0.345455  0.145455  1.109091  1.800000  1.236364   \n",
      "360  0.714286  0.464286  0.464286  0.750000  1.892857  2.464286  2.392857   \n",
      "361  3.426829  0.743902  0.475610  0.073171  0.853659  2.378049  3.621951   \n",
      "362  0.421053  0.473684  0.315789  0.263158  0.631579  1.000000  1.105263   \n",
      "363  1.000000  0.250000  0.450000  0.450000  0.700000  2.000000  1.700000   \n",
      "364  0.529412  0.470588  0.647059  0.235294  0.470588  0.705882  0.764706   \n",
      "365  1.037975  0.405063  0.506329  0.316456  0.569620  2.924051  3.151899   \n",
      "366  0.791667  0.416667  0.208333  0.125000  0.500000  0.958333  0.791667   \n",
      "367  1.250000  0.250000  0.125000  0.125000  0.250000  1.000000  0.625000   \n",
      "368  0.555556  0.333333  0.555556  0.111111  0.555556  1.666667  0.666667   \n",
      "369  0.333333  0.333333  0.666667  0.000000  0.000000  0.333333  1.333333   \n",
      "57   3.500000  2.092105  1.197368  2.342105  3.144737  9.500000  9.381579   \n",
      "\n",
      "         FG3M        FGA      eFG%   SEASON  \n",
      "56   2.098592  17.873239  0.598503  2023-24  \n",
      "58   1.250000   5.035714  0.521277  2023-24  \n",
      "59   2.973684  14.210526  0.560185  2023-24  \n",
      "60   0.700000   5.280000  0.532197  2023-24  \n",
      "61   1.807692   7.333333  0.565559  2023-24  \n",
      "62   0.000000   0.857143  0.166667  2023-24  \n",
      "63   0.275862   3.931034  0.552632  2023-24  \n",
      "64   1.441176   9.941176  0.609467  2023-24  \n",
      "65   0.272727   4.454545  0.336735  2023-24  \n",
      "66   0.770833   4.875000  0.467949  2023-24  \n",
      "67   0.000000   2.500000  0.720000  2023-24  \n",
      "68   0.500000   1.125000  0.666667  2023-24  \n",
      "69   0.117647   1.235294  0.523810  2023-24  \n",
      "70   1.878049  11.463415  0.568085  2023-24  \n",
      "71   0.000000   1.000000  0.562500  2023-24  \n",
      "72   0.626866   3.597015  0.514523  2023-24  \n",
      "73   0.095238   2.142857  0.244444  2023-24  \n",
      "74   0.029412   0.617647  0.214286  2023-24  \n",
      "75   0.000000   1.500000  0.166667  2023-24  \n",
      "76   0.428571   2.142857  0.433333  2023-24  \n",
      "351  1.661538   6.446154  0.639618  2023-24  \n",
      "352  2.000000   9.985507  0.580552  2023-24  \n",
      "353  1.929825  13.192982  0.589096  2023-24  \n",
      "354  2.071429  17.942857  0.556927  2023-24  \n",
      "356  2.684932  11.493151  0.578069  2023-24  \n",
      "357  0.015873   3.222222  0.701970  2023-24  \n",
      "358  1.024390   3.341463  0.569343  2023-24  \n",
      "359  0.272727   2.781818  0.493464  2023-24  \n",
      "360  0.000000   3.714286  0.644231  2023-24  \n",
      "361  1.792683   7.743902  0.583465  2023-24  \n",
      "362  0.157895   2.368421  0.500000  2023-24  \n",
      "363  0.400000   3.300000  0.575758  2023-24  \n",
      "364  0.117647   1.764706  0.466667  2023-24  \n",
      "365  2.493671   7.063291  0.622760  2023-24  \n",
      "366  0.083333   2.125000  0.392157  2023-24  \n",
      "367  0.375000   1.500000  0.541667  2023-24  \n",
      "368  0.222222   1.666667  0.466667  2023-24  \n",
      "369  1.000000   2.000000  0.916667  2023-24  \n",
      "57   0.381579  16.881579  0.567030  2023-24  \n",
      "\n",
      "Trade Impact (Difference in Team Stats):\n",
      "            TEAM_NAME        PTS       AST           TOV       STL  \\\n",
      "0      Boston Celtics -26.851351 -4.918919 -2.540541e+00 -1.013514   \n",
      "1  Los Angeles Lakers   0.000000  0.000000  3.552714e-15  0.000000   \n",
      "\n",
      "            BLK      OREB      DREB       FGM      FG3M       FGA      eFG%  \n",
      "0 -5.810811e-01 -0.905405 -7.216216 -9.081081 -3.094595 -19.27027 -0.551543  \n",
      "1 -8.881784e-16  0.000000  0.000000  0.000000  0.000000   0.00000  0.000000  \n",
      "\n",
      "Traded Players vs. Champions Average:\n",
      "\n",
      "Anthony Davis:\n",
      "PTS: 24.68 (Diff from Champs Avg: 15.92)\n",
      "AST: 3.50 (Diff from Champs Avg: 1.44)\n",
      "TOV: 2.09 (Diff from Champs Avg: 1.12)\n",
      "STL: 1.20 (Diff from Champs Avg: 0.63)\n",
      "BLK: 2.34 (Diff from Champs Avg: 1.91)\n",
      "OREB: 3.14 (Diff from Champs Avg: 2.30)\n",
      "DREB: 9.50 (Diff from Champs Avg: 6.86)\n",
      "FGM: 9.38 (Diff from Champs Avg: 6.12)\n",
      "FG3M: 0.38 (Diff from Champs Avg: -0.65)\n",
      "FGA: 16.88 (Diff from Champs Avg: 10.26)\n",
      "eFG%: 0.57 (Diff from Champs Avg: 0.00)\n",
      "\n",
      "Jayson Tatum:\n",
      "PTS: 26.85 (Diff from Champs Avg: 18.09)\n",
      "AST: 4.92 (Diff from Champs Avg: 2.86)\n",
      "TOV: 2.54 (Diff from Champs Avg: 1.57)\n",
      "STL: 1.01 (Diff from Champs Avg: 0.44)\n",
      "BLK: 0.58 (Diff from Champs Avg: 0.14)\n",
      "OREB: 0.91 (Diff from Champs Avg: 0.06)\n",
      "DREB: 7.22 (Diff from Champs Avg: 4.57)\n",
      "FGM: 9.08 (Diff from Champs Avg: 5.82)\n",
      "FG3M: 3.09 (Diff from Champs Avg: 2.06)\n",
      "FGA: 19.27 (Diff from Champs Avg: 12.64)\n",
      "eFG%: 0.55 (Diff from Champs Avg: -0.01)\n",
      "\n",
      "Salary Analysis for Traded Players:\n",
      "            Player      Salary  Predicted_Salary\n",
      "23   Anthony Davis  40600080.0          0.305131\n",
      "220   Jayson Tatum  32600060.0          0.237452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_684/2093214280.py:161: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat(all_current_players, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nba_api.stats.endpoints import leaguegamefinder, playergamelogs\n",
    "import time\n",
    "\n",
    "RELEVANT_STATS = ['PTS', 'AST', 'TOV', 'STL', 'BLK', 'OREB', 'DREB', 'FGM', 'FG3M', 'FGA']\n",
    "PERCENTILE_THRESHOLDS = [99, 98, 97, 96, 95, 90, 75, 50]\n",
    "\n",
    "def get_champion(season):\n",
    "    games = leaguegamefinder.LeagueGameFinder(season_nullable=season, season_type_nullable='Playoffs').get_data_frames()[0]\n",
    "    games['GAME_DATE'] = pd.to_datetime(games['GAME_DATE'])\n",
    "    last_game = games.sort_values('GAME_DATE').iloc[-2:]\n",
    "    winner = last_game[last_game['WL'] == 'W'].iloc[0]\n",
    "    return winner['TEAM_ID'], winner['TEAM_NAME']\n",
    "\n",
    "def get_champions(start_year, end_year):\n",
    "    champions = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        champ_id, champ_name = get_champion(season)\n",
    "        champions[season] = {'ChampionTeamID': champ_id, 'ChampionTeamName': champ_name}\n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    return champions\n",
    "\n",
    "def get_season_from_date(date):\n",
    "    year = int(date[:4])\n",
    "    month = int(date[5:7])\n",
    "    if month >= 10:\n",
    "        return f\"{year}-{str(year+1)[2:]}\"\n",
    "    else:\n",
    "        return f\"{year-1}-{str(year)[2:]}\"\n",
    "\n",
    "def analyze_leaguegamefinder_endpoint(start_season, end_season):\n",
    "    all_seasons_data = []\n",
    "    \n",
    "    for season in range(int(start_season[:4]), int(end_season[:4]) + 1):\n",
    "        season_str = f\"{season}-{str(season+1)[2:]}\"\n",
    "        print(f\"Fetching data for season {season_str}\")\n",
    "        \n",
    "        games = leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season_str,\n",
    "            season_type_nullable='Regular Season'\n",
    "        ).get_data_frames()[0]\n",
    "        \n",
    "        games['SEASON'] = games['GAME_DATE'].apply(get_season_from_date)\n",
    "        all_seasons_data.append(games)\n",
    "        \n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    \n",
    "    return pd.concat(all_seasons_data, ignore_index=True)\n",
    "\n",
    "def calculate_per_game_stats(games_df):\n",
    "    per_game_stats = games_df.groupby(['SEASON', 'TEAM_ID', 'TEAM_NAME'])[RELEVANT_STATS].mean().reset_index()\n",
    "    \n",
    "    # Calculate eFG%\n",
    "    per_game_stats['eFG%'] = (per_game_stats['FGM'] + 0.5 * per_game_stats['FG3M']) / per_game_stats['FGA']\n",
    "    \n",
    "    return per_game_stats\n",
    "\n",
    "def calculate_percentiles(stats_df):\n",
    "    percentile_cols = RELEVANT_STATS + ['eFG%']\n",
    "    \n",
    "    for col in percentile_cols:\n",
    "        stats_df[f'{col}_percentile'] = stats_df.groupby('SEASON')[col].rank(pct=True)\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "def get_current_season_stats(all_seasons_data, current_season):\n",
    "    current_season_data = all_seasons_data[all_seasons_data['SEASON'] == current_season]\n",
    "    per_game_stats = calculate_per_game_stats(current_season_data)\n",
    "    percentile_stats = calculate_percentiles(per_game_stats)\n",
    "    \n",
    "    # Calculate league average\n",
    "    league_avg = per_game_stats[RELEVANT_STATS + ['eFG%']].mean()\n",
    "    league_avg['TEAM_NAME'] = 'League Average'\n",
    "    league_avg['SEASON'] = current_season\n",
    "    league_avg['TEAM_ID'] = 'AVG'\n",
    "    league_avg = pd.DataFrame(league_avg).transpose()\n",
    "    \n",
    "    # Combine team stats with league average\n",
    "    combined_stats = pd.concat([percentile_stats, league_avg], ignore_index=True)\n",
    "    return combined_stats\n",
    "\n",
    "def get_champions_stats(all_seasons_data, start_season, end_season):\n",
    "    champions = {}\n",
    "    for year in range(int(start_season[:4]), int(end_season[:4]) + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        champ_id, champ_name = get_champion(season)\n",
    "        champions[season] = {'ChampionTeamID': champ_id, 'ChampionTeamName': champ_name}\n",
    "    \n",
    "    champions_data = all_seasons_data[all_seasons_data.apply(lambda row: row['TEAM_ID'] == champions.get(row['SEASON'], {}).get('ChampionTeamID'), axis=1)]\n",
    "    champions_stats = calculate_per_game_stats(champions_data)\n",
    "    return calculate_percentiles(champions_stats)\n",
    "\n",
    "def compare_stats(current_stats, champions_stats, league_avg):\n",
    "    # Compare current stats to champions average and league average\n",
    "    champs_avg = champions_stats[RELEVANT_STATS + ['eFG%']].mean()\n",
    "    \n",
    "    comparison = current_stats.copy()\n",
    "    for stat in RELEVANT_STATS + ['eFG%']:\n",
    "        comparison[f'{stat}_vs_champs'] = comparison[stat] - champs_avg[stat]\n",
    "        comparison[f'{stat}_vs_league'] = comparison[stat] - league_avg[stat]\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "def get_team_data(all_seasons_data, team_names, current_season):\n",
    "    team_data = all_seasons_data[(all_seasons_data['SEASON'] == current_season) & (all_seasons_data['TEAM_NAME'].isin(team_names))]\n",
    "    return calculate_per_game_stats(team_data)\n",
    "\n",
    "def simulate_trade(all_seasons_data, team_from, team_to, trade_impact, current_season):\n",
    "    before_trade = get_team_data(all_seasons_data, [team_from, team_to], current_season)\n",
    "    \n",
    "    # Simulate the trade by adjusting team stats\n",
    "    after_trade = before_trade.copy()\n",
    "    numeric_columns = before_trade.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for stat in numeric_columns:\n",
    "        if stat in trade_impact:\n",
    "            after_trade.loc[after_trade['TEAM_NAME'] == team_from, stat] -= trade_impact[stat]\n",
    "            after_trade.loc[after_trade['TEAM_NAME'] == team_to, stat] += trade_impact[stat]\n",
    "    \n",
    "    # Recalculate eFG% for both teams\n",
    "    for team in [team_from, team_to]:\n",
    "        team_data = after_trade[after_trade['TEAM_NAME'] == team]\n",
    "        after_trade.loc[after_trade['TEAM_NAME'] == team, 'eFG%'] = (\n",
    "            (team_data['FGM'] + 0.5 * team_data['FG3M']) / team_data['FGA']\n",
    "        ).values[0]\n",
    "    \n",
    "    return before_trade, after_trade\n",
    "\n",
    "def get_player_game_logs(team_id, season):\n",
    "    player_logs = playergamelogs.PlayerGameLogs(team_id_nullable=team_id, season_nullable=season).get_data_frames()[0]\n",
    "    return player_logs\n",
    "\n",
    "def process_player_data(player_logs):\n",
    "    player_stats = player_logs.groupby(['PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID', 'TEAM_NAME'])[RELEVANT_STATS].mean().reset_index()\n",
    "    player_stats['eFG%'] = (player_stats['FGM'] + 0.5 * player_stats['FG3M']) / player_stats['FGA']\n",
    "    return player_stats\n",
    "\n",
    "def get_champions_player_data(champions, start_season, end_season):\n",
    "    all_champion_players = []\n",
    "    for season in range(int(start_season[:4]), int(end_season[:4]) + 1):\n",
    "        season_str = f\"{season}-{str(season+1)[2:]}\"\n",
    "        champ_id = champions[season_str]['ChampionTeamID']\n",
    "        player_logs = get_player_game_logs(champ_id, season_str)\n",
    "        player_stats = process_player_data(player_logs)\n",
    "        player_stats['SEASON'] = season_str\n",
    "        all_champion_players.append(player_stats)\n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    return pd.concat(all_champion_players, ignore_index=True)\n",
    "\n",
    "def get_current_season_player_data(all_seasons_data, current_season):\n",
    "    current_teams = all_seasons_data[all_seasons_data['SEASON'] == current_season]['TEAM_ID'].unique()\n",
    "    all_current_players = []\n",
    "    for team_id in current_teams:\n",
    "        player_logs = get_player_game_logs(team_id, current_season)\n",
    "        player_stats = process_player_data(player_logs)\n",
    "        player_stats['SEASON'] = current_season\n",
    "        all_current_players.append(player_stats)\n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    return pd.concat(all_current_players, ignore_index=True)\n",
    "\n",
    "def simulate_trade_with_players(team_from_data, team_to_data, traded_players):\n",
    "    before_trade = pd.concat([team_from_data, team_to_data])\n",
    "    \n",
    "    # Move traded players between teams\n",
    "    traded_from = team_from_data[team_from_data['PLAYER_NAME'].isin(traded_players)].copy()\n",
    "    traded_to = team_to_data[team_to_data['PLAYER_NAME'].isin(traded_players)].copy()\n",
    "    \n",
    "    team_from_after = team_from_data[~team_from_data['PLAYER_NAME'].isin(traded_players)]\n",
    "    team_to_after = pd.concat([team_to_data[~team_to_data['PLAYER_NAME'].isin(traded_players)], traded_from])\n",
    "    \n",
    "    after_trade = pd.concat([team_from_after, team_to_after])\n",
    "    \n",
    "    return before_trade, after_trade\n",
    "\n",
    "def analyze_trade_impact(before_trade, after_trade):\n",
    "    team_totals_before = before_trade.groupby('TEAM_NAME')[RELEVANT_STATS + ['eFG%']].sum().reset_index()\n",
    "    team_totals_after = after_trade.groupby('TEAM_NAME')[RELEVANT_STATS + ['eFG%']].sum().reset_index()\n",
    "    \n",
    "    trade_impact = team_totals_after.set_index('TEAM_NAME').subtract(team_totals_before.set_index('TEAM_NAME')).reset_index()\n",
    "    return trade_impact\n",
    "\n",
    "def main():\n",
    "    start_season = \"2022-23\"\n",
    "    end_season = \"2023-24\"\n",
    "    current_season = end_season\n",
    "    all_seasons_data = analyze_leaguegamefinder_endpoint(start_season, end_season)\n",
    "    \n",
    "    # 1. Get champions for the past 10 seasons\n",
    "    champions = get_champions(int(start_season[:4]), int(end_season[:4]))\n",
    "    \n",
    "    # 2. Get player-level data for champions\n",
    "    champions_player_data = get_champions_player_data(champions, start_season, end_season)\n",
    "    print(\"Champions Player Data (Past 10 Seasons):\")\n",
    "    print(champions_player_data)\n",
    "    \n",
    "    # 3. Get current season player-level data\n",
    "    current_season_player_data = get_current_season_player_data(all_seasons_data, current_season)\n",
    "    print(\"\\nCurrent Season Player Data:\")\n",
    "    print(current_season_player_data)\n",
    "    \n",
    "    # 4. Load predictions dataframe\n",
    "    predictions_df = pd.read_csv('../data/processed/predictions_df.csv')\n",
    "    print(\"\\nPredictions DataFrame (first few rows):\")\n",
    "    print(predictions_df.head())\n",
    "    \n",
    "    # 5. Simulate trade\n",
    "    team_from = \"Los Angeles Lakers\"\n",
    "    team_to = \"Boston Celtics\"\n",
    "    traded_players = [\"Anthony Davis\", \"Jayson Tatum\"]  # Example players\n",
    "    \n",
    "    team_from_data = current_season_player_data[current_season_player_data['TEAM_NAME'] == team_from]\n",
    "    team_to_data = current_season_player_data[current_season_player_data['TEAM_NAME'] == team_to]\n",
    "    \n",
    "    print(\"\\nTeam Data Before Trade:\")\n",
    "    print(pd.concat([team_from_data, team_to_data]))\n",
    "    \n",
    "    before_trade, after_trade = simulate_trade_with_players(team_from_data, team_to_data, traded_players)\n",
    "    \n",
    "    print(\"\\nTeam Data After Trade:\")\n",
    "    print(after_trade)\n",
    "    \n",
    "    # 6. Analyze trade impact\n",
    "    trade_impact = analyze_trade_impact(before_trade, after_trade)\n",
    "    print(\"\\nTrade Impact (Difference in Team Stats):\")\n",
    "    print(trade_impact)\n",
    "    \n",
    "    # 7. Compare traded players to champions\n",
    "    traded_player_stats = before_trade[before_trade['PLAYER_NAME'].isin(traded_players)]\n",
    "    champion_avg = champions_player_data.groupby('SEASON')[RELEVANT_STATS + ['eFG%']].mean().mean()\n",
    "    \n",
    "    print(\"\\nTraded Players vs. Champions Average:\")\n",
    "    for _, player in traded_player_stats.iterrows():\n",
    "        print(f\"\\n{player['PLAYER_NAME']}:\")\n",
    "        for stat in RELEVANT_STATS + ['eFG%']:\n",
    "            diff = player[stat] - champion_avg[stat]\n",
    "            print(f\"{stat}: {player[stat]:.2f} (Diff from Champs Avg: {diff:.2f})\")\n",
    "    \n",
    "    # 8. Analyze salary based on predictions\n",
    "    traded_players_salary = predictions_df[predictions_df['Player'].isin(traded_players)]\n",
    "    print(\"\\nSalary Analysis for Traded Players:\")\n",
    "    print(traded_players_salary[['Player', 'Salary', 'Predicted_Salary']])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_predict/updated/trade_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_predict/updated/trade_utils.py\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import time\n",
    "from scipy import stats\n",
    "\n",
    "RELEVANT_STATS = ['PPG', 'APG', 'TPG', 'SPG', 'BPG', 'ORPG', 'DRPG', 'eFG%']\n",
    "PERCENTILE_THRESHOLDS = [99, 98, 97, 96, 95, 90, 75, 50]\n",
    "\n",
    "def get_champion(season):\n",
    "    games = leaguegamefinder.LeagueGameFinder(season_nullable=season, season_type_nullable='Playoffs').get_data_frames()[0]\n",
    "    games['GAME_DATE'] = pd.to_datetime(games['GAME_DATE'])\n",
    "    last_game = games.sort_values('GAME_DATE').iloc[-2:]\n",
    "    winner = last_game[last_game['WL'] == 'W'].iloc[0]\n",
    "    return winner['TEAM_ID'], winner['TEAM_NAME']\n",
    "\n",
    "def get_champions(start_year, end_year):\n",
    "    champions = {}\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        champ_id, champ_name = get_champion(season)\n",
    "        champions[season] = {'ChampionTeamID': champ_id, 'ChampionTeamName': champ_name}\n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    return champions\n",
    "\n",
    "def calculate_team_stats(team_players, all_players):\n",
    "    team_stats = {}\n",
    "    for stat in RELEVANT_STATS:\n",
    "        if stat in team_players.columns:\n",
    "            values = team_players[stat].values\n",
    "            all_values = all_players[stat].values\n",
    "            percentiles = np.percentile(all_values, PERCENTILE_THRESHOLDS)\n",
    "            \n",
    "            team_stats[stat] = {\n",
    "                'mean': np.mean(values) if len(values) > 0 else 0,\n",
    "                'median': np.median(values) if len(values) > 0 else 0,\n",
    "                'max': np.max(values) if len(values) > 0 else 0,\n",
    "                'total': values.tolist(),\n",
    "                'percentile_counts': {\n",
    "                    f'Top {100-p}%': np.sum(values >= percentiles[i])\n",
    "                    for i, p in enumerate(PERCENTILE_THRESHOLDS)\n",
    "                }\n",
    "            }\n",
    "    return team_stats\n",
    "\n",
    "def calculate_champ_stats(champions, num_years=10):\n",
    "    current_year = max(int(season.split('-')[0]) for season in champions.keys())\n",
    "    start_year = current_year - num_years + 1\n",
    "    recent_champions = {k: v for k, v in champions.items() if int(k.split('-')[0]) >= start_year}\n",
    "    \n",
    "    champ_stats = pd.DataFrame()\n",
    "    num_champ_seasons = len(recent_champions)\n",
    "\n",
    "    for season, champ_info in recent_champions.items():\n",
    "        games = leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season,\n",
    "            team_id_nullable=champ_info['ChampionTeamID'],\n",
    "            season_type_nullable='Regular Season'\n",
    "        ).get_data_frames()[0]\n",
    "        \n",
    "        season_stats = pd.DataFrame({\n",
    "            'PPG': [games['PTS'].mean()],\n",
    "            'APG': [games['AST'].mean()],\n",
    "            'TPG': [games['TOV'].mean()],\n",
    "            'SPG': [games['STL'].mean()],\n",
    "            'BPG': [games['BLK'].mean()],\n",
    "            'ORPG': [games['OREB'].mean()],\n",
    "            'DRPG': [games['DREB'].mean()],\n",
    "            'eFG%': [(games['FGM'].sum() + 0.5 * games['FG3M'].sum()) / games['FGA'].sum()]\n",
    "        })\n",
    "        \n",
    "        champ_stats = pd.concat([champ_stats, season_stats], ignore_index=True)\n",
    "    \n",
    "    if champ_stats.empty:\n",
    "        return {stat: {'mean': 0, 'median': 0, 'max': 0, 'percentile_counts': {f'Top {100-p}%': 0 for p in PERCENTILE_THRESHOLDS}} for stat in RELEVANT_STATS}\n",
    "    \n",
    "    champ_percentiles = {}\n",
    "    for stat in RELEVANT_STATS:\n",
    "        if stat in champ_stats.columns:\n",
    "            values = champ_stats[stat]\n",
    "            champ_percentiles[stat] = {\n",
    "                'mean': np.mean(values),\n",
    "                'median': np.median(values),\n",
    "                'max': np.max(values),\n",
    "                'percentile_counts': {\n",
    "                    f'Top {100-p}%': np.sum(values >= np.percentile(values, p)) / num_champ_seasons\n",
    "                    for p in PERCENTILE_THRESHOLDS\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return champ_percentiles\n",
    "\n",
    "def compare_stats(current_stats, simulated_stats, league_stats, champ_stats):\n",
    "    comparison = {}\n",
    "    for stat in RELEVANT_STATS:\n",
    "        if stat in current_stats and stat in league_stats:\n",
    "            current_value = current_stats[stat]['mean']\n",
    "            after_trade_value = simulated_stats[stat]['mean']\n",
    "            league_average = league_stats[stat]['mean']\n",
    "            champ_average = champ_stats[stat]['mean']\n",
    "            \n",
    "            all_league_values = league_stats[stat]['total']\n",
    "            current_percentile = stats.percentileofscore(all_league_values, current_value)\n",
    "            after_trade_percentile = stats.percentileofscore(all_league_values, after_trade_value)\n",
    "            \n",
    "            comparison[stat] = {\n",
    "                'Current': current_value,\n",
    "                'Current Percentile': current_percentile,\n",
    "                'After Trade': after_trade_value,\n",
    "                'After Trade Percentile': after_trade_percentile,\n",
    "                'League Average': league_average,\n",
    "                'Champ Average': champ_average,\n",
    "                'Current vs League': current_value - league_average,\n",
    "                'After Trade vs League': after_trade_value - league_average,\n",
    "                'Current vs Champ': current_value - champ_average,\n",
    "                'After Trade vs Champ': after_trade_value - champ_average,\n",
    "                'Current Percentile Counts': current_stats[stat]['percentile_counts'],\n",
    "                'After Trade Percentile Counts': simulated_stats[stat]['percentile_counts'],\n",
    "                'Champ Percentile Counts': champ_stats[stat]['percentile_counts']\n",
    "            }\n",
    "    return comparison\n",
    "\n",
    "def simulate_trade(team_players, players_leaving, players_joining):\n",
    "    team_after_trade = team_players[~team_players['Player'].isin(players_leaving)].copy()\n",
    "    return pd.concat([team_after_trade, players_joining], ignore_index=True)\n",
    "\n",
    "FIRST_TAX_APRON = 172_346_000\n",
    "\n",
    "def check_salary_matching_rules(outgoing_salary, incoming_salary, team_salary_before_trade):\n",
    "    if team_salary_before_trade < FIRST_TAX_APRON:\n",
    "        if outgoing_salary <= 7_500_000:\n",
    "            max_incoming_salary = 2 * outgoing_salary + 250_000\n",
    "        elif outgoing_salary <= 29_000_000:\n",
    "            max_incoming_salary = outgoing_salary + 7_500_000\n",
    "        else:\n",
    "            max_incoming_salary = 1.25 * outgoing_salary + 250_000\n",
    "    else:\n",
    "        max_incoming_salary = 1.10 * outgoing_salary\n",
    "\n",
    "    return incoming_salary <= max_incoming_salary\n",
    "\n",
    "def analyze_two_team_trade(team1_abbr, team2_abbr, players_leaving_team1, players_leaving_team2, predictions_df, champions):\n",
    "    try:\n",
    "        team1_players = predictions_df[predictions_df['Team'] == team1_abbr]\n",
    "        team2_players = predictions_df[predictions_df['Team'] == team2_abbr]\n",
    "\n",
    "        players_joining_team1 = team2_players[team2_players['Player'].isin(players_leaving_team2)]\n",
    "        players_joining_team2 = team1_players[team1_players['Player'].isin(players_leaving_team1)]\n",
    "\n",
    "        if players_joining_team1.empty or players_joining_team2.empty:\n",
    "            print(\"Could not find one or more of the specified players' stats.\")\n",
    "            return\n",
    "\n",
    "        current_team1_stats = calculate_team_stats(team1_players, predictions_df)\n",
    "        current_team2_stats = calculate_team_stats(team2_players, predictions_df)\n",
    "\n",
    "        team1_after_trade = simulate_trade(team1_players, players_leaving_team1, players_joining_team1)\n",
    "        team2_after_trade = simulate_trade(team2_players, players_leaving_team2, players_joining_team2)\n",
    "\n",
    "        simulated_team1_stats = calculate_team_stats(team1_after_trade, predictions_df)\n",
    "        simulated_team2_stats = calculate_team_stats(team2_after_trade, predictions_df)\n",
    "\n",
    "        league_stats = calculate_team_stats(predictions_df, predictions_df)\n",
    "        champ_stats = calculate_champ_stats(champions)\n",
    "\n",
    "        team1_current_salary = team1_players['Salary'].sum()\n",
    "        team2_current_salary = team2_players['Salary'].sum()\n",
    "        team1_new_salary = team1_after_trade['Salary'].sum()\n",
    "        team2_new_salary = team2_after_trade['Salary'].sum()\n",
    "\n",
    "        outgoing_salary_team1 = team1_players[team1_players['Player'].isin(players_leaving_team1)]['Salary'].sum()\n",
    "        incoming_salary_team1 = players_joining_team1['Salary'].sum()\n",
    "        outgoing_salary_team2 = team2_players[team2_players['Player'].isin(players_leaving_team2)]['Salary'].sum()\n",
    "        incoming_salary_team2 = players_joining_team2['Salary'].sum()\n",
    "\n",
    "        salary_match_team1 = check_salary_matching_rules(outgoing_salary_team1, incoming_salary_team1, team1_current_salary)\n",
    "        salary_match_team2 = check_salary_matching_rules(outgoing_salary_team2, incoming_salary_team2, team2_current_salary)\n",
    "\n",
    "        team1_comparison = compare_stats(current_team1_stats, simulated_team1_stats, league_stats, champ_stats)\n",
    "        team2_comparison = compare_stats(current_team2_stats, simulated_team2_stats, league_stats, champ_stats)\n",
    "\n",
    "        return {\n",
    "            team1_abbr: {\n",
    "                'comparison': team1_comparison,\n",
    "                'current_salary': team1_current_salary,\n",
    "                'new_salary': team1_new_salary,\n",
    "                'salary_match': salary_match_team1\n",
    "            },\n",
    "            team2_abbr: {\n",
    "                'comparison': team2_comparison,\n",
    "                'current_salary': team2_current_salary,\n",
    "                'new_salary': team2_new_salary,\n",
    "                'salary_match': salary_match_team2\n",
    "            }\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analyze_two_team_trade: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_league_stats_from_api(start_year, end_year):\n",
    "    league_stats = {stat: [] for stat in RELEVANT_STATS}\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        games = leaguegamefinder.LeagueGameFinder(\n",
    "            season_nullable=season,\n",
    "            season_type_nullable='Regular Season'\n",
    "        ).get_data_frames()[0]\n",
    "        \n",
    "        team_stats = games.groupby('TEAM_ID').agg({\n",
    "            'PTS': 'mean',\n",
    "            'AST': 'mean',\n",
    "            'TOV': 'mean',\n",
    "            'STL': 'mean',\n",
    "            'BLK': 'mean',\n",
    "            'OREB': 'mean',\n",
    "            'DREB': 'mean',\n",
    "            'FGM': 'sum',\n",
    "            'FG3M': 'sum',\n",
    "            'FGA': 'sum'\n",
    "        })\n",
    "        \n",
    "        team_stats['eFG%'] = (team_stats['FGM'] + 0.5 * team_stats['FG3M']) / team_stats['FGA']\n",
    "        \n",
    "        for stat, api_stat in zip(RELEVANT_STATS, ['PTS', 'AST', 'TOV', 'STL', 'BLK', 'OREB', 'DREB', 'eFG%']):\n",
    "            league_stats[stat].extend(team_stats[api_stat].tolist())\n",
    "        \n",
    "        time.sleep(1)  # To avoid overwhelming the API\n",
    "    \n",
    "    league_percentiles = {}\n",
    "    for stat in RELEVANT_STATS:\n",
    "        values = league_stats[stat]\n",
    "        percentiles = np.percentile(values, PERCENTILE_THRESHOLDS)\n",
    "        league_percentiles[stat] = {\n",
    "            'mean': np.mean(values),\n",
    "            'median': np.median(values),\n",
    "            'max': np.max(values),\n",
    "            'total': values,\n",
    "            'percentile_counts': {\n",
    "                f'Top {100-p}%': np.sum(np.array(values) >= percentiles[i])\n",
    "                for i, p in enumerate(PERCENTILE_THRESHOLDS)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return league_percentiles\n",
    "\n",
    "def identify_overpaid_underpaid(predictions_df):\n",
    "    predictions_df['Salary_Difference'] = predictions_df['Salary'] - predictions_df['Predicted_Salary']\n",
    "    predictions_df['Overpaid'] = predictions_df['Salary_Difference'] > 0\n",
    "    predictions_df['Underpaid'] = predictions_df['Salary_Difference'] < 0\n",
    "    \n",
    "    overpaid = predictions_df[predictions_df['Overpaid']].sort_values('Salary_Difference', ascending=False)\n",
    "    underpaid = predictions_df[predictions_df['Underpaid']].sort_values('Salary_Difference')\n",
    "    \n",
    "    return overpaid.head(10), underpaid.head(10)\n",
    "\n",
    "\n",
    "def identify_overpaid_underpaid(predictions_df):\n",
    "    # Adjust Predicted_Salary calculation\n",
    "    predictions_df['Predicted_Salary'] = predictions_df['Predicted_Salary'] * predictions_df['Salary_Cap_Inflated']\n",
    "    \n",
    "    predictions_df['Salary_Difference'] = predictions_df['Salary'] - predictions_df['Predicted_Salary']\n",
    "    predictions_df['Overpaid'] = predictions_df['Salary_Difference'] > 0\n",
    "    predictions_df['Underpaid'] = predictions_df['Salary_Difference'] < 0\n",
    "    \n",
    "    overpaid = predictions_df[predictions_df['Overpaid']].sort_values('Salary_Difference', ascending=False)\n",
    "    underpaid = predictions_df[predictions_df['Underpaid']].sort_values('Salary_Difference')\n",
    "    \n",
    "    return overpaid.head(10), underpaid.head(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictions_df = pd.read_csv('../data/processed/predictions_df.csv')\n",
    "    predictions_df = predictions_df[['Season', 'Position', 'Age', 'Team', 'TeamID', 'Years of Service', '3P%', '2P%', 'eFG%', 'FT%', 'PER', 'VORP', 'Salary', 'Total_Days_Injured', 'Injury_Risk', 'Salary Cap', 'Salary_Cap_Inflated', 'PPG', 'APG', 'TPG', 'SPG', 'BPG', 'Availability', 'SalaryPct', 'Efficiency', 'ValueOverReplacement', 'ExperienceSquared', 'Days_Injured_Percentage', 'WSPG', 'DWSPG', 'OWSPG', 'PFPG', 'ORPG', 'DRPG', 'RF_Predictions', 'XGB_Predictions', 'Predicted_Salary', 'Player']]\n",
    "    \n",
    "    current_year = 2023\n",
    "    start_year = current_year - 10\n",
    "    \n",
    "    # Calculate league stats from API\n",
    "    league_stats = calculate_league_stats_from_api(start_year, current_year - 1)\n",
    "    \n",
    "    print(\"League Stats:\")\n",
    "    for stat, values in league_stats.items():\n",
    "        print(f\"\\n{stat}:\")\n",
    "        print(f\"  Mean: {values['mean']:.2f}\")\n",
    "        print(f\"  Median: {values['median']:.2f}\")\n",
    "        print(f\"  Max: {values['max']:.2f}\")\n",
    "        print(\"  Percentile Counts:\")\n",
    "        for percentile, count in values['percentile_counts'].items():\n",
    "            print(f\"    {percentile}: {count}\")\n",
    "\n",
    "    champions = get_champions(start_year, current_year - 1)\n",
    "    champ_stats = calculate_champ_stats(champions)\n",
    "    \n",
    "    print(\"\\nChampion Stats:\")\n",
    "    for stat, values in champ_stats.items():\n",
    "        print(f\"\\n{stat}:\")\n",
    "        print(f\"  Mean: {values['mean']:.2f}\")\n",
    "        print(f\"  Median: {values['median']:.2f}\")\n",
    "        print(f\"  Max: {values['max']:.2f}\")\n",
    "        print(\"  Percentile Counts:\")\n",
    "        for percentile, count in values['percentile_counts'].items():\n",
    "            print(f\"    {percentile}: {count:.2f}\")\n",
    "    \n",
    "    # Identify overpaid and underpaid players with corrected Predicted_Salary\n",
    "    overpaid, underpaid = identify_overpaid_underpaid(predictions_df)\n",
    "    \n",
    "    print(\"\\nTop 10 Overpaid Players:\")\n",
    "    print(overpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "    \n",
    "    print(\"\\nTop 10 Underpaid Players:\")\n",
    "    print(underpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "    \n",
    "    # Example trade analysis\n",
    "    team1_abbr = 'LAL'\n",
    "    team2_abbr = 'BOS'\n",
    "    players_leaving_team1 = ['Anthony Davis', 'D\\'Angelo Russell']\n",
    "    players_leaving_team2 = ['Jayson Tatum', 'Jaylen Brown']\n",
    "    \n",
    "    result = analyze_two_team_trade(team1_abbr, team2_abbr, players_leaving_team1, players_leaving_team2, predictions_df, champions)\n",
    "    \n",
    "    if result:\n",
    "        for team_abbr, team_data in result.items():\n",
    "            print(f\"\\n{team_abbr} Trade Analysis:\")\n",
    "            print(f\"Current Salary: ${team_data['current_salary']:,.2f}\")\n",
    "            print(f\"Salary After Trade: ${team_data['new_salary']:,.2f}\")\n",
    "            print(f\"Salary Difference: ${team_data['new_salary'] - team_data['current_salary']:,.2f}\")\n",
    "            print(f\"Salary Match: {'Yes' if team_data['salary_match'] else 'No'}\")\n",
    "            \n",
    "            print(\"\\nStat Comparisons:\")\n",
    "            for stat in RELEVANT_STATS:\n",
    "                values = team_data['comparison'][stat]\n",
    "                print(f\"{stat}:\")\n",
    "                print(f\"  Current: {values['Current']:.2f} ({values['Current Percentile']:.1f}%ile)\")\n",
    "                print(f\"  After Trade: {values['After Trade']:.2f} ({values['After Trade Percentile']:.1f}%ile)\")\n",
    "                print(f\"  Change vs League: {values['After Trade vs League'] - values['Current vs League']:.2f}\")\n",
    "                print(f\"  Change vs Champ: {values['After Trade vs Champ'] - values['Current vs Champ']:.2f}\")\n",
    "                print(\"  Percentile Counts (Current / After Trade / Champ Average):\")\n",
    "                for percentile in PERCENTILE_THRESHOLDS:\n",
    "                    current_count = values['Current Percentile Counts'][f'Top {100-percentile}%']\n",
    "                    after_trade_count = values['After Trade Percentile Counts'][f'Top {100-percentile}%']\n",
    "                    champ_count = values['Champ Percentile Counts'][f'Top {100-percentile}%']\n",
    "                    print(f\"    Top {100-percentile}%: {current_count:.1f} / {after_trade_count:.1f} / {champ_count:.1f}\")\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_predict/updated/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_predict/updated/app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Import functions from other modules\n",
    "from data_loader_preprocessor import load_data, format_season, clean_data, engineer_features, encode_data\n",
    "from model_trainer import train_and_save_models, evaluate_models\n",
    "from model_predictor import predict\n",
    "from trade_utils import analyze_two_team_trade, get_champions\n",
    "\n",
    "\n",
    "def identify_overpaid_underpaid(predictions_df):\n",
    "    # Adjust Predicted_Salary calculation\n",
    "    predictions_df['Predicted_Salary'] = predictions_df['Predicted_Salary'] * predictions_df['Salary_Cap_Inflated']\n",
    "    \n",
    "    predictions_df['Salary_Difference'] = predictions_df['Salary'] - predictions_df['Predicted_Salary']\n",
    "    predictions_df['Overpaid'] = predictions_df['Salary_Difference'] > 0\n",
    "    predictions_df['Underpaid'] = predictions_df['Salary_Difference'] < 0\n",
    "    \n",
    "    overpaid = predictions_df[predictions_df['Overpaid']].sort_values('Salary_Difference', ascending=False)\n",
    "    underpaid = predictions_df[predictions_df['Underpaid']].sort_values('Salary_Difference')\n",
    "    \n",
    "    return overpaid.head(10), underpaid.head(10)\n",
    "\n",
    "\n",
    "# Utility functions\n",
    "def load_processed_data(file_path):\n",
    "    data = load_data(file_path)\n",
    "    data = format_season(data)\n",
    "    data = clean_data(data)\n",
    "    data = engineer_features(data)\n",
    "    return data\n",
    "\n",
    "def filter_data_by_season(data, season):\n",
    "    return data[data['Season'] == season]\n",
    "\n",
    "# Data visualization functions\n",
    "def plot_feature_distribution(data, feature):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.histplot(data[feature], kde=True, ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Count')\n",
    "    return fig\n",
    "\n",
    "def plot_correlation_heatmap(data):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    corr = numeric_data.corr()\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', ax=ax)\n",
    "    ax.set_title('Correlation Heatmap')\n",
    "    return fig\n",
    "\n",
    "# Model metrics function\n",
    "def display_model_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    st.subheader(\"Model Performance Metrics\")\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    col1.metric(\"Mean Squared Error\", f\"{mse:.4f}\")\n",
    "    col2.metric(\"Root Mean Squared Error\", f\"{rmse:.4f}\")\n",
    "    col3.metric(\"Mean Absolute Error\", f\"{mae:.4f}\")\n",
    "    col4.metric(\"R-squared\", f\"{r2:.4f}\")\n",
    "\n",
    "# Trade impact display function\n",
    "def display_trade_impact(result, team1, team2):\n",
    "    for team_abbr in [team1, team2]:\n",
    "        st.subheader(f\"{team_abbr} Trade Impact\")\n",
    "        \n",
    "        team_data = result[team_abbr]\n",
    "        \n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        col1.metric(\"Current Salary\", f\"${team_data['current_salary']:,.2f}\")\n",
    "        col2.metric(\"Salary After Trade\", f\"${team_data['new_salary']:,.2f}\")\n",
    "        col3.metric(\"Salary Difference\", f\"${team_data['new_salary'] - team_data['current_salary']:,.2f}\")\n",
    "        \n",
    "        st.subheader(\"Stat Comparisons\")\n",
    "        \n",
    "        # Create a DataFrame for the main stat comparisons\n",
    "        comparison_data = []\n",
    "        for stat, values in team_data['comparison'].items():\n",
    "            comparison_data.append({\n",
    "                'Stat': stat,\n",
    "                'Current': f\"{values['Current']:.2f} ({values['Current Percentile']:.1f}%ile)\",\n",
    "                'After Trade': f\"{values['After Trade']:.2f} ({values['After Trade Percentile']:.1f}%ile)\",\n",
    "                'Champion Average': f\"{values['Champ Average']:.2f}\",\n",
    "                'League Average': f\"{values['League Average']:.2f}\",\n",
    "                'Change vs League': f\"{values['After Trade vs League'] - values['Current vs League']:.2f}\",\n",
    "                'Change vs Champ': f\"{values['After Trade vs Champ'] - values['Current vs Champ']:.2f}\"\n",
    "            })\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        st.table(comparison_df)\n",
    "        \n",
    "        st.subheader(\"Percentile Counts\")\n",
    "        percentile_data = []\n",
    "        for stat, values in team_data['comparison'].items():\n",
    "            stat_data = {'Stat': stat}\n",
    "            for percentile in [99, 98, 97, 96, 95, 90, 75, 50]:\n",
    "                percentile_key = f\"Top {100-percentile}%\"\n",
    "                stat_data[f\"Current {percentile_key}\"] = values['Current Percentile Counts'][percentile_key]\n",
    "                stat_data[f\"After Trade {percentile_key}\"] = values['After Trade Percentile Counts'][percentile_key]\n",
    "                stat_data[f\"Champion {percentile_key}\"] = values['Champ Percentile Counts'][percentile_key]\n",
    "            percentile_data.append(stat_data)\n",
    "        \n",
    "        percentile_df = pd.DataFrame(percentile_data)\n",
    "        st.table(percentile_df)\n",
    "        \n",
    "        st.markdown(\"---\")\n",
    "\n",
    "def display_overpaid_underpaid(predictions_df):\n",
    "    st.subheader(\"Top 10 Overpaid and Underpaid Players\")\n",
    "\n",
    "    # Add filters\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        team_filter = st.multiselect(\"Filter by Team\", options=sorted(predictions_df['Team'].unique()))\n",
    "    with col2:\n",
    "        position_filter = st.multiselect(\"Filter by Position\", options=sorted(predictions_df['Position'].unique()))\n",
    "\n",
    "    # Apply filters\n",
    "    filtered_df = predictions_df\n",
    "    if team_filter:\n",
    "        filtered_df = filtered_df[filtered_df['Team'].isin(team_filter)]\n",
    "    if position_filter:\n",
    "        filtered_df = filtered_df[filtered_df['Position'].isin(position_filter)]\n",
    "\n",
    "    # Identify overpaid and underpaid players\n",
    "    overpaid, underpaid = identify_overpaid_underpaid(filtered_df)\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        st.subheader(\"Top 10 Overpaid Players\")\n",
    "        st.dataframe(overpaid[['Player', 'Team', 'Position', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"Top 10 Underpaid Players\")\n",
    "        st.dataframe(underpaid[['Player', 'Team', 'Position', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "\n",
    "# Main Streamlit app\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"NBA Salary Prediction and Trade Analysis\", layout=\"wide\")\n",
    "    st.title(\"NBA Salary Prediction and Trade Analysis\")\n",
    "\n",
    "    # Sidebar navigation\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Go to\", [\"Data Analysis\", \"Model Results\", \"Salary Evaluation\", \"Trade Analysis\"])\n",
    "\n",
    "    # Load base data\n",
    "    data = load_processed_data('data/processed/nba_player_data_final_inflated.csv')\n",
    "\n",
    "    # Load existing predictions for 2023\n",
    "    initial_predictions_df = pd.read_csv('data/processed/predictions_df.csv')\n",
    "\n",
    "    # Season selection\n",
    "    seasons = sorted(data['Season'].unique(), reverse=True)\n",
    "    selected_season = st.selectbox(\"Select Season\", seasons)\n",
    "\n",
    "    # Load models at the beginning of main()\n",
    "    model_save_path = 'data/models'\n",
    "    rf_model = joblib.load(f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "\n",
    "    # Use initial predictions if 2023 is selected, otherwise retrain\n",
    "    if selected_season == 2023:\n",
    "        predictions_df = initial_predictions_df\n",
    "    else:\n",
    "        # Train model and make predictions\n",
    "        train_data = data[data['Season'] < selected_season]\n",
    "        test_data = data[data['Season'] == selected_season]\n",
    "\n",
    "        # Prepare the data for training\n",
    "        X_train = train_data.drop(['SalaryPct', 'Salary', 'Player'], axis=1)\n",
    "        y_train = train_data['SalaryPct']\n",
    "\n",
    "        # Encode the training data\n",
    "        X_train_encoded, _, encoders, scaler, numeric_cols, player_encoder = encode_data(X_train)\n",
    "\n",
    "        # Train and save models\n",
    "        train_and_save_models(X_train_encoded, y_train, model_save_path, scaler, X_train_encoded.columns, encoders, player_encoder, numeric_cols)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        predictions_df = predict(test_data, model_save_path)\n",
    "\n",
    "\n",
    "\n",
    "    if page == \"Data Analysis\":\n",
    "        st.header(\"Data Analysis\")\n",
    "\n",
    "        # Filter data by selected season\n",
    "        season_data = filter_data_by_season(data, selected_season)\n",
    "\n",
    "        # Display basic statistics\n",
    "        st.subheader(\"Basic Statistics\")\n",
    "        st.write(season_data.describe())\n",
    "\n",
    "        # Feature distribution\n",
    "        st.subheader(\"Feature Distribution\")\n",
    "        feature = st.selectbox(\"Select Feature\", season_data.columns)\n",
    "        fig = plot_feature_distribution(season_data, feature)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Correlation heatmap\n",
    "        st.subheader(\"Correlation Heatmap\")\n",
    "        fig = plot_correlation_heatmap(season_data)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "        # Data handling explanation\n",
    "        st.subheader(\"Data Handling\")\n",
    "        st.write(\"\"\"\n",
    "        We preprocessed the data to ensure it's suitable for our models:\n",
    "        1. Cleaned missing values and outliers\n",
    "        2. Engineered new features like PPG, APG, etc.\n",
    "        3. Encoded categorical variables (Position, Team, Injury Risk)\n",
    "        4. Scaled numerical features\n",
    "        \"\"\")\n",
    "\n",
    "    elif page == \"Model Results\":\n",
    "        st.header(\"Model Results\")\n",
    "\n",
    "        # Model selection\n",
    "        model_choice = st.selectbox(\"Select Model\", [\"Random Forest\", \"XGBoost\"])\n",
    "\n",
    "        if model_choice == \"Random Forest\":\n",
    "            model = rf_model\n",
    "            y_pred = predictions_df['RF_Predictions']\n",
    "        else:\n",
    "            model = xgb_model\n",
    "            y_pred = predictions_df['XGB_Predictions']\n",
    "\n",
    "        # Display model metrics\n",
    "        display_model_metrics(predictions_df['SalaryPct'], y_pred)\n",
    "\n",
    "        # Feature importance\n",
    "        st.subheader(\"Feature Importance\")\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': model.feature_names_in_,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        st.bar_chart(feature_importance.set_index('feature'))\n",
    "\n",
    "\n",
    "        # Model explanation\n",
    "        st.subheader(\"Model Explanation\")\n",
    "        st.write(f\"\"\"\n",
    "        The {model_choice} model was trained on historical NBA player data to predict salary percentages.\n",
    "        We used the following techniques to improve model performance:\n",
    "        1. Feature engineering to create relevant statistics\n",
    "        2. Proper encoding of categorical variables\n",
    "        3. Scaling of numerical features\n",
    "        4. Hyperparameter tuning using GridSearchCV\n",
    "        \"\"\")\n",
    "        \n",
    "    elif page == \"Salary Evaluation\":\n",
    "        st.header(\"Salary Evaluation\")\n",
    "        display_overpaid_underpaid(predictions_df)\n",
    "\n",
    "    elif page == \"Trade Analysis\":\n",
    "        st.header(\"Trade Analysis\")\n",
    "        st.write(\"\"\"\n",
    "        Analyze potential trades and their impact on team statistics and salary cap.\n",
    "        For more information on trade rules, visit: [NBA Trade Rules](https://www.hoopsrumors.com/2023/09/salary-matching-rules-for-trades-during-2023-24-season.html)\n",
    "        \"\"\")\n",
    "\n",
    "        # Team selection\n",
    "        teams = sorted(predictions_df['Team'].unique())\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            team1 = st.selectbox(\"Select Team 1\", teams)\n",
    "        with col2:\n",
    "            team2 = st.selectbox(\"Select Team 2\", teams, index=1)\n",
    "\n",
    "        # Player selection\n",
    "        team1_players = predictions_df[predictions_df['Team'] == team1]['Player'].tolist()\n",
    "        team2_players = predictions_df[predictions_df['Team'] == team2]['Player'].tolist()\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            players_leaving_team1 = st.multiselect(f\"Select players leaving {team1}\", team1_players)\n",
    "        with col2:\n",
    "            players_leaving_team2 = st.multiselect(f\"Select players leaving {team2}\", team2_players)\n",
    "\n",
    "        if st.button(\"Analyze Trade\"):\n",
    "            champions = get_champions(selected_season - 10, selected_season - 1)\n",
    "            result = analyze_two_team_trade(team1, team2, players_leaving_team1, players_leaving_team2, predictions_df, champions)\n",
    "            \n",
    "            if result:\n",
    "                display_trade_impact(result, team1, team2)\n",
    "            else:\n",
    "                st.error(\"Trade analysis failed. Please check your selections.\")\n",
    "\n",
    "        # Trade analysis explanation\n",
    "        st.subheader(\"Trade Analysis Explanation\")\n",
    "        st.write(\"\"\"\n",
    "        Our trade analysis compares team statistics before and after the proposed trade.\n",
    "        We consider:\n",
    "        1. Changes in key performance metrics (PPG, RPG, APG, etc.)\n",
    "        2. Salary implications and cap space impact\n",
    "        3. Comparison to league averages and recent championship teams\n",
    "        4. Distribution of top performers in various statistical categories\n",
    "        5. Overpaid/Underpaid player analysis\n",
    "        \"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
