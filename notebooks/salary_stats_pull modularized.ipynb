{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/fetch_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/fetch_utils.py\n",
    "import time\n",
    "from nba_api.stats.endpoints import commonallplayers, commonplayerinfo, playercareerstats, leaguestandings\n",
    "from requests.exceptions import RequestException\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# Define the maximum requests allowed per minute and delay between requests\n",
    "MAX_REQUESTS_PER_MINUTE = 20\n",
    "DELAY_BETWEEN_REQUESTS = 3  # seconds\n",
    "\n",
    "def fetch_with_retry(endpoint, max_retries=10, initial_delay=5, max_delay=60, timeout=60, debug=False, **kwargs):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if debug:\n",
    "                print(f\"Fetching data using {endpoint.__name__} (Attempt {attempt + 1}) with parameters: {kwargs}\")\n",
    "            data = endpoint(**kwargs, timeout=timeout).get_data_frames()\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)  # Add delay between requests\n",
    "            return data[0] if isinstance(data, list) else data\n",
    "        except (RequestException, JSONDecodeError, KeyError) as e:\n",
    "            if debug:\n",
    "                print(f\"Error occurred during fetching {endpoint.__name__}: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                if debug:\n",
    "                    print(f\"Failed to fetch data from {endpoint.__name__} after {max_retries} attempts\")\n",
    "                return None\n",
    "            delay = min(initial_delay * (2 ** attempt), max_delay)\n",
    "            if debug:\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "def fetch_all_players(season, debug=False):\n",
    "    all_players_data = fetch_with_retry(commonallplayers.CommonAllPlayers, season=season, debug=debug)\n",
    "    all_players = {}\n",
    "    if all_players_data is not None:\n",
    "        for _, row in all_players_data.iterrows():\n",
    "            player_name = row['DISPLAY_FIRST_LAST'].strip().lower()\n",
    "            player_id = row['PERSON_ID']\n",
    "            team_id = row['TEAM_ID']\n",
    "            all_players[player_name] = {\n",
    "                'player_id': player_id,\n",
    "                'team_id': team_id\n",
    "            }\n",
    "    if debug:\n",
    "        print(f\"Fetched {len(all_players)} players for season {season}\")\n",
    "    return all_players\n",
    "\n",
    "def fetch_player_info(player_id, debug=False):\n",
    "    return fetch_with_retry(commonplayerinfo.CommonPlayerInfo, player_id=player_id, debug=debug)\n",
    "\n",
    "def fetch_career_stats(player_id, debug=False):\n",
    "    return fetch_with_retry(playercareerstats.PlayerCareerStats, player_id=player_id, debug=debug)\n",
    "\n",
    "def fetch_league_standings(season, debug=False):\n",
    "    return fetch_with_retry(leaguestandings.LeagueStandings, season=season, debug=debug)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    debug = True\n",
    "    season = \"2022-23\"\n",
    "    sample_player_name = \"LeBron James\"\n",
    "    \n",
    "    # Fetch all players\n",
    "    all_players = fetch_all_players(season, debug=debug)\n",
    "    print(f\"Total players fetched: {len(all_players)}\")\n",
    "    \n",
    "    # Fetch player info for a sample player\n",
    "    if sample_player_name.lower() in all_players:\n",
    "        sample_player_id = all_players[sample_player_name.lower()]['player_id']\n",
    "        player_info = fetch_player_info(sample_player_id, debug=debug)\n",
    "        print(f\"Sample player info for {sample_player_name}:\")\n",
    "        print(player_info)\n",
    "        \n",
    "        # Fetch career stats for the sample player\n",
    "        career_stats = fetch_career_stats(sample_player_id, debug=debug)\n",
    "        print(f\"Sample player career stats for {sample_player_name}:\")\n",
    "        print(career_stats)\n",
    "    else:\n",
    "        print(f\"Player {sample_player_name} not found in the {season} season data.\")\n",
    "    \n",
    "    # Fetch league standings\n",
    "    standings = fetch_league_standings(season, debug=debug)\n",
    "    print(\"League standings:\")\n",
    "    print(standings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/scrape_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/scrape_utils.py\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "def scrape_salary_cap_history(debug=False):\n",
    "    url = \"https://basketball.realgm.com/nba/info/salary_cap\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', class_='basketball compact')\n",
    "        \n",
    "        if not table:\n",
    "            if debug:\n",
    "                print(\"Could not find the salary cap table on the page.\")\n",
    "            return None\n",
    "\n",
    "        data = []\n",
    "        headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "        for row in table.find('tbody').find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                row_data = [col.text.strip() for col in cols]\n",
    "                data.append(row_data)\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        \n",
    "        # Clean up the data\n",
    "        df['Season'] = df['Season'].str.extract(r'(\\d{4}-\\d{4})')\n",
    "        df['Salary Cap'] = df['Salary Cap'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "        \n",
    "        # Convert other columns to float, handling non-numeric values\n",
    "        for col in df.columns:\n",
    "            if col not in ['Season', 'Salary Cap']:\n",
    "                df[col] = pd.to_numeric(df[col].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Salary cap data scraped successfully\")\n",
    "            print(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error scraping salary cap history: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "DELAY_BETWEEN_REQUESTS = 3  # seconds\n",
    "\n",
    "def scrape_player_salary_data(start_season, end_season, player_filter=None, debug=False):\n",
    "    all_data = []\n",
    "    \n",
    "    for season in range(start_season, end_season + 1):\n",
    "        season_str = f\"{season}-{str(season+1)[-2:]}\"\n",
    "        url = f\"https://hoopshype.com/salaries/players/{season}-{season+1}/\"\n",
    "        if debug:\n",
    "            print(f\"Scraping data for {season_str} from URL: {url}\")\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', class_='hh-salaries-ranking-table')\n",
    "        \n",
    "        if table:\n",
    "            rows = table.find_all('tr')[1:]\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if len(cols) >= 3:\n",
    "                    player = cols[1].get_text(strip=True)\n",
    "                    if player_filter is None or player_filter.lower() == 'all' or player.lower() == player_filter.lower():\n",
    "                        salary_text = cols[2].get_text(strip=True)\n",
    "                        salary = int(salary_text.replace('$', '').replace(',', ''))\n",
    "                        all_data.append({'Player': player, 'Salary': salary, 'Season': season_str})\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"No salary data found for season {season_str}\")\n",
    "        \n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)  # Delay between requests to avoid hitting rate limits\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    if debug:\n",
    "        print(f\"Scraped salary data for {'all players' if player_filter is None or player_filter.lower() == 'all' else player_filter} from seasons {start_season}-{end_season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    if debug:\n",
    "        print(f\"Scraped salary data for {'all players' if player_filter is None or player_filter.lower() == 'all' else player_filter} from seasons {start_season}-{end_season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "\n",
    "def scrape_team_salary_data(season, debug=False):\n",
    "    url = f\"https://hoopshype.com/salaries/{season}/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', class_='hh-salaries-ranking-table')\n",
    "    rows = table.find_all('tr')[1:]\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        team = cols[1].get_text(strip=True)\n",
    "        salary = int(cols[2].get_text(strip=True).replace('$', '').replace(',', ''))\n",
    "        data.append({'Team': team, 'Team_Salary': salary, 'Season': season})\n",
    "    df = pd.DataFrame(data)\n",
    "    if debug:\n",
    "        print(f\"Scraped team salary data for season {season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "\n",
    "def scrape_advanced_metrics(player_name, season, debug=False, max_retries=3, retry_delay=60):\n",
    "    def make_request(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 429:\n",
    "            if debug:\n",
    "                print(f\"Rate limit hit. Waiting for {retry_delay} seconds before retrying.\")\n",
    "            time.sleep(retry_delay)\n",
    "            return None\n",
    "        return response\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            search_url = f\"https://www.basketball-reference.com/search/search.fcgi?search={player_name.replace(' ', '+')}\"\n",
    "            response = make_request(search_url)\n",
    "            if response is None:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            search_results = soup.find('div', {'class': 'search-results'})\n",
    "\n",
    "            if search_results:\n",
    "                for item in search_results.find_all('div', {'class': 'search-item'}):\n",
    "                    link = item.find('a')\n",
    "                    if link and 'players' in link['href']:\n",
    "                        player_url = f\"https://www.basketball-reference.com{link['href']}\"\n",
    "                        break\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"No player URL found for {player_name}\")\n",
    "                    return {}\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"No search results found for {player_name}\")\n",
    "                return {}\n",
    "\n",
    "            time.sleep(2)  # Wait 2 seconds between requests\n",
    "\n",
    "            response = make_request(player_url)\n",
    "            if response is None:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': 'advanced'})\n",
    "            if table:\n",
    "                df = pd.read_html(StringIO(str(table)))[0]\n",
    "                if isinstance(df.columns, pd.MultiIndex):\n",
    "                    df.columns = df.columns.droplevel()\n",
    "                df['Season'] = df['Season'].astype(str)\n",
    "                df = df[df['Season'].str.contains(season.split('-')[0], na=False)]\n",
    "                if not df.empty:\n",
    "                    row = df.iloc[0]\n",
    "                    metrics = ['PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "                    result = {col: row[col] for col in metrics if col in row.index}\n",
    "                    if debug:\n",
    "                        print(f\"Scraped advanced metrics for {player_name} in season {season}: {result}\")\n",
    "                    return result\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"No advanced metrics found for {player_name} in season {season}\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"No advanced stats table found for {player_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"Error scraping advanced metrics for {player_name}: {e}\")\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            if debug:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Failed to scrape advanced metrics for {player_name} after {max_retries} attempts\")\n",
    "    return {}\n",
    "\n",
    "def load_injury_data(file_path='../data/processed/NBA Player Injury Stats(1951 - 2023).csv'):\n",
    "    try:\n",
    "        injury_data = pd.read_csv(file_path)\n",
    "        injury_data['Date'] = pd.to_datetime(injury_data['Date'])\n",
    "        injury_data['Season'] = injury_data['Date'].apply(lambda x: f\"{x.year}-{str(x.year+1)[-2:]}\" if x.month >= 10 else f\"{x.year-1}-{str(x.year)[-2:]}\")\n",
    "        print(\"Injury data loaded successfully\")\n",
    "        return injury_data\n",
    "    except FileNotFoundError:\n",
    "        print(\"Injury data file not found. Proceeding without injury data.\")\n",
    "        return None\n",
    "\n",
    "def merge_injury_data(player_data, injury_data):\n",
    "    if injury_data is None:\n",
    "        return player_data\n",
    "\n",
    "    all_players_df = player_data.copy()\n",
    "    all_players_df['Injured'] = False\n",
    "    all_players_df['Injury_Periods'] = ''\n",
    "    all_players_df['Total_Days_Injured'] = 0\n",
    "    all_players_df['Injury_Risk'] = 'Low Risk'\n",
    "\n",
    "    for index, row in all_players_df.iterrows():\n",
    "        player_injuries = injury_data[\n",
    "            (injury_data['Season'] == row['Season']) & \n",
    "            (injury_data['Relinquished'].str.contains(row['Player'], case=False, na=False))\n",
    "        ]\n",
    "        if not player_injuries.empty:\n",
    "            periods = []\n",
    "            total_days = 0\n",
    "            for _, injury in player_injuries.iterrows():\n",
    "                start_date = injury['Date']\n",
    "                acquired_matches = injury_data[\n",
    "                    (injury_data['Date'] > start_date) & \n",
    "                    (injury_data['Acquired'].str.contains(row['Player'], case=False, na=False))\n",
    "                ]\n",
    "                if not acquired_matches.empty:\n",
    "                    end_date = acquired_matches.iloc[0]['Date']\n",
    "                else:\n",
    "                    # Assuming injuries last until the end of the season if no acquired date is found\n",
    "                    end_year = int(row['Season'].split('-')[1])\n",
    "                    end_date = pd.Timestamp(f\"{end_year}-06-30\")\n",
    "                \n",
    "                period_days = (end_date - start_date).days\n",
    "                total_days += period_days\n",
    "                periods.append(f\"{start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "            all_players_df.at[index, 'Injured'] = True\n",
    "            all_players_df.at[index, 'Injury_Periods'] = '; '.join(periods)\n",
    "            all_players_df.at[index, 'Total_Days_Injured'] = total_days\n",
    "            \n",
    "            # Categorize injury risk based on total days\n",
    "            if total_days < 10:\n",
    "                risk = 'Low Risk'\n",
    "            elif 10 <= total_days <= 20:\n",
    "                risk = 'Moderate Risk'\n",
    "            else:\n",
    "                risk = 'High Risk'\n",
    "            all_players_df.at[index, 'Injury_Risk'] = risk\n",
    "\n",
    "    return all_players_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage and testing of all functions\n",
    "    debug = True\n",
    "    start_season = 2022\n",
    "    end_season = 2023\n",
    "    sample_player = \"Ja Morant\"  # Example player\n",
    "    \n",
    "    print(\"1. Testing scrape_salary_cap_history:\")\n",
    "    salary_cap_history = scrape_salary_cap_history(debug=debug)\n",
    "    \n",
    "    print(\"\\n2. Testing scrape_player_salary_data:\")\n",
    "    player_salary_data = scrape_player_salary_data(start_season, end_season, player_filter=sample_player, debug=debug)\n",
    "    \n",
    "    print(\"\\n3. Testing scrape_team_salary_data:\")\n",
    "    team_salary_data = scrape_team_salary_data(f\"{start_season}-{str(start_season+1)[-2:]}\", debug=debug)\n",
    "    \n",
    "    print(\"\\n4. Testing scrape_advanced_metrics:\")\n",
    "    advanced_metrics = scrape_advanced_metrics(sample_player, f\"{start_season}-{str(start_season+1)[-2:]}\", debug=debug)\n",
    "    print(f\"Advanced Metrics for {sample_player}:\")\n",
    "    print(advanced_metrics)\n",
    "    \n",
    "    print(\"\\n5. Testing load_injury_data and merge_injury_data:\")\n",
    "    injury_data = load_injury_data()\n",
    "    if not player_salary_data.empty and injury_data is not None:\n",
    "        merged_data = merge_injury_data(player_salary_data, injury_data)\n",
    "        print(\"Merged data with injury info:\")\n",
    "        columns_to_display = ['Player', 'Season', 'Salary']\n",
    "        if 'Injured' in merged_data.columns:\n",
    "            columns_to_display.append('Injured')\n",
    "        if 'Injury_Periods' in merged_data.columns:\n",
    "            columns_to_display.append('Injury_Periods')\n",
    "        if 'Total_Days_Injured' in merged_data.columns:\n",
    "            columns_to_display.append('Total_Days_Injured')\n",
    "        if 'Injury_Risk' in merged_data.columns:\n",
    "            columns_to_display.append('Injury_Risk')\n",
    "        print(merged_data[columns_to_display].head())\n",
    "\n",
    "    if not player_salary_data.empty:\n",
    "        avg_salary = player_salary_data['Salary'].mean()\n",
    "        print(f\"Average salary for {sample_player} from {start_season} to {end_season}: ${avg_salary:,.2f}\")\n",
    "    \n",
    "    if not team_salary_data.empty:\n",
    "        highest_team_salary = team_salary_data.loc[team_salary_data['Team_Salary'].idxmax()]\n",
    "        print(f\"Team with highest salary in {start_season}-{end_season}: {highest_team_salary['Team']} (${highest_team_salary['Team_Salary']:,.2f})\")\n",
    "    \n",
    "    if not injury_data.empty:\n",
    "        injury_count = injury_data['Relinquished'].str.contains(sample_player, case=False).sum()\n",
    "        print(f\"Number of injuries/illnesses for {sample_player} from {start_season} to {end_season}: {injury_count}\")\n",
    "\n",
    "    print(\"\\nAll tests completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/process_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/process_utils.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import cpi\n",
    "from fetch_utils import fetch_player_info, fetch_career_stats, fetch_league_standings\n",
    "from scrape_utils import scrape_advanced_metrics\n",
    "\n",
    "def inflate_value(value, year_str, debug=False):\n",
    "    try:\n",
    "        year = int(year_str[:4])\n",
    "        current_year = datetime.now().year\n",
    "       \n",
    "        if year >= current_year:\n",
    "            return value  # Return the original value for future years\n",
    "        # Adjust to 2022 dollars to match the original data\n",
    "        inflated_value = cpi.inflate(value, year, to=2022)\n",
    "        if debug:\n",
    "            print(f\"Inflated value {value} from {year} to {inflated_value} (2022 dollars)\")\n",
    "        return inflated_value\n",
    "    except ValueError:\n",
    "        if debug:\n",
    "            print(f\"Invalid year format: {year_str}\")\n",
    "        return value\n",
    "    except cpi.errors.CPIObjectDoesNotExist:\n",
    "        # If data for the specific year is not available, use the earliest available year\n",
    "        earliest_year = min(cpi.SURVEYS['CPI-U'].indexes['annual'].keys()).year\n",
    "        inflated_value = cpi.inflate(value, earliest_year, to=2022)\n",
    "        if debug:\n",
    "            print(f\"Used earliest available year {earliest_year} for inflation calculation\")\n",
    "        return inflated_value\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error inflating value for year {year_str}: {e}\")\n",
    "        return value\n",
    "\n",
    "def calculate_percentages(df, debug=False):\n",
    "    df['FG%'] = df['FG'] / df['FGA'].replace(0, np.nan)\n",
    "    df['3P%'] = df['3P'] / df['3PA'].replace(0, np.nan)\n",
    "    df['2P%'] = df['2P'] / df['2PA'].replace(0, np.nan)\n",
    "    df['FT%'] = df['FT'] / df['FTA'].replace(0, np.nan)\n",
    "    df['eFG%'] = (df['FG'] + 0.5 * df['3P']) / df['FGA'].replace(0, np.nan)\n",
    "    if debug:\n",
    "        print(\"Calculated percentages:\")\n",
    "        print(df[['FG%', '3P%', '2P%', 'FT%', 'eFG%']].head())\n",
    "    return df\n",
    "\n",
    "def process_player_data(player, season, all_players, debug=False):\n",
    "    if player.lower() not in all_players:\n",
    "        if debug:\n",
    "            print(f\"No player ID found for {player}\")\n",
    "        return None\n",
    "\n",
    "    player_id = all_players[player.lower()]['player_id']\n",
    "    team_id = all_players[player.lower()]['team_id']\n",
    "    \n",
    "    player_info = fetch_player_info(player_id, debug=debug)\n",
    "    career_stats = fetch_career_stats(player_id, debug=debug)\n",
    "    league_standings = fetch_league_standings(season, debug=debug)\n",
    "    \n",
    "    # Scrape advanced metrics from Basketball Reference\n",
    "    advanced_metrics = scrape_advanced_metrics(player, season, debug=debug)\n",
    "\n",
    "    if player_info is None or career_stats is None or career_stats.empty:\n",
    "        if debug:\n",
    "            print(f\"Unable to fetch complete data for {player}\")\n",
    "        return None\n",
    "\n",
    "    season_stats = career_stats[career_stats['SEASON_ID'].str.contains(season.split('-')[0], na=False)]\n",
    "    if season_stats.empty:\n",
    "        if debug:\n",
    "            print(f\"No stats found for {player} in season {season}\")\n",
    "        return None\n",
    "\n",
    "    latest_season_stats = season_stats.iloc[0]\n",
    "    \n",
    "    try:\n",
    "        draft_year = int(player_info['DRAFT_YEAR'].iloc[0])\n",
    "    except ValueError:\n",
    "        draft_year = int(player_info['FROM_YEAR'].iloc[0])\n",
    "\n",
    "    current_season_year = int(season.split('-')[0])\n",
    "    years_of_service = max(0, current_season_year - draft_year)\n",
    "\n",
    "    # Handle missing league standings gracefully\n",
    "    if league_standings is not None and not league_standings.empty:\n",
    "        player_stats = calculate_player_stats(latest_season_stats, player_info, years_of_service, team_id, league_standings, advanced_metrics)\n",
    "    else:\n",
    "        player_stats = calculate_player_stats(latest_season_stats, player_info, years_of_service, team_id, pd.DataFrame(), advanced_metrics)\n",
    "\n",
    "    player_stats.update({'Player': player, 'Season': season})\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Processed data for {player} in season {season}: {player_stats}\")\n",
    "    return player_stats\n",
    "\n",
    "def calculate_player_stats(stats, player_info, years_of_service, team_id, league_standings, advanced_metrics):\n",
    "    fg = stats.get('FGM', 0) or 0\n",
    "    fga = stats.get('FGA', 0) or 0\n",
    "    fg3 = stats.get('FG3M', 0) or 0\n",
    "    fg3a = stats.get('FG3A', 0) or 0\n",
    "    efg = (fg + 0.5 * fg3) / fga if fga != 0 else 0\n",
    "    fg2 = fg - fg3\n",
    "    fg2a = fga - fg3a\n",
    "    fg2_pct = (fg2 / fg2a) if fg2a != 0 else 0\n",
    "\n",
    "    player_stats = {\n",
    "        'Position': player_info.iloc[0]['POSITION'],\n",
    "        'Age': stats.get('PLAYER_AGE', None),\n",
    "        'Team': stats.get('TEAM_ABBREVIATION', None),\n",
    "        'TeamID': team_id,\n",
    "        'Years of Service': years_of_service,\n",
    "        'GP': stats.get('GP', None),\n",
    "        'GS': stats.get('GS', None),\n",
    "        'MP': stats.get('MIN', None),\n",
    "        'FG': fg,\n",
    "        'FGA': fga,\n",
    "        'FG%': stats.get('FG_PCT', None),\n",
    "        '3P': fg3,\n",
    "        '3PA': fg3a,\n",
    "        '3P%': stats.get('FG3_PCT', None),\n",
    "        '2P': fg2,\n",
    "        '2PA': fg2a,\n",
    "        '2P%': fg2_pct,\n",
    "        'eFG%': efg,\n",
    "        'FT': stats.get('FTM', None),\n",
    "        'FTA': stats.get('FTA', None),\n",
    "        'FT%': stats.get('FT_PCT', None),\n",
    "        'ORB': stats.get('OREB', None),\n",
    "        'DRB': stats.get('DREB', None),\n",
    "        'TRB': stats.get('REB', None),\n",
    "        'AST': stats.get('AST', None),\n",
    "        'STL': stats.get('STL', None),\n",
    "        'BLK': stats.get('BLK', None),\n",
    "        'TOV': stats.get('TOV', None),\n",
    "        'PF': stats.get('PF', None),\n",
    "        'PTS': stats.get('PTS', None),\n",
    "    }\n",
    "    \n",
    "    # Add advanced metrics\n",
    "    player_stats.update(advanced_metrics)\n",
    "\n",
    "    if league_standings is not None and not league_standings.empty:\n",
    "        team_standings = league_standings[league_standings['TeamID'] == team_id]\n",
    "        if not team_standings.empty:\n",
    "            player_stats.update({\n",
    "                'Wins': team_standings['WINS'].values[0],\n",
    "                'Losses': team_standings['LOSSES'].values[0]\n",
    "            })\n",
    "\n",
    "    return player_stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    debug = True\n",
    "    season = \"2022-23\"\n",
    "    sample_value = 1000000\n",
    "    sample_year = \"2022\"\n",
    "    sample_player = \"LeBron James\"\n",
    "    \n",
    "    # Test inflate_value\n",
    "    inflated_value = inflate_value(sample_value, sample_year, debug=debug)\n",
    "    print(f\"Inflated value: {inflated_value}\")\n",
    "    \n",
    "    # Test calculate_percentages\n",
    "    sample_df = pd.DataFrame({\n",
    "        'FG': [100], 'FGA': [200],\n",
    "        '3P': [50], '3PA': [100],\n",
    "        '2P': [50], '2PA': [100],\n",
    "        'FT': [75], 'FTA': [100]\n",
    "    })\n",
    "    calculated_df = calculate_percentages(sample_df, debug=debug)\n",
    "    print(\"Calculated percentages:\")\n",
    "    print(calculated_df)\n",
    "    \n",
    "    # Test process_player_data\n",
    "    # Note: This requires actual data from fetch_utils and scrape_utils\n",
    "    # Here's a mock-up of how it would work:\n",
    "    # from fetch_utils import fetch_all_players\n",
    "    all_players = fetch_all_players(season, debug=debug)\n",
    "    if sample_player.lower() in all_players:\n",
    "        player_data = process_player_data(sample_player, season, all_players, debug=debug)\n",
    "        print(f\"Processed data for {sample_player}:\")\n",
    "        print(player_data)\n",
    "    else:\n",
    "        print(f\"Player {sample_player} not found in the {season} season data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/data_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/data_utils.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from process_utils import inflate_value\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    \n",
    "    # Remove columns with all NaN values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Remove rows with all NaN values\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    \n",
    "    # Ensure only one 'Season' column exists\n",
    "    season_columns = [col for col in df.columns if 'Season' in col]\n",
    "    if len(season_columns) > 1:\n",
    "        df = df.rename(columns={season_columns[0]: 'Season'})\n",
    "        for col in season_columns[1:]:\n",
    "            df = df.drop(columns=[col])\n",
    "    \n",
    "    # Remove '3PAr' and 'FTr' columns\n",
    "    columns_to_remove = ['3PAr', 'FTr']\n",
    "    df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "    \n",
    "    # Round numeric columns to 2 decimal places\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].round(2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def merge_salary_cap_data(player_data, salary_cap_data):\n",
    "    player_data['Season_Year'] = player_data['Season'].str[:4].astype(int)\n",
    "    salary_cap_data['Season_Year'] = salary_cap_data['Season'].str[:4].astype(int)\n",
    "    \n",
    "    # Add inflation-adjusted salary cap\n",
    "    salary_cap_data['Salary_Cap_Inflated'] = salary_cap_data.apply(\n",
    "        lambda row: inflate_value(row['Salary Cap'], row['Season']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Merge salary cap data\n",
    "    merged_data = pd.merge(player_data, salary_cap_data, on='Season_Year', how='left', suffixes=('', '_cap'))\n",
    "    \n",
    "    # Update salary cap columns\n",
    "    cap_columns = ['Mid-Level Exception', 'Salary Cap', 'Luxury Tax', '1st Apron', '2nd Apron', 'BAE',\n",
    "                   'Standard /Non-Taxpayer', 'Taxpayer', 'Team Room /Under Cap', 'Salary_Cap_Inflated']\n",
    "    for col in cap_columns:\n",
    "        if f'{col}_cap' in merged_data.columns:\n",
    "            merged_data[col] = merged_data[col].fillna(merged_data[f'{col}_cap'])\n",
    "            merged_data.drop(columns=[f'{col}_cap'], inplace=True)\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_data.drop(columns=['Season_Year'], inplace=True)\n",
    "    \n",
    "    # Clean the dataframe\n",
    "    merged_data = clean_dataframe(merged_data)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "def validate_data(df):\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"Warning: Missing values found in the following columns:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicates = df.duplicated()\n",
    "    if duplicates.sum() > 0:\n",
    "        print(f\"Warning: {duplicates.sum()} duplicate rows found\")\n",
    "    \n",
    "    # Check data types\n",
    "    expected_types = {\n",
    "        'Season': 'object',\n",
    "        'Player': 'object',\n",
    "        'Age': 'float64',\n",
    "        'GP': 'float64',\n",
    "        'MP': 'float64',\n",
    "        'Salary': 'float64',\n",
    "        'Team_Salary': 'float64',\n",
    "        'Salary Cap': 'float64',\n",
    "        'Salary_Cap_Inflated': 'float64'\n",
    "    }\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if col in df.columns:\n",
    "            actual_type = df[col].dtype\n",
    "            if str(actual_type) != expected_type:\n",
    "                print(f\"Warning: Column '{col}' has type {actual_type}, expected {expected_type}\")\n",
    "    \n",
    "    # Check for negative values in numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if (df[col] < 0).any():\n",
    "            print(f\"Warning: Negative values found in column '{col}'\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/main.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from fetch_utils import fetch_all_players\n",
    "from process_utils import process_player_data, inflate_value, calculate_percentages\n",
    "from scrape_utils import scrape_salary_cap_history, merge_injury_data, scrape_player_salary_data, scrape_team_salary_data, load_injury_data\n",
    "from data_utils import clean_dataframe, merge_salary_cap_data, validate_data\n",
    "\n",
    "\n",
    "def update_data(existing_data, start_year, end_year, player_filter=None, min_avg_minutes=None, debug=False):\n",
    "    all_data = existing_data.copy() if existing_data is not None else pd.DataFrame()\n",
    "\n",
    "    # Load injury data\n",
    "    injury_data = load_injury_data()\n",
    "\n",
    "    salary_data = scrape_player_salary_data(start_year, end_year, player_filter=player_filter, debug=debug)\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Processing season: {season}\")\n",
    "        \n",
    "        team_salary_data = scrape_team_salary_data(season, debug=debug)\n",
    "        all_players = fetch_all_players(season=season, debug=debug)\n",
    "        \n",
    "        season_salary_data = salary_data[salary_data['Season'] == season]\n",
    "        \n",
    "        if player_filter and player_filter.lower() != 'all':\n",
    "            season_salary_data = season_salary_data[season_salary_data['Player'].str.lower() == player_filter.lower()]\n",
    "\n",
    "        additional_stats = []\n",
    "\n",
    "        for _, salary_row in season_salary_data.iterrows():\n",
    "            player_name = salary_row['Player']\n",
    "            player_name_lower = player_name.lower()\n",
    "            \n",
    "            if player_name_lower in all_players:\n",
    "                player_stats = process_player_data(player_name, season, all_players, debug=debug)\n",
    "                if player_stats:\n",
    "                    player_stats['Salary'] = salary_row['Salary']\n",
    "                    additional_stats.append(player_stats)\n",
    "            elif debug:\n",
    "                print(f\"Player not found in all_players: {player_name}\")\n",
    "\n",
    "        additional_stats_df = pd.DataFrame(additional_stats)\n",
    "\n",
    "        if additional_stats_df.empty or 'Team' not in additional_stats_df.columns:\n",
    "            if debug:\n",
    "                print(f\"Warning: No valid player stats data for season {season}\")\n",
    "            continue\n",
    "\n",
    "        # Merge team salary data\n",
    "        merged_data = pd.merge(additional_stats_df, team_salary_data, on=['Team', 'Season'], how='left', suffixes=('', '_team'))\n",
    "\n",
    "        # Apply minimum average minutes filter if specified\n",
    "        if min_avg_minutes is not None:\n",
    "            before_filter = len(merged_data)\n",
    "            merged_data = merged_data[merged_data['MP'] >= min_avg_minutes]\n",
    "            if debug:\n",
    "                print(f\"Filtered {before_filter - len(merged_data)} players based on minimum average minutes\")\n",
    "\n",
    "        # Merge injury data\n",
    "        merged_data = merge_injury_data(merged_data, injury_data)\n",
    "\n",
    "        new_data = pd.concat([new_data, merged_data], ignore_index=True, sort=False)\n",
    "\n",
    "    # Remove existing data for the players and seasons we just updated\n",
    "    if not all_data.empty and not new_data.empty:\n",
    "        all_data = all_data[~((all_data['Season'].isin(new_data['Season'])) & \n",
    "                              (all_data['Player'].isin(new_data['Player'])))]\n",
    "\n",
    "    # Combine existing data with new data\n",
    "    all_data = pd.concat([all_data, new_data], ignore_index=True, sort=False)\n",
    "\n",
    "    # Sort the final data by season and player\n",
    "    all_data.sort_values(by=['Season', 'Player'], inplace=True)\n",
    "\n",
    "    # Calculate percentages\n",
    "    all_data = calculate_percentages(all_data)\n",
    "\n",
    "    # Clean the dataframe\n",
    "    all_data = clean_dataframe(all_data)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Final data shape: {all_data.shape}\")\n",
    "        print(f\"Columns: {all_data.columns.tolist()}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def get_timestamp():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def remove_old_logs(log_dir, days_to_keep=7):\n",
    "    current_time = datetime.now()\n",
    "    for log_file in glob.glob(os.path.join(log_dir, 'stat_pull_log_*.txt')):\n",
    "        file_modified_time = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "        if current_time - file_modified_time > timedelta(days=days_to_keep):\n",
    "            os.remove(log_file)\n",
    "\n",
    "def main(start_year, end_year, player_filter=None, min_avg_minutes=None, debug=False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    output_dir = '../data/stat_pull_output'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Remove old log files\n",
    "    remove_old_logs(output_dir)\n",
    "    \n",
    "    # Set up logging\n",
    "    log_file = os.path.join(output_dir, f'stat_pull_log_{get_timestamp()}.txt')\n",
    "    logging.basicConfig(filename=log_file, level=logging.DEBUG if debug else logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    try:\n",
    "        logging.info(f\"Starting data update for years {start_year} to {end_year}\")\n",
    "        \n",
    "        \n",
    "        processed_file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "        salary_cap_file_path = '../data/processed/salary_cap_history_inflated.csv'\n",
    "\n",
    "        # Load existing data\n",
    "        try:\n",
    "            existing_data = pd.read_csv(processed_file_path)\n",
    "        except FileNotFoundError:\n",
    "            existing_data = pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "            if debug:\n",
    "                print(f\"Updating data for years {start_year} to {end_year}\")\n",
    "            updated_data = update_data(existing_data, start_year, end_year, player_filter, min_avg_minutes, debug=debug)\n",
    "\n",
    "            if not updated_data.empty:\n",
    "                if debug:\n",
    "                    print(\"New data retrieved. Processing and saving...\")\n",
    "\n",
    "                salary_cap_data = scrape_salary_cap_history(debug=debug)\n",
    "\n",
    "                if salary_cap_data is not None:\n",
    "                    salary_cap_data.to_csv(salary_cap_file_path, index=False)\n",
    "                    updated_data = merge_salary_cap_data(updated_data, salary_cap_data)\n",
    "\n",
    "                # Final cleaning of the data\n",
    "                updated_data = clean_dataframe(updated_data)\n",
    "\n",
    "                # Save the updated data\n",
    "                updated_data.to_csv(processed_file_path, index=False, float_format='%.2f')\n",
    "                if debug:\n",
    "                    print(f\"Updated data saved to {processed_file_path}\")\n",
    "\n",
    "                # Print summary of the data\n",
    "                summary_columns = ['Season', 'Player', 'Salary', 'GP', 'PTS', 'TRB', 'AST', 'PER', 'WS', 'VORP', 'Injured', 'FG%', '3P%', 'FT%', 'Team_Salary', 'Salary Cap', 'Salary_Cap_Inflated']\n",
    "                available_columns = [col for col in summary_columns if col in updated_data.columns]\n",
    "                print(\"\\nData summary:\")\n",
    "                print(updated_data[available_columns].head().to_string(index=False))\n",
    "            else:\n",
    "                print(\"No new data to save. The dataset is empty.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            print(\"Traceback:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        logging.info(\"Data update completed successfully\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        logging.error(\"Traceback:\", exc_info=True)\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        logging.info(f\"Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "        # Print summary to console as well\n",
    "        print(f\"Process completed. Log file saved to: {log_file}\")\n",
    "        print(f\"Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    current_year = datetime.now().year\n",
    "    parser = argparse.ArgumentParser(description=\"Update NBA player data\")\n",
    "    parser.add_argument(\"--start_year\", type=int, default=current_year-1, help=\"Start year for data update\")\n",
    "    parser.add_argument(\"--end_year\", type=int, default=current_year, help=\"End year for data update\")\n",
    "    parser.add_argument(\"--player_filter\", type=str, default=\"all\", help=\"Filter for specific player or 'all'\")\n",
    "    parser.add_argument(\"--min_avg_minutes\", type=float, default=25, help=\"Minimum average minutes per game\")\n",
    "    parser.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug mode\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.start_year, args.end_year, args.player_filter, args.min_avg_minutes, args.debug)\n",
    "\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start_year = 2019\n",
    "#     end_year = 2023\n",
    "#     player_filter = input(\"Enter player name or 'all' for all players: \").strip()\n",
    "#     min_avg_minutes = None\n",
    "#     if player_filter.lower() == 'all':\n",
    "#         min_avg_minutes = float(input(\"Enter the minimum average minutes per game (default 25 mins): \") or 25)\n",
    "\n",
    "#     debug = True  # Set to False to disable debug output\n",
    "\n",
    "#     main(start_year, end_year, player_filter, min_avg_minutes, debug)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/coach_analysis/notebooks\n",
      "/workspaces/coach_analysis/src\n",
      "/workspaces/coach_analysis/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "%cd ../src\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating data for years 2018 to 2019\n",
      "Injury data loaded successfully\n",
      "Scraping data for 2018-19 from URL: https://hoopshype.com/salaries/players/2018-2019/\n",
      "Scraping data for 2019-20 from URL: https://hoopshype.com/salaries/players/2019-2020/\n",
      "Scraped salary data for all players from seasons 2018-2019:\n",
      "              Player    Salary   Season\n",
      "0      Stephen Curry  37457154  2018-19\n",
      "1  Russell Westbrook  35665000  2018-19\n",
      "2         Chris Paul  35654150  2018-19\n",
      "3       LeBron James  35654150  2018-19\n",
      "4         Kyle Lowry  32700000  2018-19\n",
      "Processing season: 2018-19\n",
      "Scraped team salary data for season 2018-19:\n",
      "        Team  Team_Salary   Season\n",
      "0    Phoenix    231297508  2018-19\n",
      "1  Minnesota    209038266  2018-19\n",
      "2     Boston    204431315  2018-19\n",
      "3  Milwaukee    196680310  2018-19\n",
      "4      Miami    190849391  2018-19\n",
      "Fetching data using CommonAllPlayers (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Fetched 4973 players for season 2018-19\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201939}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201939}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Stephen Curry in season 2018-19: {'PER': 24.4, 'TS%': 0.641, '3PAr': 0.604, 'FTr': 0.214, 'ORB%': 2.2, 'DRB%': 14.2, 'TRB%': 8.4, 'AST%': 24.2, 'STL%': 1.9, 'BLK%': 0.9, 'TOV%': 11.6, 'USG%': 30.4, 'OWS': 7.2, 'DWS': 2.5, 'WS': 9.7, 'WS/48': 0.199, 'OBPM': 7.1, 'DBPM': -0.5, 'BPM': 6.6, 'VORP': 5.1}\n",
      "Processed data for Stephen Curry in season 2018-19: {'Position': 'Guard', 'Age': 31.0, 'Team': 'GSW', 'TeamID': 1610612744, 'Years of Service': 9, 'GP': 69, 'GS': 69, 'MP': 2331.0, 'FG': 632, 'FGA': 1340, 'FG%': 0.472, '3P': 354, '3PA': 810, '3P%': 0.437, '2P': 278, '2PA': 530, '2P%': 0.5245283018867924, 'eFG%': 0.6037313432835821, 'FT': 263, 'FTA': 287, 'FT%': 0.916, 'ORB': 45, 'DRB': 324, 'TRB': 369, 'AST': 361, 'STL': 92, 'BLK': 25, 'TOV': 192, 'PF': 166, 'PTS': 1881, 'PER': 24.4, 'TS%': 0.641, '3PAr': 0.604, 'FTr': 0.214, 'ORB%': 2.2, 'DRB%': 14.2, 'TRB%': 8.4, 'AST%': 24.2, 'STL%': 1.9, 'BLK%': 0.9, 'TOV%': 11.6, 'USG%': 30.4, 'OWS': 7.2, 'DWS': 2.5, 'WS': 9.7, 'WS/48': 0.199, 'OBPM': 7.1, 'DBPM': -0.5, 'BPM': 6.6, 'VORP': 5.1, 'Wins': 57, 'Losses': 25, 'Player': 'Stephen Curry', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201566}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201566}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Russell Westbrook in season 2018-19: {'PER': 21.1, 'TS%': 0.501, '3PAr': 0.279, 'FTr': 0.306, 'ORB%': 4.1, 'DRB%': 28.3, 'TRB%': 15.8, 'AST%': 46.5, 'STL%': 2.5, 'BLK%': 1.1, 'TOV%': 16.3, 'USG%': 30.9, 'OWS': 1.8, 'DWS': 5.0, 'WS': 6.8, 'WS/48': 0.124, 'OBPM': 2.8, 'DBPM': 2.4, 'BPM': 5.2, 'VORP': 4.7}\n",
      "Processed data for Russell Westbrook in season 2018-19: {'Position': 'Guard', 'Age': 30.0, 'Team': 'OKC', 'TeamID': 1610612760, 'Years of Service': 10, 'GP': 73, 'GS': 73, 'MP': 2629.0, 'FG': 630, 'FGA': 1473, 'FG%': 0.428, '3P': 119, '3PA': 411, '3P%': 0.29, '2P': 511, '2PA': 1062, '2P%': 0.4811676082862524, 'eFG%': 0.4680923285811269, 'FT': 296, 'FTA': 451, 'FT%': 0.656, 'ORB': 109, 'DRB': 698, 'TRB': 807, 'AST': 784, 'STL': 142, 'BLK': 33, 'TOV': 325, 'PF': 245, 'PTS': 1675, 'PER': 21.1, 'TS%': 0.501, '3PAr': 0.279, 'FTr': 0.306, 'ORB%': 4.1, 'DRB%': 28.3, 'TRB%': 15.8, 'AST%': 46.5, 'STL%': 2.5, 'BLK%': 1.1, 'TOV%': 16.3, 'USG%': 30.9, 'OWS': 1.8, 'DWS': 5.0, 'WS': 6.8, 'WS/48': 0.124, 'OBPM': 2.8, 'DBPM': 2.4, 'BPM': 5.2, 'VORP': 4.7, 'Wins': 49, 'Losses': 33, 'Player': 'Russell Westbrook', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 101108}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 101108}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Chris Paul in season 2018-19: {'PER': 19.7, 'TS%': 0.56, '3PAr': 0.493, 'FTr': 0.282, 'ORB%': 2.1, 'DRB%': 13.9, 'TRB%': 7.9, 'AST%': 39.3, 'STL%': 3.0, 'BLK%': 0.8, 'TOV%': 15.8, 'USG%': 22.5, 'OWS': 4.4, 'DWS': 2.2, 'WS': 6.6, 'WS/48': 0.172, 'OBPM': 2.7, 'DBPM': 1.1, 'BPM': 3.9, 'VORP': 2.8}\n",
      "Processed data for Chris Paul in season 2018-19: {'Position': 'Guard', 'Age': 34.0, 'Team': 'HOU', 'TeamID': 1610612745, 'Years of Service': 13, 'GP': 58, 'GS': 58, 'MP': 1857.0, 'FG': 302, 'FGA': 720, 'FG%': 0.419, '3P': 127, '3PA': 355, '3P%': 0.358, '2P': 175, '2PA': 365, '2P%': 0.4794520547945205, 'eFG%': 0.5076388888888889, 'FT': 175, 'FTA': 203, 'FT%': 0.862, 'ORB': 36, 'DRB': 229, 'TRB': 265, 'AST': 473, 'STL': 114, 'BLK': 18, 'TOV': 152, 'PF': 146, 'PTS': 906, 'PER': 19.7, 'TS%': 0.56, '3PAr': 0.493, 'FTr': 0.282, 'ORB%': 2.1, 'DRB%': 13.9, 'TRB%': 7.9, 'AST%': 39.3, 'STL%': 3.0, 'BLK%': 0.8, 'TOV%': 15.8, 'USG%': 22.5, 'OWS': 4.4, 'DWS': 2.2, 'WS': 6.6, 'WS/48': 0.172, 'OBPM': 2.7, 'DBPM': 1.1, 'BPM': 3.9, 'VORP': 2.8, 'Wins': 53, 'Losses': 29, 'Player': 'Chris Paul', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for LeBron James in season 2018-19: {'PER': 25.6, 'TS%': 0.588, '3PAr': 0.299, 'FTr': 0.382, 'ORB%': 3.1, 'DRB%': 21.3, 'TRB%': 12.4, 'AST%': 39.4, 'STL%': 1.7, 'BLK%': 1.4, 'TOV%': 13.3, 'USG%': 31.6, 'OWS': 4.7, 'DWS': 2.6, 'WS': 7.2, 'WS/48': 0.179, 'OBPM': 6.4, 'DBPM': 1.7, 'BPM': 8.0, 'VORP': 4.9}\n",
      "Processed data for LeBron James in season 2018-19: {'Position': 'Forward', 'Age': 34.0, 'Team': 'LAL', 'TeamID': 1610612747, 'Years of Service': 15, 'GP': 55, 'GS': 55, 'MP': 1937.0, 'FG': 558, 'FGA': 1095, 'FG%': 0.51, '3P': 111, '3PA': 327, '3P%': 0.339, '2P': 447, '2PA': 768, '2P%': 0.58203125, 'eFG%': 0.5602739726027397, 'FT': 278, 'FTA': 418, 'FT%': 0.665, 'ORB': 57, 'DRB': 408, 'TRB': 465, 'AST': 454, 'STL': 72, 'BLK': 33, 'TOV': 197, 'PF': 94, 'PTS': 1505, 'PER': 25.6, 'TS%': 0.588, '3PAr': 0.299, 'FTr': 0.382, 'ORB%': 3.1, 'DRB%': 21.3, 'TRB%': 12.4, 'AST%': 39.4, 'STL%': 1.7, 'BLK%': 1.4, 'TOV%': 13.3, 'USG%': 31.6, 'OWS': 4.7, 'DWS': 2.6, 'WS': 7.2, 'WS/48': 0.179, 'OBPM': 6.4, 'DBPM': 1.7, 'BPM': 8.0, 'VORP': 4.9, 'Wins': 37, 'Losses': 45, 'Player': 'LeBron James', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 200768}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 200768}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Kyle Lowry in season 2018-19: {'PER': 16.5, 'TS%': 0.562, '3PAr': 0.613, 'FTr': 0.263, 'ORB%': 2.1, 'DRB%': 12.9, 'TRB%': 7.6, 'AST%': 34.8, 'STL%': 2.0, 'BLK%': 1.2, 'TOV%': 18.1, 'USG%': 19.6, 'OWS': 3.6, 'DWS': 3.0, 'WS': 6.6, 'WS/48': 0.144, 'OBPM': 1.7, 'DBPM': 0.6, 'BPM': 2.3, 'VORP': 2.4}\n",
      "Processed data for Kyle Lowry in season 2018-19: {'Position': 'Guard', 'Age': 33.0, 'Team': 'TOR', 'TeamID': 1610612761, 'Years of Service': 12, 'GP': 65, 'GS': 65, 'MP': 2213.0, 'FG': 304, 'FGA': 739, 'FG%': 0.411, '3P': 157, '3PA': 453, '3P%': 0.347, '2P': 147, '2PA': 286, '2P%': 0.513986013986014, 'eFG%': 0.5175913396481732, 'FT': 161, 'FTA': 194, 'FT%': 0.83, 'ORB': 41, 'DRB': 271, 'TRB': 312, 'AST': 564, 'STL': 91, 'BLK': 31, 'TOV': 182, 'PF': 166, 'PTS': 926, 'PER': 16.5, 'TS%': 0.562, '3PAr': 0.613, 'FTr': 0.263, 'ORB%': 2.1, 'DRB%': 12.9, 'TRB%': 7.6, 'AST%': 34.8, 'STL%': 2.0, 'BLK%': 1.2, 'TOV%': 18.1, 'USG%': 19.6, 'OWS': 3.6, 'DWS': 3.0, 'WS': 6.6, 'WS/48': 0.144, 'OBPM': 1.7, 'DBPM': 0.6, 'BPM': 2.3, 'VORP': 2.4, 'Wins': 58, 'Losses': 24, 'Player': 'Kyle Lowry', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201933}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201933}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Blake Griffin in season 2018-19: {'PER': 21.0, 'TS%': 0.581, '3PAr': 0.389, 'FTr': 0.41, 'ORB%': 4.0, 'DRB%': 20.1, 'TRB%': 11.8, 'AST%': 27.1, 'STL%': 1.0, 'BLK%': 0.9, 'TOV%': 13.8, 'USG%': 30.2, 'OWS': 5.1, 'DWS': 2.9, 'WS': 8.0, 'WS/48': 0.147, 'OBPM': 4.9, 'DBPM': 0.2, 'BPM': 5.1, 'VORP': 4.7}\n",
      "Processed data for Blake Griffin in season 2018-19: {'Position': 'Forward', 'Age': 30.0, 'Team': 'DET', 'TeamID': 1610612765, 'Years of Service': 9, 'GP': 75, 'GS': 75, 'MP': 2622.0, 'FG': 619, 'FGA': 1341, 'FG%': 0.462, '3P': 189, '3PA': 522, '3P%': 0.362, '2P': 430, '2PA': 819, '2P%': 0.525030525030525, 'eFG%': 0.5320656226696495, 'FT': 414, 'FTA': 550, 'FT%': 0.753, 'ORB': 100, 'DRB': 465, 'TRB': 565, 'AST': 402, 'STL': 52, 'BLK': 28, 'TOV': 253, 'PF': 199, 'PTS': 1841, 'PER': 21.0, 'TS%': 0.581, '3PAr': 0.389, 'FTr': 0.41, 'ORB%': 4.0, 'DRB%': 20.1, 'TRB%': 11.8, 'AST%': 27.1, 'STL%': 1.0, 'BLK%': 0.9, 'TOV%': 13.8, 'USG%': 30.2, 'OWS': 5.1, 'DWS': 2.9, 'WS': 8.0, 'WS/48': 0.147, 'OBPM': 4.9, 'DBPM': 0.2, 'BPM': 5.1, 'VORP': 4.7, 'Wins': 41, 'Losses': 41, 'Player': 'Blake Griffin', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 202330}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 202330}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Gordon Hayward in season 2018-19: {'PER': 15.6, 'TS%': 0.575, '3PAr': 0.364, 'FTr': 0.294, 'ORB%': 2.9, 'DRB%': 15.5, 'TRB%': 9.2, 'AST%': 18.4, 'STL%': 1.6, 'BLK%': 1.1, 'TOV%': 12.8, 'USG%': 19.1, 'OWS': 2.6, 'DWS': 2.2, 'WS': 4.8, 'WS/48': 0.123, 'OBPM': 0.4, 'DBPM': 0.4, 'BPM': 0.8, 'VORP': 1.3}\n",
      "Processed data for Gordon Hayward in season 2018-19: {'Position': 'Forward', 'Age': 29.0, 'Team': 'BOS', 'TeamID': 1610612738, 'Years of Service': 8, 'GP': 72, 'GS': 18, 'MP': 1863.0, 'FG': 296, 'FGA': 635, 'FG%': 0.466, '3P': 77, '3PA': 231, '3P%': 0.333, '2P': 219, '2PA': 404, '2P%': 0.5420792079207921, 'eFG%': 0.5267716535433071, 'FT': 156, 'FTA': 187, 'FT%': 0.834, 'ORB': 51, 'DRB': 271, 'TRB': 322, 'AST': 244, 'STL': 62, 'BLK': 23, 'TOV': 105, 'PF': 104, 'PTS': 825, 'PER': 15.6, 'TS%': 0.575, '3PAr': 0.364, 'FTr': 0.294, 'ORB%': 2.9, 'DRB%': 15.5, 'TRB%': 9.2, 'AST%': 18.4, 'STL%': 1.6, 'BLK%': 1.1, 'TOV%': 12.8, 'USG%': 19.1, 'OWS': 2.6, 'DWS': 2.2, 'WS': 4.8, 'WS/48': 0.123, 'OBPM': 0.4, 'DBPM': 0.4, 'BPM': 0.8, 'VORP': 1.3, 'Wins': 49, 'Losses': 33, 'Player': 'Gordon Hayward', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201935}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201935}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for James Harden in season 2018-19: {'PER': 30.6, 'TS%': 0.616, '3PAr': 0.539, 'FTr': 0.449, 'ORB%': 2.5, 'DRB%': 17.8, 'TRB%': 10.0, 'AST%': 39.5, 'STL%': 2.7, 'BLK%': 1.7, 'TOV%': 14.5, 'USG%': 40.5, 'OWS': 11.4, 'DWS': 3.8, 'WS': 15.2, 'WS/48': 0.254, 'OBPM': 9.4, 'DBPM': 1.6, 'BPM': 11.0, 'VORP': 9.3}\n",
      "Processed data for James Harden in season 2018-19: {'Position': 'Guard', 'Age': 29.0, 'Team': 'HOU', 'TeamID': 1610612745, 'Years of Service': 9, 'GP': 78, 'GS': 78, 'MP': 2867.0, 'FG': 843, 'FGA': 1909, 'FG%': 0.442, '3P': 378, '3PA': 1028, '3P%': 0.368, '2P': 465, '2PA': 881, '2P%': 0.5278093076049943, 'eFG%': 0.5405971712938711, 'FT': 754, 'FTA': 858, 'FT%': 0.879, 'ORB': 66, 'DRB': 452, 'TRB': 518, 'AST': 586, 'STL': 158, 'BLK': 58, 'TOV': 387, 'PF': 244, 'PTS': 2818, 'PER': 30.6, 'TS%': 0.616, '3PAr': 0.539, 'FTr': 0.449, 'ORB%': 2.5, 'DRB%': 17.8, 'TRB%': 10.0, 'AST%': 39.5, 'STL%': 2.7, 'BLK%': 1.7, 'TOV%': 14.5, 'USG%': 40.5, 'OWS': 11.4, 'DWS': 3.8, 'WS': 15.2, 'WS/48': 0.254, 'OBPM': 9.4, 'DBPM': 1.6, 'BPM': 11.0, 'VORP': 9.3, 'Wins': 53, 'Losses': 29, 'Player': 'James Harden', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 202331}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 202331}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Paul George in season 2018-19: {'PER': 23.3, 'TS%': 0.583, '3PAr': 0.469, 'FTr': 0.335, 'ORB%': 3.7, 'DRB%': 19.6, 'TRB%': 11.4, 'AST%': 17.7, 'STL%': 2.8, 'BLK%': 1.0, 'TOV%': 10.0, 'USG%': 29.5, 'OWS': 7.0, 'DWS': 4.9, 'WS': 11.9, 'WS/48': 0.201, 'OBPM': 5.6, 'DBPM': 1.6, 'BPM': 7.2, 'VORP': 6.6}\n",
      "Processed data for Paul George in season 2018-19: {'Position': 'Forward', 'Age': 29.0, 'Team': 'OKC', 'TeamID': 1610612760, 'Years of Service': 8, 'GP': 77, 'GS': 77, 'MP': 2841.0, 'FG': 707, 'FGA': 1614, 'FG%': 0.438, '3P': 292, '3PA': 757, '3P%': 0.386, '2P': 415, '2PA': 857, '2P%': 0.48424737456242706, 'eFG%': 0.5285006195786865, 'FT': 453, 'FTA': 540, 'FT%': 0.839, 'ORB': 105, 'DRB': 523, 'TRB': 628, 'AST': 318, 'STL': 170, 'BLK': 34, 'TOV': 205, 'PF': 214, 'PTS': 2159, 'PER': 23.3, 'TS%': 0.583, '3PAr': 0.469, 'FTr': 0.335, 'ORB%': 3.7, 'DRB%': 19.6, 'TRB%': 11.4, 'AST%': 17.7, 'STL%': 2.8, 'BLK%': 1.0, 'TOV%': 10.0, 'USG%': 29.5, 'OWS': 7.0, 'DWS': 4.9, 'WS': 11.9, 'WS/48': 0.201, 'OBPM': 5.6, 'DBPM': 1.6, 'BPM': 7.2, 'VORP': 6.6, 'Wins': 49, 'Losses': 33, 'Player': 'Paul George', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201144}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201144}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Mike Conley in season 2018-19: {'PER': 21.4, 'TS%': 0.569, '3PAr': 0.38, 'FTr': 0.363, 'ORB%': 1.9, 'DRB%': 9.7, 'TRB%': 5.7, 'AST%': 33.4, 'STL%': 2.0, 'BLK%': 0.9, 'TOV%': 9.1, 'USG%': 27.3, 'OWS': 5.7, 'DWS': 2.3, 'WS': 8.0, 'WS/48': 0.164, 'OBPM': 4.6, 'DBPM': 0.1, 'BPM': 4.7, 'VORP': 3.9}\n",
      "Processed data for Mike Conley in season 2018-19: {'Position': 'Guard', 'Age': 31.0, 'Team': 'MEM', 'TeamID': 1610612763, 'Years of Service': 11, 'GP': 70, 'GS': 70, 'MP': 2342.0, 'FG': 490, 'FGA': 1120, 'FG%': 0.438, '3P': 155, '3PA': 426, '3P%': 0.364, '2P': 335, '2PA': 694, '2P%': 0.4827089337175792, 'eFG%': 0.5066964285714286, 'FT': 343, 'FTA': 406, 'FT%': 0.845, 'ORB': 40, 'DRB': 199, 'TRB': 239, 'AST': 449, 'STL': 94, 'BLK': 22, 'TOV': 130, 'PF': 123, 'PTS': 1478, 'PER': 21.4, 'TS%': 0.569, '3PAr': 0.38, 'FTr': 0.363, 'ORB%': 1.9, 'DRB%': 9.7, 'TRB%': 5.7, 'AST%': 33.4, 'STL%': 2.0, 'BLK%': 0.9, 'TOV%': 9.1, 'USG%': 27.3, 'OWS': 5.7, 'DWS': 2.3, 'WS': 8.0, 'WS/48': 0.164, 'OBPM': 4.6, 'DBPM': 0.1, 'BPM': 4.7, 'VORP': 3.9, 'Wins': 33, 'Losses': 49, 'Player': 'Mike Conley', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201142}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201142}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Kevin Durant in season 2018-19: {'PER': 24.2, 'TS%': 0.631, '3PAr': 0.281, 'FTr': 0.366, 'ORB%': 1.4, 'DRB%': 17.5, 'TRB%': 9.8, 'AST%': 26.2, 'STL%': 1.0, 'BLK%': 2.6, 'TOV%': 12.3, 'USG%': 29.0, 'OWS': 8.6, 'DWS': 2.9, 'WS': 11.5, 'WS/48': 0.204, 'OBPM': 5.4, 'DBPM': 0.1, 'BPM': 5.5, 'VORP': 5.1}\n",
      "Processed data for Kevin Durant in season 2018-19: {'Position': 'Forward', 'Age': 30.0, 'Team': 'GSW', 'TeamID': 1610612744, 'Years of Service': 11, 'GP': 78, 'GS': 78, 'MP': 2702.0, 'FG': 721, 'FGA': 1383, 'FG%': 0.521, '3P': 137, '3PA': 388, '3P%': 0.353, '2P': 584, '2PA': 995, '2P%': 0.5869346733668341, 'eFG%': 0.5708604483007954, 'FT': 448, 'FTA': 506, 'FT%': 0.885, 'ORB': 33, 'DRB': 464, 'TRB': 497, 'AST': 457, 'STL': 58, 'BLK': 84, 'TOV': 225, 'PF': 155, 'PTS': 2027, 'PER': 24.2, 'TS%': 0.631, '3PAr': 0.281, 'FTr': 0.366, 'ORB%': 1.4, 'DRB%': 17.5, 'TRB%': 9.8, 'AST%': 26.2, 'STL%': 1.0, 'BLK%': 2.6, 'TOV%': 12.3, 'USG%': 29.0, 'OWS': 8.6, 'DWS': 2.9, 'WS': 11.5, 'WS/48': 0.204, 'OBPM': 5.4, 'DBPM': 0.1, 'BPM': 5.5, 'VORP': 5.1, 'Wins': 57, 'Losses': 25, 'Player': 'Kevin Durant', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 200794}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 200794}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Paul Millsap in season 2018-19: {'PER': 17.9, 'TS%': 0.57, '3PAr': 0.239, 'FTr': 0.374, 'ORB%': 8.7, 'DRB%': 20.2, 'TRB%': 14.4, 'AST%': 10.6, 'STL%': 2.2, 'BLK%': 2.5, 'TOV%': 10.9, 'USG%': 19.6, 'OWS': 3.2, 'DWS': 2.9, 'WS': 6.1, 'WS/48': 0.155, 'OBPM': 0.7, 'DBPM': 1.0, 'BPM': 1.7, 'VORP': 1.8}\n",
      "Processed data for Paul Millsap in season 2018-19: {'Position': 'Forward', 'Age': 34.0, 'Team': 'DEN', 'TeamID': 1610612743, 'Years of Service': 12, 'GP': 70, 'GS': 65, 'MP': 1895.0, 'FG': 322, 'FGA': 665, 'FG%': 0.484, '3P': 58, '3PA': 159, '3P%': 0.365, '2P': 264, '2PA': 506, '2P%': 0.5217391304347826, 'eFG%': 0.5278195488721804, 'FT': 181, 'FTA': 249, 'FT%': 0.727, 'ORB': 153, 'DRB': 352, 'TRB': 505, 'AST': 141, 'STL': 83, 'BLK': 54, 'TOV': 95, 'PF': 183, 'PTS': 883, 'PER': 17.9, 'TS%': 0.57, '3PAr': 0.239, 'FTr': 0.374, 'ORB%': 8.7, 'DRB%': 20.2, 'TRB%': 14.4, 'AST%': 10.6, 'STL%': 2.2, 'BLK%': 2.5, 'TOV%': 10.9, 'USG%': 19.6, 'OWS': 3.2, 'DWS': 2.9, 'WS': 6.1, 'WS/48': 0.155, 'OBPM': 0.7, 'DBPM': 1.0, 'BPM': 1.7, 'VORP': 1.8, 'Wins': 54, 'Losses': 28, 'Player': 'Paul Millsap', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201143}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201143}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Al Horford in season 2018-19: {'PER': 20.2, 'TS%': 0.605, '3PAr': 0.281, 'FTr': 0.131, 'ORB%': 6.5, 'DRB%': 18.3, 'TRB%': 12.4, 'AST%': 21.2, 'STL%': 1.4, 'BLK%': 3.9, 'TOV%': 11.8, 'USG%': 19.0, 'OWS': 4.5, 'DWS': 2.8, 'WS': 7.4, 'WS/48': 0.179, 'OBPM': 3.3, 'DBPM': 1.9, 'BPM': 5.1, 'VORP': 3.6}\n",
      "Processed data for Al Horford in season 2018-19: {'Position': 'Center-Forward', 'Age': 33.0, 'Team': 'BOS', 'TeamID': 1610612738, 'Years of Service': 11, 'GP': 68, 'GS': 68, 'MP': 1973.0, 'FG': 387, 'FGA': 723, 'FG%': 0.535, '3P': 73, '3PA': 203, '3P%': 0.36, '2P': 314, '2PA': 520, '2P%': 0.6038461538461538, 'eFG%': 0.5857538035961273, 'FT': 78, 'FTA': 95, 'FT%': 0.821, 'ORB': 120, 'DRB': 338, 'TRB': 458, 'AST': 283, 'STL': 59, 'BLK': 86, 'TOV': 102, 'PF': 126, 'PTS': 925, 'PER': 20.2, 'TS%': 0.605, '3PAr': 0.281, 'FTr': 0.131, 'ORB%': 6.5, 'DRB%': 18.3, 'TRB%': 12.4, 'AST%': 21.2, 'STL%': 1.4, 'BLK%': 3.9, 'TOV%': 11.8, 'USG%': 19.0, 'OWS': 4.5, 'DWS': 2.8, 'WS': 7.4, 'WS/48': 0.179, 'OBPM': 3.3, 'DBPM': 1.9, 'BPM': 5.1, 'VORP': 3.6, 'Wins': 49, 'Losses': 33, 'Player': 'Al Horford', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 203081}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 203081}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for Damian Lillard in season 2018-19: {'PER': 23.7, 'TS%': 0.588, '3PAr': 0.419, 'FTr': 0.335, 'ORB%': 2.6, 'DRB%': 11.1, 'TRB%': 7.0, 'AST%': 30.6, 'STL%': 1.5, 'BLK%': 1.0, 'TOV%': 10.8, 'USG%': 29.3, 'OWS': 9.7, 'DWS': 2.4, 'WS': 12.1, 'WS/48': 0.205, 'OBPM': 6.6, 'DBPM': -0.3, 'BPM': 6.4, 'VORP': 6.0}\n",
      "Processed data for Damian Lillard in season 2018-19: {'Position': 'Guard', 'Age': 28.0, 'Team': 'POR', 'TeamID': 1610612757, 'Years of Service': 6, 'GP': 80, 'GS': 80, 'MP': 2838.0, 'FG': 681, 'FGA': 1533, 'FG%': 0.444, '3P': 237, '3PA': 643, '3P%': 0.369, '2P': 444, '2PA': 890, '2P%': 0.49887640449438203, 'eFG%': 0.5215264187866928, 'FT': 468, 'FTA': 513, 'FT%': 0.912, 'ORB': 68, 'DRB': 303, 'TRB': 371, 'AST': 551, 'STL': 88, 'BLK': 34, 'TOV': 212, 'PF': 148, 'PTS': 2067, 'PER': 23.7, 'TS%': 0.588, '3PAr': 0.419, 'FTr': 0.335, 'ORB%': 2.6, 'DRB%': 11.1, 'TRB%': 7.0, 'AST%': 30.6, 'STL%': 1.5, 'BLK%': 1.0, 'TOV%': 10.8, 'USG%': 29.3, 'OWS': 9.7, 'DWS': 2.4, 'WS': 12.1, 'WS/48': 0.205, 'OBPM': 6.6, 'DBPM': -0.3, 'BPM': 6.4, 'VORP': 6.0, 'Wins': 53, 'Losses': 29, 'Player': 'Damian Lillard', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 201942}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 201942}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "Scraped advanced metrics for DeMar DeRozan in season 2018-19: {'PER': 19.5, 'TS%': 0.542, '3PAr': 0.034, 'FTr': 0.336, 'ORB%': 2.2, 'DRB%': 16.4, 'TRB%': 9.4, 'AST%': 27.6, 'STL%': 1.6, 'BLK%': 1.1, 'TOV%': 11.7, 'USG%': 27.9, 'OWS': 3.6, 'DWS': 2.6, 'WS': 6.3, 'WS/48': 0.112, 'OBPM': 1.0, 'DBPM': 0.1, 'BPM': 1.1, 'VORP': 2.2}\n",
      "Processed data for DeMar DeRozan in season 2018-19: {'Position': 'Guard-Forward', 'Age': 29.0, 'Team': 'SAS', 'TeamID': 1610612759, 'Years of Service': 9, 'GP': 77, 'GS': 77, 'MP': 2688.0, 'FG': 631, 'FGA': 1313, 'FG%': 0.481, '3P': 7, '3PA': 45, '3P%': 0.156, '2P': 624, '2PA': 1268, '2P%': 0.4921135646687697, 'eFG%': 0.48324447829398326, 'FT': 366, 'FTA': 441, 'FT%': 0.83, 'ORB': 54, 'DRB': 408, 'TRB': 462, 'AST': 475, 'STL': 86, 'BLK': 36, 'TOV': 199, 'PF': 177, 'PTS': 1635, 'PER': 19.5, 'TS%': 0.542, '3PAr': 0.034, 'FTr': 0.336, 'ORB%': 2.2, 'DRB%': 16.4, 'TRB%': 9.4, 'AST%': 27.6, 'STL%': 1.6, 'BLK%': 1.1, 'TOV%': 11.7, 'USG%': 27.9, 'OWS': 3.6, 'DWS': 2.6, 'WS': 6.3, 'WS/48': 0.112, 'OBPM': 1.0, 'DBPM': 0.1, 'BPM': 1.1, 'VORP': 2.2, 'Wins': 48, 'Losses': 34, 'Player': 'DeMar DeRozan', 'Season': '2018-19'}\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 2547}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 2547}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2018-19'}\n",
      "No advanced metrics found for Chris Bosh in season 2018-19\n",
      "Retrying in 60 seconds...\n",
      "No advanced metrics found for Chris Bosh in season 2018-19\n",
      "Retrying in 60 seconds...\n"
     ]
    }
   ],
   "source": [
    "!python main.py --debug --start_year 2018 --end_year 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
