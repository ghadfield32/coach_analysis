{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data using CommonAllPlayers (Attempt 1) with parameters: {'season': '2022-23'}\n",
      "Fetched 4972 players for season 2022-23\n",
      "Total players fetched: 4972\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Sample player info for LeBron James:\n",
      "   PERSON_ID FIRST_NAME LAST_NAME DISPLAY_FIRST_LAST DISPLAY_LAST_COMMA_FIRST  \\\n",
      "0       2544     LeBron     James       LeBron James            James, LeBron   \n",
      "\n",
      "  DISPLAY_FI_LAST   PLAYER_SLUG            BIRTHDATE  \\\n",
      "0        L. James  lebron-james  1984-12-30T00:00:00   \n",
      "\n",
      "                         SCHOOL COUNTRY  ...    PLAYERCODE FROM_YEAR TO_YEAR  \\\n",
      "0  St. Vincent-St. Mary HS (OH)     USA  ...  lebron_james      2003    2024   \n",
      "\n",
      "   DLEAGUE_FLAG NBA_FLAG GAMES_PLAYED_FLAG DRAFT_YEAR DRAFT_ROUND  \\\n",
      "0             N        Y                 Y       2003           1   \n",
      "\n",
      "   DRAFT_NUMBER GREATEST_75_FLAG  \n",
      "0             1                Y  \n",
      "\n",
      "[1 rows x 33 columns]\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Sample player career stats for LeBron James:\n",
      "    PLAYER_ID SEASON_ID LEAGUE_ID     TEAM_ID TEAM_ABBREVIATION  PLAYER_AGE  \\\n",
      "0        2544   2003-04        00  1610612739               CLE        19.0   \n",
      "1        2544   2004-05        00  1610612739               CLE        20.0   \n",
      "2        2544   2005-06        00  1610612739               CLE        21.0   \n",
      "3        2544   2006-07        00  1610612739               CLE        22.0   \n",
      "4        2544   2007-08        00  1610612739               CLE        23.0   \n",
      "5        2544   2008-09        00  1610612739               CLE        24.0   \n",
      "6        2544   2009-10        00  1610612739               CLE        25.0   \n",
      "7        2544   2010-11        00  1610612748               MIA        26.0   \n",
      "8        2544   2011-12        00  1610612748               MIA        27.0   \n",
      "9        2544   2012-13        00  1610612748               MIA        28.0   \n",
      "10       2544   2013-14        00  1610612748               MIA        29.0   \n",
      "11       2544   2014-15        00  1610612739               CLE        30.0   \n",
      "12       2544   2015-16        00  1610612739               CLE        31.0   \n",
      "13       2544   2016-17        00  1610612739               CLE        32.0   \n",
      "14       2544   2017-18        00  1610612739               CLE        33.0   \n",
      "15       2544   2018-19        00  1610612747               LAL        34.0   \n",
      "16       2544   2019-20        00  1610612747               LAL        35.0   \n",
      "17       2544   2020-21        00  1610612747               LAL        36.0   \n",
      "18       2544   2021-22        00  1610612747               LAL        37.0   \n",
      "19       2544   2022-23        00  1610612747               LAL        38.0   \n",
      "20       2544   2023-24        00  1610612747               LAL        39.0   \n",
      "\n",
      "    GP  GS     MIN  FGM  ...  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  \\\n",
      "0   79  79  3120.0  622  ...   0.754    99   333  432  465  130   58  273   \n",
      "1   80  80  3388.0  795  ...   0.750   111   477  588  577  177   52  262   \n",
      "2   79  79  3361.0  875  ...   0.738    75   481  556  521  123   66  260   \n",
      "3   78  78  3190.0  772  ...   0.698    83   443  526  470  125   55  250   \n",
      "4   75  74  3027.0  794  ...   0.712   133   459  592  539  138   81  255   \n",
      "5   81  81  3054.0  789  ...   0.780   106   507  613  587  137   93  241   \n",
      "6   76  76  2966.0  768  ...   0.767    71   483  554  651  125   77  261   \n",
      "7   79  79  3063.0  758  ...   0.759    80   510  590  554  124   50  284   \n",
      "8   62  62  2326.0  621  ...   0.771    94   398  492  387  115   50  213   \n",
      "9   76  76  2877.0  765  ...   0.753    97   513  610  551  129   67  226   \n",
      "10  77  77  2902.0  767  ...   0.750    81   452  533  488  121   26  270   \n",
      "11  69  69  2493.0  624  ...   0.710    51   365  416  511  109   49  272   \n",
      "12  76  76  2709.0  737  ...   0.731   111   454  565  514  104   49  249   \n",
      "13  74  74  2795.0  736  ...   0.674    97   542  639  646   92   44  303   \n",
      "14  82  82  3026.0  857  ...   0.731    97   612  709  747  116   71  347   \n",
      "15  55  55  1937.0  558  ...   0.665    57   408  465  454   72   33  197   \n",
      "16  67  67  2316.0  643  ...   0.693    66   459  525  684   78   36  261   \n",
      "17  45  45  1504.0  422  ...   0.698    29   317  346  350   48   25  168   \n",
      "18  56  56  2084.0  640  ...   0.756    63   396  459  349   73   59  196   \n",
      "19  55  54  1954.0  609  ...   0.768    65   392  457  375   50   32  178   \n",
      "20  71  71  2504.0  685  ...   0.750    61   457  518  589   89   38  245   \n",
      "\n",
      "     PF   PTS  \n",
      "0   149  1654  \n",
      "1   146  2175  \n",
      "2   181  2478  \n",
      "3   171  2132  \n",
      "4   165  2250  \n",
      "5   139  2304  \n",
      "6   119  2258  \n",
      "7   163  2111  \n",
      "8    96  1683  \n",
      "9   110  2036  \n",
      "10  126  2089  \n",
      "11  135  1743  \n",
      "12  143  1920  \n",
      "13  134  1954  \n",
      "14  136  2251  \n",
      "15   94  1505  \n",
      "16  118  1698  \n",
      "17   70  1126  \n",
      "18  121  1695  \n",
      "19   88  1590  \n",
      "20   78  1822  \n",
      "\n",
      "[21 rows x 27 columns]\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2022-23'}\n",
      "League standings:\n",
      "   LeagueID SeasonID      TeamID       TeamCity       TeamName Conference  \\\n",
      "0        00    22022  1610612743         Denver        Nuggets       West   \n",
      "1        00    22022  1610612749      Milwaukee          Bucks       East   \n",
      "2        00    22022  1610612763        Memphis      Grizzlies       West   \n",
      "3        00    22022  1610612738         Boston        Celtics       East   \n",
      "4        00    22022  1610612755   Philadelphia          76ers       East   \n",
      "5        00    22022  1610612758     Sacramento          Kings       West   \n",
      "6        00    22022  1610612739      Cleveland      Cavaliers       East   \n",
      "7        00    22022  1610612756        Phoenix           Suns       West   \n",
      "8        00    22022  1610612752       New York         Knicks       East   \n",
      "9        00    22022  1610612746             LA       Clippers       West   \n",
      "10       00    22022  1610612751       Brooklyn           Nets       East   \n",
      "11       00    22022  1610612744   Golden State       Warriors       West   \n",
      "12       00    22022  1610612747    Los Angeles         Lakers       West   \n",
      "13       00    22022  1610612748          Miami           Heat       East   \n",
      "14       00    22022  1610612737        Atlanta          Hawks       East   \n",
      "15       00    22022  1610612750      Minnesota   Timberwolves       West   \n",
      "16       00    22022  1610612761        Toronto        Raptors       East   \n",
      "17       00    22022  1610612740    New Orleans       Pelicans       West   \n",
      "18       00    22022  1610612741        Chicago          Bulls       East   \n",
      "19       00    22022  1610612760  Oklahoma City        Thunder       West   \n",
      "20       00    22022  1610612754        Indiana         Pacers       East   \n",
      "21       00    22022  1610612742         Dallas      Mavericks       West   \n",
      "22       00    22022  1610612762           Utah           Jazz       West   \n",
      "23       00    22022  1610612764     Washington        Wizards       East   \n",
      "24       00    22022  1610612757       Portland  Trail Blazers       West   \n",
      "25       00    22022  1610612753        Orlando          Magic       East   \n",
      "26       00    22022  1610612745        Houston        Rockets       West   \n",
      "27       00    22022  1610612766      Charlotte        Hornets       East   \n",
      "28       00    22022  1610612759    San Antonio          Spurs       West   \n",
      "29       00    22022  1610612765        Detroit        Pistons       East   \n",
      "\n",
      "   ConferenceRecord  PlayoffRank ClinchIndicator   Division  ...   May   Jun  \\\n",
      "0             34-18            1             - w  Northwest  ...  None  None   \n",
      "1             35-17            1             - e    Central  ...  None  None   \n",
      "2             30-22            2            - sw  Southwest  ...  None  None   \n",
      "3             34-18            2             - a   Atlantic  ...  None  None   \n",
      "4             34-18            3             - x   Atlantic  ...  None  None   \n",
      "5             32-20            3             - p    Pacific  ...  None  None   \n",
      "6             34-18            4             - x    Central  ...  None  None   \n",
      "7             30-22            4             - x    Pacific  ...  None  None   \n",
      "8             32-20            5             - x   Atlantic  ...  None  None   \n",
      "9             27-25            5             - x    Pacific  ...  None  None   \n",
      "10            30-22            6             - x   Atlantic  ...  None  None   \n",
      "11            30-22            6             - x    Pacific  ...  None  None   \n",
      "12            27-25            7                    Pacific  ...  None  None   \n",
      "13            24-28            7            - se  Southeast  ...  None  None   \n",
      "14            26-26            8                  Southeast  ...  None  None   \n",
      "15            29-23            8                  Northwest  ...  None  None   \n",
      "16            26-26            9                   Atlantic  ...  None  None   \n",
      "17            29-23            9                  Southwest  ...  None  None   \n",
      "18            27-25           10                    Central  ...  None  None   \n",
      "19            25-27           10                  Northwest  ...  None  None   \n",
      "20            24-28           11             - o    Central  ...  None  None   \n",
      "21            28-24           11             - o  Southwest  ...  None  None   \n",
      "22            24-28           12             - o  Northwest  ...  None  None   \n",
      "23            21-31           12             - o  Southeast  ...  None  None   \n",
      "24            23-29           13             - o  Northwest  ...  None  None   \n",
      "25            20-32           13             - o  Southeast  ...  None  None   \n",
      "26            12-40           14             - o  Southwest  ...  None  None   \n",
      "27            15-37           14             - o  Southeast  ...  None  None   \n",
      "28            10-42           15             - o  Southwest  ...  None  None   \n",
      "29             8-44           15             - o    Central  ...  None  None   \n",
      "\n",
      "     Jul   Aug   Sep  Oct   Nov   Dec  PreAS PostAS  \n",
      "0   None  None  None  4-3  10-4   9-5  41-18  12-11  \n",
      "1   None  None  None  6-0   9-5   8-7  41-17   17-7  \n",
      "2   None  None  None  4-3   8-6  10-4  35-22   16-9  \n",
      "3   None  None  None  4-2  14-2   8-6  42-17   15-8  \n",
      "4   None  None  None  4-4   8-6   9-4  38-19   16-9  \n",
      "5   None  None  None  2-4   9-5   8-6  32-25   16-9  \n",
      "6   None  None  None  5-1   9-7   9-6  38-23   13-8  \n",
      "7   None  None  None  5-1  10-5  5-11  32-28   13-9  \n",
      "8   None  None  None  3-3   7-9   9-6  33-27   14-8  \n",
      "9   None  None  None  3-4  10-6   8-7  33-28  11-10  \n",
      "10  None  None  None  2-5  10-6  12-1  34-24  11-13  \n",
      "11  None  None  None  3-4   8-7   8-7  29-29   15-9  \n",
      "12  None  None  None  1-5   7-7   7-9  27-32   16-7  \n",
      "13  None  None  None  2-5   8-7   9-6  32-27  12-11  \n",
      "14  None  None  None  4-3   8-7   5-9  29-30  12-11  \n",
      "15  None  None  None  4-3   7-8  5-10  31-30  11-10  \n",
      "16  None  None  None  4-3   7-7  5-10  28-31  13-10  \n",
      "17  None  None  None  4-2   9-6  10-5  30-29  12-11  \n",
      "18  None  None  None  3-4   6-8   7-8  26-33   14-9  \n",
      "19  None  None  None  3-3  6-10   6-8  28-29  12-13  \n",
      "20  None  None  None  3-5   9-4   8-8  26-34   9-13  \n",
      "21  None  None  None  3-3   7-7  11-6  31-29   7-15  \n",
      "22  None  None  None  6-2   7-9   6-9  29-31   8-14  \n",
      "23  None  None  None  3-4   8-7  5-10  28-30   7-17  \n",
      "24  None  None  None  5-1  6-10   7-6  28-30   5-19  \n",
      "25  None  None  None  1-6  4-11   8-7  24-35  10-13  \n",
      "26  None  None  None  1-7   4-9  5-10  13-45   9-15  \n",
      "27  None  None  None  3-4  3-11  4-12  17-43  10-12  \n",
      "28  None  None  None  5-2  1-14   6-8  14-45   8-15  \n",
      "29  None  None  None  2-6  3-12  5-11  15-44   2-21  \n",
      "\n",
      "[30 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# %%write_file ../src/fetch_utils.py\n",
    "import time\n",
    "from nba_api.stats.endpoints import commonallplayers, commonplayerinfo, playercareerstats, leaguestandings\n",
    "from requests.exceptions import RequestException\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "# Define the maximum requests allowed per minute and delay between requests\n",
    "MAX_REQUESTS_PER_MINUTE = 20\n",
    "DELAY_BETWEEN_REQUESTS = 3  # seconds\n",
    "\n",
    "def fetch_with_retry(endpoint, max_retries=10, initial_delay=5, max_delay=60, timeout=60, debug=False, **kwargs):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if debug:\n",
    "                print(f\"Fetching data using {endpoint.__name__} (Attempt {attempt + 1}) with parameters: {kwargs}\")\n",
    "            data = endpoint(**kwargs, timeout=timeout).get_data_frames()\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)  # Add delay between requests\n",
    "            return data[0] if isinstance(data, list) else data\n",
    "        except (RequestException, JSONDecodeError, KeyError) as e:\n",
    "            if debug:\n",
    "                print(f\"Error occurred during fetching {endpoint.__name__}: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                if debug:\n",
    "                    print(f\"Failed to fetch data from {endpoint.__name__} after {max_retries} attempts\")\n",
    "                return None\n",
    "            delay = min(initial_delay * (2 ** attempt), max_delay)\n",
    "            if debug:\n",
    "                print(f\"Retrying in {delay} seconds...\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "def fetch_all_players(season, debug=False):\n",
    "    all_players_data = fetch_with_retry(commonallplayers.CommonAllPlayers, season=season, debug=debug)\n",
    "    all_players = {}\n",
    "    if all_players_data is not None:\n",
    "        for _, row in all_players_data.iterrows():\n",
    "            player_name = row['DISPLAY_FIRST_LAST'].strip().lower()\n",
    "            player_id = row['PERSON_ID']\n",
    "            team_id = row['TEAM_ID']\n",
    "            all_players[player_name] = {\n",
    "                'player_id': player_id,\n",
    "                'team_id': team_id\n",
    "            }\n",
    "    if debug:\n",
    "        print(f\"Fetched {len(all_players)} players for season {season}\")\n",
    "    return all_players\n",
    "\n",
    "def fetch_player_info(player_id, debug=False):\n",
    "    return fetch_with_retry(commonplayerinfo.CommonPlayerInfo, player_id=player_id, debug=debug)\n",
    "\n",
    "def fetch_career_stats(player_id, debug=False):\n",
    "    return fetch_with_retry(playercareerstats.PlayerCareerStats, player_id=player_id, debug=debug)\n",
    "\n",
    "def fetch_league_standings(season, debug=False):\n",
    "    return fetch_with_retry(leaguestandings.LeagueStandings, season=season, debug=debug)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    debug = True\n",
    "    season = \"2022-23\"\n",
    "    sample_player_name = \"LeBron James\"\n",
    "    \n",
    "    # Fetch all players\n",
    "    all_players = fetch_all_players(season, debug=debug)\n",
    "    print(f\"Total players fetched: {len(all_players)}\")\n",
    "    \n",
    "    # Fetch player info for a sample player\n",
    "    if sample_player_name.lower() in all_players:\n",
    "        sample_player_id = all_players[sample_player_name.lower()]['player_id']\n",
    "        player_info = fetch_player_info(sample_player_id, debug=debug)\n",
    "        print(f\"Sample player info for {sample_player_name}:\")\n",
    "        print(player_info)\n",
    "        \n",
    "        # Fetch career stats for the sample player\n",
    "        career_stats = fetch_career_stats(sample_player_id, debug=debug)\n",
    "        print(f\"Sample player career stats for {sample_player_name}:\")\n",
    "        print(career_stats)\n",
    "    else:\n",
    "        print(f\"Player {sample_player_name} not found in the {season} season data.\")\n",
    "    \n",
    "    # Fetch league standings\n",
    "    standings = fetch_league_standings(season, debug=debug)\n",
    "    print(\"League standings:\")\n",
    "    print(standings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Testing scrape_salary_cap_history:\n",
      "Salary cap data scraped successfully\n",
      "       Mid-Level Exception     Season   Salary Cap   Luxury Tax    1st Apron  \\\n",
      "0 NaN                  NaN  2034-2035  364650000.0  443050000.0  461955000.0   \n",
      "1 NaN                  NaN  2033-2034  331500000.0  402773000.0  419960000.0   \n",
      "2 NaN                  NaN  2032-2033  301364000.0  366157000.0  381781000.0   \n",
      "3 NaN                  NaN  2031-2032  273967000.0  332870000.0  347074000.0   \n",
      "4 NaN                  NaN  2030-2031  249061000.0  302609000.0  315522000.0   \n",
      "\n",
      "     2nd Apron         BAE  Standard /Non-Taxpayer    Taxpayer  \\\n",
      "0  489965000.0  12106000.0              33256000.0  13404000.0   \n",
      "1  445423000.0  11006000.0              30233000.0  12186000.0   \n",
      "2  404929000.0  10005000.0              27484000.0  11078000.0   \n",
      "3  368118000.0   9096000.0              24986000.0  10071000.0   \n",
      "4  334652000.0   8269000.0              22714000.0   9155000.0   \n",
      "\n",
      "   Team Room /Under Cap  \n",
      "0            20705000.0  \n",
      "1            18823000.0  \n",
      "2            17111000.0  \n",
      "3            15556000.0  \n",
      "4            14142000.0  \n",
      "\n",
      "2. Testing scrape_player_salary_data:\n",
      "Scraping data for 2022-23 from URL: https://hoopshype.com/salaries/players/2022-2023/\n",
      "Scraping data for 2023-24 from URL: https://hoopshype.com/salaries/players/2023-2024/\n",
      "Scraped salary data for Ja Morant from seasons 2022-2023:\n",
      "      Player    Salary   Season\n",
      "0  Ja Morant  12119440  2022-23\n",
      "1  Ja Morant  34005250  2023-24\n",
      "\n",
      "3. Testing scrape_team_salary_data:\n",
      "Scraped team salary data for season 2022-23:\n",
      "        Team  Team_Salary   Season\n",
      "0    Phoenix    230718931  2022-23\n",
      "1  Minnesota    209038266  2022-23\n",
      "2     Boston    203852738  2022-23\n",
      "3  Milwaukee    196680310  2022-23\n",
      "4  LA Lakers    189921720  2022-23\n",
      "\n",
      "4. Testing scrape_advanced_metrics:\n",
      "Scraped advanced metrics for Ja Morant in season 2022-23: {'PER': 23.3, 'TS%': 0.557, '3PAr': 0.247, 'FTr': 0.409, 'ORB%': 3.3, 'DRB%': 16.1, 'TRB%': 9.7, 'AST%': 41.1, 'STL%': 1.6, 'BLK%': 0.7, 'TOV%': 12.6, 'USG%': 34.9, 'OWS': 3.4, 'DWS': 2.6, 'WS': 6.0, 'WS/48': 0.148, 'OBPM': 5.2, 'DBPM': 0.5, 'BPM': 5.7, 'VORP': 3.8}\n",
      "Advanced Metrics for Ja Morant:\n",
      "{'PER': 23.3, 'TS%': 0.557, '3PAr': 0.247, 'FTr': 0.409, 'ORB%': 3.3, 'DRB%': 16.1, 'TRB%': 9.7, 'AST%': 41.1, 'STL%': 1.6, 'BLK%': 0.7, 'TOV%': 12.6, 'USG%': 34.9, 'OWS': 3.4, 'DWS': 2.6, 'WS': 6.0, 'WS/48': 0.148, 'OBPM': 5.2, 'DBPM': 0.5, 'BPM': 5.7, 'VORP': 3.8}\n",
      "\n",
      "5. Testing load_injury_data and merge_injury_data:\n",
      "Injury data loaded successfully\n",
      "Merged data with injury info:\n",
      "      Player   Season    Salary  Injured  \\\n",
      "0  Ja Morant  2022-23  12119440     True   \n",
      "1  Ja Morant  2023-24  34005250    False   \n",
      "\n",
      "                                      Injury_Periods  Total_Days_Injured  \\\n",
      "0  2022-10-29 - 2022-10-31; 2022-11-13 - 2022-11-...                  19   \n",
      "1                                                                      0   \n",
      "\n",
      "     Injury_Risk  \n",
      "0  Moderate Risk  \n",
      "1       Low Risk  \n",
      "Average salary for Ja Morant from 2022 to 2023: $23,062,345.00\n",
      "Team with highest salary in 2022-2023: Phoenix ($230,718,931.00)\n",
      "Number of injuries/illnesses for Ja Morant from 2022 to 2023: 19\n",
      "\n",
      "All tests completed.\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ../src/scrape_utils.py\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "def scrape_salary_cap_history(debug=False):\n",
    "    url = \"https://basketball.realgm.com/nba/info/salary_cap\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', class_='basketball compact')\n",
    "        \n",
    "        if not table:\n",
    "            if debug:\n",
    "                print(\"Could not find the salary cap table on the page.\")\n",
    "            return None\n",
    "\n",
    "        data = []\n",
    "        headers = [th.text.strip() for th in table.find('thead').find_all('th')]\n",
    "        for row in table.find('tbody').find_all('tr'):\n",
    "            cols = row.find_all('td')\n",
    "            if cols:\n",
    "                row_data = [col.text.strip() for col in cols]\n",
    "                data.append(row_data)\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        \n",
    "        # Clean up the data\n",
    "        df['Season'] = df['Season'].str.extract(r'(\\d{4}-\\d{4})')\n",
    "        df['Salary Cap'] = df['Salary Cap'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "        \n",
    "        # Convert other columns to float, handling non-numeric values\n",
    "        for col in df.columns:\n",
    "            if col not in ['Season', 'Salary Cap']:\n",
    "                df[col] = pd.to_numeric(df[col].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "        \n",
    "        if debug:\n",
    "            print(\"Salary cap data scraped successfully\")\n",
    "            print(df.head())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error scraping salary cap history: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "DELAY_BETWEEN_REQUESTS = 3  # seconds\n",
    "\n",
    "def scrape_player_salary_data(start_season, end_season, player_filter=None, debug=False):\n",
    "    all_data = []\n",
    "    \n",
    "    for season in range(start_season, end_season + 1):\n",
    "        season_str = f\"{season}-{str(season+1)[-2:]}\"\n",
    "        url = f\"https://hoopshype.com/salaries/players/{season}-{season+1}/\"\n",
    "        if debug:\n",
    "            print(f\"Scraping data for {season_str} from URL: {url}\")\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', class_='hh-salaries-ranking-table')\n",
    "        \n",
    "        if table:\n",
    "            rows = table.find_all('tr')[1:]\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if len(cols) >= 3:\n",
    "                    player = cols[1].get_text(strip=True)\n",
    "                    if player_filter is None or player_filter.lower() == 'all' or player.lower() == player_filter.lower():\n",
    "                        salary_text = cols[2].get_text(strip=True)\n",
    "                        salary = int(salary_text.replace('$', '').replace(',', ''))\n",
    "                        all_data.append({'Player': player, 'Salary': salary, 'Season': season_str})\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"No salary data found for season {season_str}\")\n",
    "        \n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)  # Delay between requests to avoid hitting rate limits\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    if debug:\n",
    "        print(f\"Scraped salary data for {'all players' if player_filter is None or player_filter.lower() == 'all' else player_filter} from seasons {start_season}-{end_season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "    \n",
    "    df = pd.DataFrame(all_data)\n",
    "    if debug:\n",
    "        print(f\"Scraped salary data for {'all players' if player_filter is None or player_filter.lower() == 'all' else player_filter} from seasons {start_season}-{end_season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "\n",
    "def scrape_team_salary_data(season, debug=False):\n",
    "    url = f\"https://hoopshype.com/salaries/{season}/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', class_='hh-salaries-ranking-table')\n",
    "    rows = table.find_all('tr')[1:]\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        team = cols[1].get_text(strip=True)\n",
    "        salary = int(cols[2].get_text(strip=True).replace('$', '').replace(',', ''))\n",
    "        data.append({'Team': team, 'Team_Salary': salary, 'Season': season})\n",
    "    df = pd.DataFrame(data)\n",
    "    if debug:\n",
    "        print(f\"Scraped team salary data for season {season}:\")\n",
    "        print(df.head())\n",
    "    return df\n",
    "\n",
    "def scrape_advanced_metrics(player_name, season, debug=False, max_retries=3, retry_delay=60):\n",
    "    def make_request(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 429:\n",
    "            if debug:\n",
    "                print(f\"Rate limit hit. Waiting for {retry_delay} seconds before retrying.\")\n",
    "            time.sleep(retry_delay)\n",
    "            return None\n",
    "        return response\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            search_url = f\"https://www.basketball-reference.com/search/search.fcgi?search={player_name.replace(' ', '+')}\"\n",
    "            response = make_request(search_url)\n",
    "            if response is None:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            search_results = soup.find('div', {'class': 'search-results'})\n",
    "\n",
    "            if search_results:\n",
    "                for item in search_results.find_all('div', {'class': 'search-item'}):\n",
    "                    link = item.find('a')\n",
    "                    if link and 'players' in link['href']:\n",
    "                        player_url = f\"https://www.basketball-reference.com{link['href']}\"\n",
    "                        break\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"No player URL found for {player_name}\")\n",
    "                    return {}\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"No search results found for {player_name}\")\n",
    "                return {}\n",
    "\n",
    "            time.sleep(2)  # Wait 2 seconds between requests\n",
    "\n",
    "            response = make_request(player_url)\n",
    "            if response is None:\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', {'id': 'advanced'})\n",
    "            if table:\n",
    "                df = pd.read_html(StringIO(str(table)))[0]\n",
    "                if isinstance(df.columns, pd.MultiIndex):\n",
    "                    df.columns = df.columns.droplevel()\n",
    "                df['Season'] = df['Season'].astype(str)\n",
    "                df = df[df['Season'].str.contains(season.split('-')[0], na=False)]\n",
    "                if not df.empty:\n",
    "                    row = df.iloc[0]\n",
    "                    metrics = ['PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "                    result = {col: row[col] for col in metrics if col in row.index}\n",
    "                    if debug:\n",
    "                        print(f\"Scraped advanced metrics for {player_name} in season {season}: {result}\")\n",
    "                    return result\n",
    "                else:\n",
    "                    if debug:\n",
    "                        print(f\"No advanced metrics found for {player_name} in season {season}\")\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"No advanced stats table found for {player_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"Error scraping advanced metrics for {player_name}: {e}\")\n",
    "        \n",
    "        if attempt < max_retries - 1:\n",
    "            if debug:\n",
    "                print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Failed to scrape advanced metrics for {player_name} after {max_retries} attempts\")\n",
    "    return {}\n",
    "\n",
    "def load_injury_data(file_path='../data/processed/NBA Player Injury Stats(1951 - 2023).csv'):\n",
    "    try:\n",
    "        injury_data = pd.read_csv(file_path)\n",
    "        injury_data['Date'] = pd.to_datetime(injury_data['Date'])\n",
    "        injury_data['Season'] = injury_data['Date'].apply(lambda x: f\"{x.year}-{str(x.year+1)[-2:]}\" if x.month >= 10 else f\"{x.year-1}-{str(x.year)[-2:]}\")\n",
    "        print(\"Injury data loaded successfully\")\n",
    "        return injury_data\n",
    "    except FileNotFoundError:\n",
    "        print(\"Injury data file not found. Proceeding without injury data.\")\n",
    "        return None\n",
    "\n",
    "def merge_injury_data(player_data, injury_data):\n",
    "    if injury_data is None:\n",
    "        return player_data\n",
    "\n",
    "    all_players_df = player_data.copy()\n",
    "    all_players_df['Injured'] = False\n",
    "    all_players_df['Injury_Periods'] = ''\n",
    "    all_players_df['Total_Days_Injured'] = 0\n",
    "    all_players_df['Injury_Risk'] = 'Low Risk'\n",
    "\n",
    "    for index, row in all_players_df.iterrows():\n",
    "        player_injuries = injury_data[\n",
    "            (injury_data['Season'] == row['Season']) & \n",
    "            (injury_data['Relinquished'].str.contains(row['Player'], case=False, na=False))\n",
    "        ]\n",
    "        if not player_injuries.empty:\n",
    "            periods = []\n",
    "            total_days = 0\n",
    "            for _, injury in player_injuries.iterrows():\n",
    "                start_date = injury['Date']\n",
    "                acquired_matches = injury_data[\n",
    "                    (injury_data['Date'] > start_date) & \n",
    "                    (injury_data['Acquired'].str.contains(row['Player'], case=False, na=False))\n",
    "                ]\n",
    "                if not acquired_matches.empty:\n",
    "                    end_date = acquired_matches.iloc[0]['Date']\n",
    "                else:\n",
    "                    # Assuming injuries last until the end of the season if no acquired date is found\n",
    "                    end_year = int(row['Season'].split('-')[1])\n",
    "                    end_date = pd.Timestamp(f\"{end_year}-06-30\")\n",
    "                \n",
    "                period_days = (end_date - start_date).days\n",
    "                total_days += period_days\n",
    "                periods.append(f\"{start_date.strftime('%Y-%m-%d')} - {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "            all_players_df.at[index, 'Injured'] = True\n",
    "            all_players_df.at[index, 'Injury_Periods'] = '; '.join(periods)\n",
    "            all_players_df.at[index, 'Total_Days_Injured'] = total_days\n",
    "            \n",
    "            # Categorize injury risk based on total days\n",
    "            if total_days < 10:\n",
    "                risk = 'Low Risk'\n",
    "            elif 10 <= total_days <= 20:\n",
    "                risk = 'Moderate Risk'\n",
    "            else:\n",
    "                risk = 'High Risk'\n",
    "            all_players_df.at[index, 'Injury_Risk'] = risk\n",
    "\n",
    "    return all_players_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage and testing of all functions\n",
    "    debug = True\n",
    "    start_season = 2022\n",
    "    end_season = 2023\n",
    "    sample_player = \"Ja Morant\"  # Example player\n",
    "    \n",
    "    print(\"1. Testing scrape_salary_cap_history:\")\n",
    "    salary_cap_history = scrape_salary_cap_history(debug=debug)\n",
    "    \n",
    "    print(\"\\n2. Testing scrape_player_salary_data:\")\n",
    "    player_salary_data = scrape_player_salary_data(start_season, end_season, player_filter=sample_player, debug=debug)\n",
    "    \n",
    "    print(\"\\n3. Testing scrape_team_salary_data:\")\n",
    "    team_salary_data = scrape_team_salary_data(f\"{start_season}-{str(start_season+1)[-2:]}\", debug=debug)\n",
    "    \n",
    "    print(\"\\n4. Testing scrape_advanced_metrics:\")\n",
    "    advanced_metrics = scrape_advanced_metrics(sample_player, f\"{start_season}-{str(start_season+1)[-2:]}\", debug=debug)\n",
    "    print(f\"Advanced Metrics for {sample_player}:\")\n",
    "    print(advanced_metrics)\n",
    "    \n",
    "    print(\"\\n5. Testing load_injury_data and merge_injury_data:\")\n",
    "    injury_data = load_injury_data()\n",
    "    if not player_salary_data.empty and injury_data is not None:\n",
    "        merged_data = merge_injury_data(player_salary_data, injury_data)\n",
    "        print(\"Merged data with injury info:\")\n",
    "        columns_to_display = ['Player', 'Season', 'Salary']\n",
    "        if 'Injured' in merged_data.columns:\n",
    "            columns_to_display.append('Injured')\n",
    "        if 'Injury_Periods' in merged_data.columns:\n",
    "            columns_to_display.append('Injury_Periods')\n",
    "        if 'Total_Days_Injured' in merged_data.columns:\n",
    "            columns_to_display.append('Total_Days_Injured')\n",
    "        if 'Injury_Risk' in merged_data.columns:\n",
    "            columns_to_display.append('Injury_Risk')\n",
    "        print(merged_data[columns_to_display].head())\n",
    "\n",
    "    if not player_salary_data.empty:\n",
    "        avg_salary = player_salary_data['Salary'].mean()\n",
    "        print(f\"Average salary for {sample_player} from {start_season} to {end_season}: ${avg_salary:,.2f}\")\n",
    "    \n",
    "    if not team_salary_data.empty:\n",
    "        highest_team_salary = team_salary_data.loc[team_salary_data['Team_Salary'].idxmax()]\n",
    "        print(f\"Team with highest salary in {start_season}-{end_season}: {highest_team_salary['Team']} (${highest_team_salary['Team_Salary']:,.2f})\")\n",
    "    \n",
    "    if not injury_data.empty:\n",
    "        injury_count = injury_data['Relinquished'].str.contains(sample_player, case=False).sum()\n",
    "        print(f\"Number of injuries/illnesses for {sample_player} from {start_season} to {end_season}: {injury_count}\")\n",
    "\n",
    "    print(\"\\nAll tests completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inflated value 1000000 from 2022 to 1000000 (2022 dollars)\n",
      "Inflated value: 1000000\n",
      "Calculated percentages:\n",
      "   FG%  3P%  2P%   FT%   eFG%\n",
      "0  0.5  0.5  0.5  0.75  0.625\n",
      "Calculated percentages:\n",
      "    FG  FGA  3P  3PA  2P  2PA  FT  FTA  FG%  3P%  2P%   FT%   eFG%\n",
      "0  100  200  50  100  50  100  75  100  0.5  0.5  0.5  0.75  0.625\n",
      "Fetching data using CommonAllPlayers (Attempt 1) with parameters: {'season': '2022-23'}\n",
      "Fetched 4972 players for season 2022-23\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 2544}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2022-23'}\n",
      "Scraped advanced metrics for LeBron James in season 2022-23: {'PER': 23.9, 'TS%': 0.583, '3PAr': 0.309, 'FTr': 0.268, 'ORB%': 3.7, 'DRB%': 20.8, 'TRB%': 12.5, 'AST%': 33.5, 'STL%': 1.2, 'BLK%': 1.4, 'TOV%': 11.6, 'USG%': 33.3, 'OWS': 3.2, 'DWS': 2.4, 'WS': 5.6, 'WS/48': 0.138, 'OBPM': 5.5, 'DBPM': 0.6, 'BPM': 6.1, 'VORP': 4.0}\n",
      "Processed data for LeBron James in season 2022-23: {'Position': 'Forward', 'Age': 38.0, 'Team': 'LAL', 'TeamID': 1610612747, 'Years of Service': 19, 'GP': 55, 'GS': 54, 'MP': 1954.0, 'FG': 609, 'FGA': 1219, 'FG%': 0.5, '3P': 121, '3PA': 377, '3P%': 0.321, '2P': 488, '2PA': 842, '2P%': 0.5795724465558195, 'eFG%': 0.5492206726825266, 'FT': 251, 'FTA': 327, 'FT%': 0.768, 'ORB': 65, 'DRB': 392, 'TRB': 457, 'AST': 375, 'STL': 50, 'BLK': 32, 'TOV': 178, 'PF': 88, 'PTS': 1590, 'PER': 23.9, 'TS%': 0.583, '3PAr': 0.309, 'FTr': 0.268, 'ORB%': 3.7, 'DRB%': 20.8, 'TRB%': 12.5, 'AST%': 33.5, 'STL%': 1.2, 'BLK%': 1.4, 'TOV%': 11.6, 'USG%': 33.3, 'OWS': 3.2, 'DWS': 2.4, 'WS': 5.6, 'WS/48': 0.138, 'OBPM': 5.5, 'DBPM': 0.6, 'BPM': 6.1, 'VORP': 4.0, 'Wins': 43, 'Losses': 39, 'Player': 'LeBron James', 'Season': '2022-23'}\n",
      "Processed data for LeBron James:\n",
      "{'Position': 'Forward', 'Age': 38.0, 'Team': 'LAL', 'TeamID': 1610612747, 'Years of Service': 19, 'GP': 55, 'GS': 54, 'MP': 1954.0, 'FG': 609, 'FGA': 1219, 'FG%': 0.5, '3P': 121, '3PA': 377, '3P%': 0.321, '2P': 488, '2PA': 842, '2P%': 0.5795724465558195, 'eFG%': 0.5492206726825266, 'FT': 251, 'FTA': 327, 'FT%': 0.768, 'ORB': 65, 'DRB': 392, 'TRB': 457, 'AST': 375, 'STL': 50, 'BLK': 32, 'TOV': 178, 'PF': 88, 'PTS': 1590, 'PER': 23.9, 'TS%': 0.583, '3PAr': 0.309, 'FTr': 0.268, 'ORB%': 3.7, 'DRB%': 20.8, 'TRB%': 12.5, 'AST%': 33.5, 'STL%': 1.2, 'BLK%': 1.4, 'TOV%': 11.6, 'USG%': 33.3, 'OWS': 3.2, 'DWS': 2.4, 'WS': 5.6, 'WS/48': 0.138, 'OBPM': 5.5, 'DBPM': 0.6, 'BPM': 6.1, 'VORP': 4.0, 'Wins': 43, 'Losses': 39, 'Player': 'LeBron James', 'Season': '2022-23'}\n"
     ]
    }
   ],
   "source": [
    "# %%write_file ../src/process_utils.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import cpi\n",
    "# from fetch_utils import fetch_player_info, fetch_career_stats, fetch_league_standings\n",
    "# from scrape_utils import scrape_advanced_metrics\n",
    "\n",
    "def inflate_value(value, year_str, debug=False):\n",
    "    try:\n",
    "        year = int(year_str[:4])\n",
    "        current_year = datetime.now().year\n",
    "       \n",
    "        if year >= current_year:\n",
    "            return value  # Return the original value for future years\n",
    "        # Adjust to 2022 dollars to match the original data\n",
    "        inflated_value = cpi.inflate(value, year, to=2022)\n",
    "        if debug:\n",
    "            print(f\"Inflated value {value} from {year} to {inflated_value} (2022 dollars)\")\n",
    "        return inflated_value\n",
    "    except ValueError:\n",
    "        if debug:\n",
    "            print(f\"Invalid year format: {year_str}\")\n",
    "        return value\n",
    "    except cpi.errors.CPIObjectDoesNotExist:\n",
    "        # If data for the specific year is not available, use the earliest available year\n",
    "        earliest_year = min(cpi.SURVEYS['CPI-U'].indexes['annual'].keys()).year\n",
    "        inflated_value = cpi.inflate(value, earliest_year, to=2022)\n",
    "        if debug:\n",
    "            print(f\"Used earliest available year {earliest_year} for inflation calculation\")\n",
    "        return inflated_value\n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"Error inflating value for year {year_str}: {e}\")\n",
    "        return value\n",
    "\n",
    "def calculate_percentages(df, debug=False):\n",
    "    df['FG%'] = df['FG'] / df['FGA'].replace(0, np.nan)\n",
    "    df['3P%'] = df['3P'] / df['3PA'].replace(0, np.nan)\n",
    "    df['2P%'] = df['2P'] / df['2PA'].replace(0, np.nan)\n",
    "    df['FT%'] = df['FT'] / df['FTA'].replace(0, np.nan)\n",
    "    df['eFG%'] = (df['FG'] + 0.5 * df['3P']) / df['FGA'].replace(0, np.nan)\n",
    "    if debug:\n",
    "        print(\"Calculated percentages:\")\n",
    "        print(df[['FG%', '3P%', '2P%', 'FT%', 'eFG%']].head())\n",
    "    return df\n",
    "\n",
    "def process_player_data(player, season, all_players, debug=False):\n",
    "    if player.lower() not in all_players:\n",
    "        if debug:\n",
    "            print(f\"No player ID found for {player}\")\n",
    "        return None\n",
    "\n",
    "    player_id = all_players[player.lower()]['player_id']\n",
    "    team_id = all_players[player.lower()]['team_id']\n",
    "    \n",
    "    player_info = fetch_player_info(player_id, debug=debug)\n",
    "    career_stats = fetch_career_stats(player_id, debug=debug)\n",
    "    league_standings = fetch_league_standings(season, debug=debug)\n",
    "    \n",
    "    # Scrape advanced metrics from Basketball Reference\n",
    "    advanced_metrics = scrape_advanced_metrics(player, season, debug=debug)\n",
    "\n",
    "    if player_info is None or career_stats is None or career_stats.empty:\n",
    "        if debug:\n",
    "            print(f\"Unable to fetch complete data for {player}\")\n",
    "        return None\n",
    "\n",
    "    season_stats = career_stats[career_stats['SEASON_ID'].str.contains(season.split('-')[0], na=False)]\n",
    "    if season_stats.empty:\n",
    "        if debug:\n",
    "            print(f\"No stats found for {player} in season {season}\")\n",
    "        return None\n",
    "\n",
    "    latest_season_stats = season_stats.iloc[0]\n",
    "    \n",
    "    try:\n",
    "        draft_year = int(player_info['DRAFT_YEAR'].iloc[0])\n",
    "    except ValueError:\n",
    "        draft_year = int(player_info['FROM_YEAR'].iloc[0])\n",
    "\n",
    "    current_season_year = int(season.split('-')[0])\n",
    "    years_of_service = max(0, current_season_year - draft_year)\n",
    "\n",
    "    # Handle missing league standings gracefully\n",
    "    if league_standings is not None and not league_standings.empty:\n",
    "        player_stats = calculate_player_stats(latest_season_stats, player_info, years_of_service, team_id, league_standings, advanced_metrics)\n",
    "    else:\n",
    "        player_stats = calculate_player_stats(latest_season_stats, player_info, years_of_service, team_id, pd.DataFrame(), advanced_metrics)\n",
    "\n",
    "    player_stats.update({'Player': player, 'Season': season})\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Processed data for {player} in season {season}: {player_stats}\")\n",
    "    return player_stats\n",
    "\n",
    "def calculate_player_stats(stats, player_info, years_of_service, team_id, league_standings, advanced_metrics):\n",
    "    fg = stats.get('FGM', 0) or 0\n",
    "    fga = stats.get('FGA', 0) or 0\n",
    "    fg3 = stats.get('FG3M', 0) or 0\n",
    "    fg3a = stats.get('FG3A', 0) or 0\n",
    "    efg = (fg + 0.5 * fg3) / fga if fga != 0 else 0\n",
    "    fg2 = fg - fg3\n",
    "    fg2a = fga - fg3a\n",
    "    fg2_pct = (fg2 / fg2a) if fg2a != 0 else 0\n",
    "\n",
    "    player_stats = {\n",
    "        'Position': player_info.iloc[0]['POSITION'],\n",
    "        'Age': stats.get('PLAYER_AGE', None),\n",
    "        'Team': stats.get('TEAM_ABBREVIATION', None),\n",
    "        'TeamID': team_id,\n",
    "        'Years of Service': years_of_service,\n",
    "        'GP': stats.get('GP', None),\n",
    "        'GS': stats.get('GS', None),\n",
    "        'MP': stats.get('MIN', None),\n",
    "        'FG': fg,\n",
    "        'FGA': fga,\n",
    "        'FG%': stats.get('FG_PCT', None),\n",
    "        '3P': fg3,\n",
    "        '3PA': fg3a,\n",
    "        '3P%': stats.get('FG3_PCT', None),\n",
    "        '2P': fg2,\n",
    "        '2PA': fg2a,\n",
    "        '2P%': fg2_pct,\n",
    "        'eFG%': efg,\n",
    "        'FT': stats.get('FTM', None),\n",
    "        'FTA': stats.get('FTA', None),\n",
    "        'FT%': stats.get('FT_PCT', None),\n",
    "        'ORB': stats.get('OREB', None),\n",
    "        'DRB': stats.get('DREB', None),\n",
    "        'TRB': stats.get('REB', None),\n",
    "        'AST': stats.get('AST', None),\n",
    "        'STL': stats.get('STL', None),\n",
    "        'BLK': stats.get('BLK', None),\n",
    "        'TOV': stats.get('TOV', None),\n",
    "        'PF': stats.get('PF', None),\n",
    "        'PTS': stats.get('PTS', None),\n",
    "    }\n",
    "    \n",
    "    # Add advanced metrics\n",
    "    player_stats.update(advanced_metrics)\n",
    "\n",
    "    if league_standings is not None and not league_standings.empty:\n",
    "        team_standings = league_standings[league_standings['TeamID'] == team_id]\n",
    "        if not team_standings.empty:\n",
    "            player_stats.update({\n",
    "                'Wins': team_standings['WINS'].values[0],\n",
    "                'Losses': team_standings['LOSSES'].values[0]\n",
    "            })\n",
    "\n",
    "    return player_stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    debug = True\n",
    "    season = \"2022-23\"\n",
    "    sample_value = 1000000\n",
    "    sample_year = \"2022\"\n",
    "    sample_player = \"LeBron James\"\n",
    "    \n",
    "    # Test inflate_value\n",
    "    inflated_value = inflate_value(sample_value, sample_year, debug=debug)\n",
    "    print(f\"Inflated value: {inflated_value}\")\n",
    "    \n",
    "    # Test calculate_percentages\n",
    "    sample_df = pd.DataFrame({\n",
    "        'FG': [100], 'FGA': [200],\n",
    "        '3P': [50], '3PA': [100],\n",
    "        '2P': [50], '2PA': [100],\n",
    "        'FT': [75], 'FTA': [100]\n",
    "    })\n",
    "    calculated_df = calculate_percentages(sample_df, debug=debug)\n",
    "    print(\"Calculated percentages:\")\n",
    "    print(calculated_df)\n",
    "    \n",
    "    # Test process_player_data\n",
    "    # Note: This requires actual data from fetch_utils and scrape_utils\n",
    "    # Here's a mock-up of how it would work:\n",
    "    # from fetch_utils import fetch_all_players\n",
    "    all_players = fetch_all_players(season, debug=debug)\n",
    "    if sample_player.lower() in all_players:\n",
    "        player_data = process_player_data(sample_player, season, all_players, debug=debug)\n",
    "        print(f\"Processed data for {sample_player}:\")\n",
    "        print(player_data)\n",
    "    else:\n",
    "        print(f\"Player {sample_player} not found in the {season} season data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../src/data_utils.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    # Remove unnamed columns\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "    \n",
    "    # Remove columns with all NaN values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    # Remove rows with all NaN values\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    \n",
    "    # Ensure only one 'Season' column exists\n",
    "    season_columns = [col for col in df.columns if 'Season' in col]\n",
    "    if len(season_columns) > 1:\n",
    "        df = df.rename(columns={season_columns[0]: 'Season'})\n",
    "        for col in season_columns[1:]:\n",
    "            df = df.drop(columns=[col])\n",
    "    \n",
    "    # Remove '3PAr' and 'FTr' columns\n",
    "    columns_to_remove = ['3PAr', 'FTr']\n",
    "    df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "    \n",
    "    # Round numeric columns to 2 decimal places\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_columns] = df[numeric_columns].round(2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def merge_salary_cap_data(player_data, salary_cap_data):\n",
    "    player_data['Season_Year'] = player_data['Season'].str[:4].astype(int)\n",
    "    salary_cap_data['Season_Year'] = salary_cap_data['Season'].str[:4].astype(int)\n",
    "    \n",
    "    # Add inflation-adjusted salary cap\n",
    "    salary_cap_data['Salary_Cap_Inflated'] = salary_cap_data.apply(\n",
    "        lambda row: inflate_value(row['Salary Cap'], row['Season']),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Merge salary cap data\n",
    "    merged_data = pd.merge(player_data, salary_cap_data, on='Season_Year', how='left', suffixes=('', '_cap'))\n",
    "    \n",
    "    # Update salary cap columns\n",
    "    cap_columns = ['Mid-Level Exception', 'Salary Cap', 'Luxury Tax', '1st Apron', '2nd Apron', 'BAE',\n",
    "                   'Standard /Non-Taxpayer', 'Taxpayer', 'Team Room /Under Cap', 'Salary_Cap_Inflated']\n",
    "    for col in cap_columns:\n",
    "        if f'{col}_cap' in merged_data.columns:\n",
    "            merged_data[col] = merged_data[col].fillna(merged_data[f'{col}_cap'])\n",
    "            merged_data.drop(columns=[f'{col}_cap'], inplace=True)\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    merged_data.drop(columns=['Season_Year'], inplace=True)\n",
    "    \n",
    "    # Clean the dataframe\n",
    "    merged_data = clean_dataframe(merged_data)\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "def validate_data(df):\n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    if missing_values.sum() > 0:\n",
    "        print(\"Warning: Missing values found in the following columns:\")\n",
    "        print(missing_values[missing_values > 0])\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicates = df.duplicated()\n",
    "    if duplicates.sum() > 0:\n",
    "        print(f\"Warning: {duplicates.sum()} duplicate rows found\")\n",
    "    \n",
    "    # Check data types\n",
    "    expected_types = {\n",
    "        'Season': 'object',\n",
    "        'Player': 'object',\n",
    "        'Age': 'float64',\n",
    "        'GP': 'float64',\n",
    "        'MP': 'float64',\n",
    "        'Salary': 'float64',\n",
    "        'Team_Salary': 'float64',\n",
    "        'Salary Cap': 'float64',\n",
    "        'Salary_Cap_Inflated': 'float64'\n",
    "    }\n",
    "    for col, expected_type in expected_types.items():\n",
    "        if col in df.columns:\n",
    "            actual_type = df[col].dtype\n",
    "            if str(actual_type) != expected_type:\n",
    "                print(f\"Warning: Column '{col}' has type {actual_type}, expected {expected_type}\")\n",
    "    \n",
    "    # Check for negative values in numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if (df[col] < 0).any():\n",
    "            print(f\"Warning: Negative values found in column '{col}'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def merge_injury_data(player_data, injury_data):\n",
    "#     merged_data = player_data.copy()\n",
    "#     merged_data['Injured'] = False\n",
    "#     merged_data['Injury_Periods'] = ''\n",
    "\n",
    "#     for index, row in merged_data.iterrows():\n",
    "#         player_injuries = injury_data[(injury_data['Season'] == row['Season']) & \n",
    "#                                       (injury_data['Relinquished'].str.contains(row['Player'], case=False, na=False))]\n",
    "#         if not player_injuries.empty:\n",
    "#             merged_data.at[index, 'Injured'] = True\n",
    "#             injury_periods = player_injuries.apply(lambda x: f\"{x['Date'].strftime('%Y-%m-%d')} - {x['Notes']}\", axis=1).tolist()\n",
    "#             merged_data.at[index, 'Injury_Periods'] = '; '.join(injury_periods)\n",
    "\n",
    "#     return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing data with shape: (23, 66)\n",
      "Updating data for years 2019 to 2023\n",
      "Injury data loaded successfully\n",
      "Scraping data for 2019-20 from URL: https://hoopshype.com/salaries/players/2019-2020/\n",
      "Scraping data for 2020-21 from URL: https://hoopshype.com/salaries/players/2020-2021/\n",
      "Scraping data for 2021-22 from URL: https://hoopshype.com/salaries/players/2021-2022/\n",
      "Scraping data for 2022-23 from URL: https://hoopshype.com/salaries/players/2022-2023/\n",
      "Scraping data for 2023-24 from URL: https://hoopshype.com/salaries/players/2023-2024/\n",
      "Scraped salary data for Jayson Tatum from seasons 2019-2023:\n",
      "         Player    Salary   Season\n",
      "0  Jayson Tatum   7830000  2019-20\n",
      "1  Jayson Tatum   9897120  2020-21\n",
      "2  Jayson Tatum  28103500  2021-22\n",
      "3  Jayson Tatum  30351780  2022-23\n",
      "4  Jayson Tatum  32600060  2023-24\n",
      "Processing season: 2019-20\n",
      "Scraped team salary data for season 2019-20:\n",
      "        Team  Team_Salary   Season\n",
      "0    Phoenix    230718931  2019-20\n",
      "1  Minnesota    209038266  2019-20\n",
      "2     Boston    203852738  2019-20\n",
      "3  Milwaukee    196680310  2019-20\n",
      "4  LA Lakers    189921720  2019-20\n",
      "Fetching data using CommonAllPlayers (Attempt 1) with parameters: {'season': '2019-20'}\n",
      "Fetched 4972 players for season 2019-20\n",
      "Fetching data using CommonPlayerInfo (Attempt 1) with parameters: {'player_id': 1628369}\n",
      "Fetching data using PlayerCareerStats (Attempt 1) with parameters: {'player_id': 1628369}\n",
      "Fetching data using LeagueStandings (Attempt 1) with parameters: {'season': '2019-20'}\n",
      "Rate limit hit. Waiting for 60 seconds before retrying.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 159\u001b[0m\n\u001b[1;32m    155\u001b[0m     min_avg_minutes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the minimum average minutes per game (default 25 mins): \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m    157\u001b[0m debug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Set to False to disable debug output\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_avg_minutes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 102\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(start_year, end_year, player_filter, min_avg_minutes, debug)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating data for years \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_year\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m updated_data \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexisting_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_avg_minutes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m updated_data\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "Cell \u001b[0;32mIn[68], line 41\u001b[0m, in \u001b[0;36mupdate_data\u001b[0;34m(existing_data, start_year, end_year, player_filter, min_avg_minutes, debug)\u001b[0m\n\u001b[1;32m     38\u001b[0m player_name_lower \u001b[38;5;241m=\u001b[39m player_name\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m player_name_lower \u001b[38;5;129;01min\u001b[39;00m all_players:\n\u001b[0;32m---> 41\u001b[0m     player_stats \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_player_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_players\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m player_stats:\n\u001b[1;32m     43\u001b[0m         player_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m salary_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[59], line 62\u001b[0m, in \u001b[0;36mprocess_player_data\u001b[0;34m(player, season, all_players, debug)\u001b[0m\n\u001b[1;32m     59\u001b[0m league_standings \u001b[38;5;241m=\u001b[39m fetch_league_standings(season, debug\u001b[38;5;241m=\u001b[39mdebug)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Scrape advanced metrics from Basketball Reference\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m advanced_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_advanced_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseason\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m player_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m career_stats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m career_stats\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n",
      "Cell \u001b[0;32mIn[58], line 114\u001b[0m, in \u001b[0;36mscrape_advanced_metrics\u001b[0;34m(player_name, season, debug, max_retries, retry_delay)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     search_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.basketball-reference.com/search/search.fcgi?search=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 107\u001b[0m, in \u001b[0;36mscrape_advanced_metrics.<locals>.make_request\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate limit hit. Waiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_delay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds before retrying.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%writefile ../src/main.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "# from fetch_utils import fetch_all_players\n",
    "# from process_utils import process_player_data, inflate_value, calculate_percentages\n",
    "# from scrape_utils import scrape_salary_cap_history, scrape_player_salary_data, scrape_team_salary_data, scrape_injury_data\n",
    "# from data_utils import load_existing_data, clean_dataframe, merge_salary_cap_data, validate_data, merge_injury_data\n",
    "\n",
    "\n",
    "def update_data(existing_data, start_year, end_year, player_filter=None, min_avg_minutes=None, debug=False):\n",
    "    all_data = existing_data.copy() if existing_data is not None else pd.DataFrame()\n",
    "\n",
    "    # Load injury data\n",
    "    injury_data = load_injury_data()\n",
    "\n",
    "    salary_data = scrape_player_salary_data(start_year, end_year, player_filter=player_filter, debug=debug)\n",
    "\n",
    "    new_data = pd.DataFrame()\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season = f\"{year}-{str(year+1)[-2:]}\"\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Processing season: {season}\")\n",
    "        \n",
    "        team_salary_data = scrape_team_salary_data(season, debug=debug)\n",
    "        all_players = fetch_all_players(season=season, debug=debug)\n",
    "        \n",
    "        season_salary_data = salary_data[salary_data['Season'] == season]\n",
    "        \n",
    "        if player_filter and player_filter.lower() != 'all':\n",
    "            season_salary_data = season_salary_data[season_salary_data['Player'].str.lower() == player_filter.lower()]\n",
    "\n",
    "        additional_stats = []\n",
    "\n",
    "        for _, salary_row in season_salary_data.iterrows():\n",
    "            player_name = salary_row['Player']\n",
    "            player_name_lower = player_name.lower()\n",
    "            \n",
    "            if player_name_lower in all_players:\n",
    "                player_stats = process_player_data(player_name, season, all_players, debug=debug)\n",
    "                if player_stats:\n",
    "                    player_stats['Salary'] = salary_row['Salary']\n",
    "                    additional_stats.append(player_stats)\n",
    "            elif debug:\n",
    "                print(f\"Player not found in all_players: {player_name}\")\n",
    "\n",
    "        additional_stats_df = pd.DataFrame(additional_stats)\n",
    "\n",
    "        if additional_stats_df.empty or 'Team' not in additional_stats_df.columns:\n",
    "            if debug:\n",
    "                print(f\"Warning: No valid player stats data for season {season}\")\n",
    "            continue\n",
    "\n",
    "        # Merge team salary data\n",
    "        merged_data = pd.merge(additional_stats_df, team_salary_data, on=['Team', 'Season'], how='left', suffixes=('', '_team'))\n",
    "\n",
    "        # Apply minimum average minutes filter if specified\n",
    "        if min_avg_minutes is not None:\n",
    "            before_filter = len(merged_data)\n",
    "            merged_data = merged_data[merged_data['MP'] >= min_avg_minutes]\n",
    "            if debug:\n",
    "                print(f\"Filtered {before_filter - len(merged_data)} players based on minimum average minutes\")\n",
    "\n",
    "        # Merge injury data\n",
    "        merged_data = merge_injury_data(merged_data, injury_data)\n",
    "\n",
    "        new_data = pd.concat([new_data, merged_data], ignore_index=True, sort=False)\n",
    "\n",
    "    # Remove existing data for the players and seasons we just updated\n",
    "    if not all_data.empty and not new_data.empty:\n",
    "        all_data = all_data[~((all_data['Season'].isin(new_data['Season'])) & \n",
    "                              (all_data['Player'].isin(new_data['Player'])))]\n",
    "\n",
    "    # Combine existing data with new data\n",
    "    all_data = pd.concat([all_data, new_data], ignore_index=True, sort=False)\n",
    "\n",
    "    # Sort the final data by season and player\n",
    "    all_data.sort_values(by=['Season', 'Player'], inplace=True)\n",
    "\n",
    "    # Calculate percentages\n",
    "    all_data = calculate_percentages(all_data)\n",
    "\n",
    "    # Clean the dataframe\n",
    "    all_data = clean_dataframe(all_data)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Final data shape: {all_data.shape}\")\n",
    "        print(f\"Columns: {all_data.columns.tolist()}\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def main(start_year, end_year, player_filter=None, min_avg_minutes=None, debug=False):\n",
    "    processed_file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    salary_cap_file_path = '../data/processed/salary_cap_history_inflated.csv'\n",
    "\n",
    "    existing_data = load_existing_data(processed_file_path)\n",
    "\n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"Updating data for years {start_year} to {end_year}\")\n",
    "        updated_data = update_data(existing_data, start_year, end_year, player_filter, min_avg_minutes, debug=debug)\n",
    "\n",
    "        if not updated_data.empty:\n",
    "            if debug:\n",
    "                print(\"New data retrieved. Processing and saving...\")\n",
    "\n",
    "            salary_cap_data = scrape_salary_cap_history(debug=debug)\n",
    "\n",
    "            if salary_cap_data is not None:\n",
    "                salary_cap_data.to_csv(salary_cap_file_path, index=False)\n",
    "                updated_data = merge_salary_cap_data(updated_data, salary_cap_data)\n",
    "\n",
    "            # Final cleaning of the data\n",
    "            updated_data = clean_dataframe(updated_data)\n",
    "\n",
    "            # Save the updated data\n",
    "            updated_data.to_csv(processed_file_path, index=False, float_format='%.2f')\n",
    "            if debug:\n",
    "                print(f\"Updated data saved to {processed_file_path}\")\n",
    "\n",
    "            # Print summary of the data\n",
    "            summary_columns = ['Season', 'Player', 'Salary', 'GP', 'PTS', 'TRB', 'AST', 'PER', 'WS', 'VORP', 'Injured', 'FG%', '3P%', 'FT%', 'Team_Salary', 'Salary Cap', 'Salary_Cap_Inflated']\n",
    "            available_columns = [col for col in summary_columns if col in updated_data.columns]\n",
    "            print(\"\\nData summary:\")\n",
    "            print(updated_data[available_columns].head().to_string(index=False))\n",
    "        else:\n",
    "            print(\"No new data to save. The dataset is empty.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Traceback:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser(description=\"Update NBA player data\")\n",
    "#     parser.add_argument(\"--start_year\", type=int, required=True, help=\"Start year for data update\")\n",
    "#     parser.add_argument(\"--end_year\", type=int, required=True, help=\"End year for data update\")\n",
    "#     parser.add_argument(\"--player_filter\", type=str, default=\"all\", help=\"Filter for specific player or 'all'\")\n",
    "#     parser.add_argument(\"--min_avg_minutes\", type=float, default=25, help=\"Minimum average minutes per game\")\n",
    "#     parser.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug mode\")\n",
    "\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     main(args.start_year, args.end_year, args.player_filter, args.min_avg_minutes, args.debug)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_year = 2019\n",
    "    end_year = 2023\n",
    "    player_filter = input(\"Enter player name or 'all' for all players: \").strip()\n",
    "    min_avg_minutes = None\n",
    "    if player_filter.lower() == 'all':\n",
    "        min_avg_minutes = float(input(\"Enter the minimum average minutes per game (default 25 mins): \") or 25)\n",
    "\n",
    "    debug = True  # Set to False to disable debug output\n",
    "\n",
    "    main(start_year, end_year, player_filter, min_avg_minutes, debug)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
