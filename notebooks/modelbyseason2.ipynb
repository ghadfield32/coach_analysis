{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/data_loader_preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/data_loader_preprocessor.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "INJURY_RISK_MAP = {\n",
    "    'Low Risk': 1,\n",
    "    'Moderate Risk': 2,\n",
    "    'High Risk': 3\n",
    "}\n",
    "\n",
    "REVERSE_INJURY_RISK_MAP = {\n",
    "    1: 'Low Risk',\n",
    "    2: 'Moderate Risk',\n",
    "    3: 'High Risk'\n",
    "}\n",
    "\n",
    "# Define feature groups\n",
    "NUMERIC_FEATURES = ['Age', 'Years of Service', 'PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', \n",
    "                    'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', \n",
    "                    'PPG', 'APG', 'SPG', 'TPG', 'BPG', 'Availability', \n",
    "                    'Efficiency', 'Days_Injured_Percentage', 'ValueOverReplacement', 'ExperienceSquared']\n",
    "\n",
    "ONE_HOT_ENCODE_CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk', 'SalaryPct'] #SalaryPct included so it's included in engineer data filter\n",
    "PIPELINE_LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk'] #SalaryPct taken out because this goes through the pipeline. So it's included in engineer features, split into train/test and x/y datasets, then input through the pipeline where it shouldn't be used\n",
    "columns_to_add_back_later = ['Season', 'Salary_Cap_Inflated', 'Player', 'SalaryPct']  \n",
    "\n",
    "# Format Season Column\n",
    "def format_season(data):\n",
    "    \"\"\"Converts the 'Season' column from 'YYYY-YY' to 'YYYY' format.\"\"\"\n",
    "    try:\n",
    "        data['Season'] = data['Season'].apply(lambda x: int(x.split('-')[0]))\n",
    "        logger.info(f\"Seasons in data: {data['Season'].unique()}\")\n",
    "        logger.info(f\"Shape after season formatting: {data.shape}\")\n",
    "        logger.info(f\"Null values after season formatting:\\n{data.isnull().sum()}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to format season data: {e}\")\n",
    "        raise\n",
    "    \n",
    "def filter_seasons(data, predict_season):\n",
    "    \"\"\"Split the data into prior seasons (train) and the selected season (test).\"\"\"\n",
    "    prior_seasons_data = data[data['Season'] < predict_season]\n",
    "    target_season_data = data[data['Season'] == predict_season]\n",
    "    \n",
    "    logger.debug(f\"Data filtered. Prior seasons shape: {prior_seasons_data.shape}, Target season shape: {target_season_data.shape}\")\n",
    "    logger.debug(f\"Feature columns used for training: {prior_seasons_data.columns.tolist()}\")\n",
    "\n",
    "    return prior_seasons_data, target_season_data\n",
    "\n",
    "# Get Feature Names from Pipeline\n",
    "def get_feature_names(pipeline):\n",
    "    \"\"\"Extract feature names after applying transformations in the pipeline.\"\"\"\n",
    "    # Numeric feature names\n",
    "    num_col_names = NUMERIC_FEATURES\n",
    "    \n",
    "    # Categorical feature names (after one-hot encoding)\n",
    "    cat_col_names = pipeline.named_transformers_['cat']['onehot'].get_feature_names_out(ONE_HOT_ENCODE_CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # Combine all column names: numeric, one-hot encoded, and passthrough (without 'SalaryPct')\n",
    "    all_col_names = list(num_col_names) + list(cat_col_names) + PIPELINE_LEAVE_ALONE_FEATURES\n",
    "    \n",
    "    return all_col_names\n",
    "\n",
    "\n",
    "# Label Encoding Injury Risk\n",
    "def label_encode_injury_risk(data):\n",
    "    \"\"\"Encode Injury_Risk using predefined mapping.\"\"\"\n",
    "    logger.debug(\"Label encoding Injury_Risk...\")\n",
    "    logger.debug(f\"First few Injury_Risk values before encoding:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    # Encode Injury_Risk\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(INJURY_RISK_MAP)\n",
    "    logger.debug(f\"First few Injury_Risk values after encoding:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def inverse_transform_injury_risk(data):\n",
    "    \"\"\"Inverse transform Injury_Risk using predefined reverse mapping.\"\"\"\n",
    "    logger.debug(\"Inverse transforming Injury_Risk...\")\n",
    "    logger.debug(f\"First few Injury_Risk values before inverse transformation:\\n{data['Injury_Risk'].head()}\")\n",
    "\n",
    "    # Inverse transform Injury_Risk\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(REVERSE_INJURY_RISK_MAP)\n",
    "    logger.debug(f\"First few Injury_Risk values after inverse transformation:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: load and clean the data\n",
    "def clean_data(file_path):\n",
    "    \"\"\"Load and clean data.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logger.info(f\"Data loaded. Initial shape: {data.shape}\")\n",
    "\n",
    "        # Handle missing percentages and drop unnecessary columns\n",
    "        data['3P%'] = np.where(data['3PA'] != 0, data['3P'] / data['3PA'], np.nan)\n",
    "        data['FT%'] = np.where(data['FTA'] != 0, data['FT'] / data['FTA'], np.nan)\n",
    "        data['2P%'] = np.where(data['2PA'] != 0, data['2P'] / data['2PA'], np.nan)\n",
    "        data.drop(['3P%', 'FT%', '2P%'], axis=1, inplace=True)\n",
    "\n",
    "        columns_to_remove = ['Salary Cap', 'Luxury Tax', '1st Apron', 'BAE', 'Standard /Non-Taxpayer', \n",
    "                             'Taxpayer', 'Team Room /Under Cap', 'Wins', 'Losses', '2nd Apron', 'Injury_Periods']\n",
    "        data.drop(columns_to_remove, axis=1, inplace=True)\n",
    "\n",
    "        # Filter out rows with nulls in advanced stats\n",
    "        advanced_stats_columns = ['PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', \n",
    "                                  'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "        data = data.dropna(subset=advanced_stats_columns)\n",
    "        \n",
    "        logger.info(f\"Final shape after processing: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data cleaning failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Feature Engineering\n",
    "def engineer_features(data):\n",
    "    \"\"\"Feature engineering step where new features are derived from existing ones.\"\"\"\n",
    "    per_game_cols = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "    for col in per_game_cols:\n",
    "        data[f'{col[0]}PG'] = data[col] / data['GP']\n",
    "    \n",
    "    data['Availability'] = data['GP'] / 82\n",
    "    data['SalaryPct'] = data['Salary'] / data['Salary_Cap_Inflated']\n",
    "    data['Efficiency'] = (data['PTS'] + data['TRB'] + data['AST'] + data['STL'] + data['BLK']) / (data['FGA'] + data['FTA'] + data['TOV'] + 1)\n",
    "    data['ValueOverReplacement'] = data['VORP'] / data['GP'] \n",
    "    data['ExperienceSquared'] = data['Years of Service'] ** 2\n",
    "    data['Days_Injured_Percentage'] = data['Total_Days_Injured'] / data['GP']\n",
    "\n",
    "    engineered_data = data.copy()\n",
    "\n",
    "    columns_to_keep_for_pipeline = NUMERIC_FEATURES + ONE_HOT_ENCODE_CATEGORICAL_FEATURES + LEAVE_ALONE_FEATURES\n",
    "    pipeline_data = data[columns_to_keep_for_pipeline]\n",
    "    columns_to_re_add = data[columns_to_add_back_later]\n",
    "    \n",
    "    return engineered_data, pipeline_data, columns_to_re_add\n",
    "\n",
    "# After preprocessing, extract SalaryPct as the target (y)\n",
    "def preprocessed_datasets(file_path):\n",
    "    original_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    cleaned_data = clean_data(file_path)\n",
    "    cleaned_data = format_season(cleaned_data)\n",
    "    \n",
    "    # Get the pipeline data and columns to re-add\n",
    "    engineered_data, pipeline_data, columns_to_re_add = engineer_features(cleaned_data)\n",
    "    \n",
    "    # Label encode the pipeline data\n",
    "    pipeline_data = label_encode_injury_risk(pipeline_data)\n",
    "    \n",
    "    return cleaned_data, engineered_data, pipeline_data, columns_to_re_add\n",
    "\n",
    "# Split the dataset into train and test sets based on the season\n",
    "def filter_seasons(data, predict_season):\n",
    "    \"\"\"Split the data into prior seasons (train) and the selected season (test).\"\"\"\n",
    "    prior_seasons_data = data[data['Season'] < predict_season]\n",
    "    target_season_data = data[data['Season'] == predict_season]\n",
    "    \n",
    "    return prior_seasons_data, target_season_data\n",
    "\n",
    "# Build the Pipeline\n",
    "def build_pipeline():\n",
    "    \"\"\"Creates a data processing pipeline that applies encoding and scaling transformations.\"\"\"\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, NUMERIC_FEATURES),\n",
    "            ('cat', categorical_transformer, ONE_HOT_ENCODE_CATEGORICAL_FEATURES),\n",
    "            ('passthrough', 'passthrough', PIPELINE_LEAVE_ALONE_FEATURES)  # Season and Injury_Risk passthrough\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "        season = 2022\n",
    "        original_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Step 1: Preprocess the dataset\n",
    "        cleaned_data, engineered_data, pipeline_data, columns_to_re_add = preprocessed_datasets(file_path)\n",
    "\n",
    "        # Step 2: Split data into train and test sets based on season\n",
    "        train_data, test_data = filter_seasons(pipeline_data, season)\n",
    "        print(\"days injured unique values = \", train_data['Days_Injured_Percentage'].unique())\n",
    "        print(\"days injured unique values = \", test_data['Days_Injured_Percentage'].unique())\n",
    "        # Step 3: Separate features (X) and target (y)\n",
    "        X_train = train_data.drop('SalaryPct', axis=1)\n",
    "        y_train = train_data['SalaryPct']\n",
    "        X_test = test_data.drop('SalaryPct', axis=1)\n",
    "        y_test = test_data['SalaryPct']\n",
    "\n",
    "        # Step 4: Build and apply the pipeline\n",
    "        pipeline = build_pipeline()\n",
    "        # Before and after pipeline debug\n",
    "        logger.debug(f\"Before pipeline transformation: {X_train.columns.tolist()}\")\n",
    "        X_train_transformed = pipeline.fit_transform(X_train)\n",
    "        logger.debug(f\"After pipeline transformation: {X_train_transformed.shape}\")\n",
    "        logger.debug(f\"Transformed feature names: {pipeline.get_feature_names_out()}\")\n",
    "        print(\"Sample of transformed data:\", X_train_transformed[:5])\n",
    "\n",
    "\n",
    "        # Save the fitted pipeline\n",
    "        joblib.dump(pipeline, f'../data/models/season_{season}/preprocessing_pipeline.pkl')\n",
    "        \n",
    "        columns_to_re_add_train_data, columns_to_re_add_test_data = filter_seasons(columns_to_re_add, season)\n",
    "        columns_to_re_add_train_data = columns_to_re_add_train_data.drop('Season', axis=1)\n",
    "        columns_to_re_add = columns_to_re_add_test_data.drop('Season', axis=1)\n",
    "        print(\"columns_to_re_add =\", columns_to_re_add)\n",
    "        # Save columns to re-add later\n",
    "        joblib.dump(columns_to_re_add, f'../data/models/season_{season}/columns_to_re_add.pkl')\n",
    "\n",
    "        # all_col_names = get_feature_names(pipeline)\n",
    "        # print(\"all column names = \", all_col_names)\n",
    "        # joblib.dump(all_col_names, f'../data/models/season_{season}/feature_names.pkl')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in data processing pipeline: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/model_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/model_trainer.py\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from .data_loader_preprocessor import preprocessed_datasets, build_pipeline, filter_seasons, get_feature_names\n",
    "\n",
    "# Set up logging for debugging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    \"\"\"Performs grid search for hyperparameter tuning.\"\"\"\n",
    "    logger.debug(f\"Starting grid search for {model.__class__.__name__}. Parameters: {param_grid}\")\n",
    "    logger.debug(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logger.info(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "    logger.info(f\"Best score for {model.__class__.__name__}: {-grid_search.best_score_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def train_and_save_models(X_train, y_train, model_save_path):\n",
    "    \"\"\"Train models and save them along with preprocessing pipeline.\"\"\"\n",
    "    logger.debug(f\"Starting model training. Model save path: {model_save_path}\")\n",
    "    logger.debug(f\"Training data shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    xgb_model = xgb.XGBRegressor(random_state=42, enable_categorical=False)\n",
    "\n",
    "    rf_param_grid = {'n_estimators': [100, 200], 'max_depth': [None, 10], 'min_samples_split': [2, 5]}\n",
    "    xgb_param_grid = {'n_estimators': [50, 100], 'max_depth': [3], 'learning_rate': [0.01]}\n",
    "\n",
    "    logger.debug(f\"Performing grid search for RandomForestRegressor.\")\n",
    "    best_rf_model = perform_grid_search(rf_model, rf_param_grid, X_train, y_train)\n",
    "    \n",
    "    logger.debug(f\"Performing grid search for XGBoostRegressor.\")\n",
    "    best_xgb_model = perform_grid_search(xgb_model, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "    # Save the models\n",
    "    joblib.dump(best_rf_model, os.path.join(model_save_path, 'best_rf_model.pkl'))\n",
    "    joblib.dump(best_xgb_model, os.path.join(model_save_path, 'best_xgb_model.pkl'))\n",
    "    logger.info(f\"Models saved in {model_save_path}.\")\n",
    "\n",
    "def evaluate_models(X_test, y_test, model_save_path):\n",
    "    \"\"\"Evaluate models on the test set and save predictions.\"\"\"\n",
    "    rf_model = joblib.load(f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "\n",
    "    logger.debug(f\"Loaded models for evaluation.\")\n",
    "    logger.debug(f\"Evaluating on test data. X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "    rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "    rf_r2 = r2_score(y_test, rf_predictions)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "    xgb_r2 = r2_score(y_test, xgb_predictions)\n",
    "    xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "\n",
    "    logger.info(f\"\\nRandom Forest RMSE: {rf_rmse}\")\n",
    "    logger.info(f\"Random Forest MAE: {rf_mae}\")\n",
    "    logger.info(f\"Random Forest R²: {rf_r2}\")\n",
    "    logger.info(f\"Random Forest MSE: {rf_mse}\")\n",
    "\n",
    "    logger.info(f\"\\nXGBoost RMSE: {xgb_rmse}\")\n",
    "    logger.info(f\"XGBoost MAE: {xgb_mae}\")\n",
    "    logger.info(f\"XGBoost R²: {xgb_r2}\")\n",
    "    logger.info(f\"XGBoost MSE: {xgb_mse}\")\n",
    "\n",
    "    eval_results = {\n",
    "        'rf_predictions': rf_predictions,\n",
    "        'xgb_predictions': xgb_predictions,\n",
    "        'rf_rmse': rf_rmse,\n",
    "        'rf_mae': rf_mae,\n",
    "        'rf_r2': rf_r2,\n",
    "        'rf_mse': rf_mse,\n",
    "        'xgb_rmse': xgb_rmse,\n",
    "        'xgb_mae': xgb_mae,\n",
    "        'xgb_r2': xgb_r2,\n",
    "        'xgb_mse': xgb_mse\n",
    "    }\n",
    "\n",
    "    eval_save_path = f\"{model_save_path}/evaluation_results.pkl\"\n",
    "    joblib.dump(eval_results, eval_save_path)\n",
    "    logger.info(f\"Evaluation results saved at {eval_save_path}\")\n",
    "    \n",
    "    return eval_results\n",
    "\n",
    "def load_and_preprocess_data(file_path, predict_season, model_save_path):\n",
    "    \"\"\"Load data, filter by seasons, and apply preprocessing pipeline.\"\"\"\n",
    "    logger.debug(f\"Loading data and preprocessing for season {predict_season}\")\n",
    "    \n",
    "    # Step 1: Preprocess the dataset\n",
    "    cleaned_data, engineered_data, pipeline_data, columns_to_re_add = preprocessed_datasets(file_path)\n",
    "    \n",
    "    # Step 2: Split data into train and test sets based on season\n",
    "    train_data, test_data = filter_seasons(pipeline_data, predict_season)\n",
    "\n",
    "    # Step 3: Separate features (X) and target (y)\n",
    "    X_train = train_data.drop('SalaryPct', axis=1)\n",
    "    y_train = train_data['SalaryPct']\n",
    "    X_test = test_data.drop('SalaryPct', axis=1)\n",
    "    y_test = test_data['SalaryPct']\n",
    "\n",
    "    # Step 4: Build and apply the pipeline\n",
    "    pipeline = build_pipeline()\n",
    "\n",
    "    X_train_transformed = pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # Save the fitted pipeline\n",
    "    joblib.dump(pipeline, os.path.join(model_save_path, 'preprocessing_pipeline.pkl'))\n",
    "\n",
    "    # Save the columns to re-add later\n",
    "    joblib.dump(columns_to_re_add, os.path.join(model_save_path, 'columns_to_re_add.pkl'))\n",
    "\n",
    "    # Save Features\n",
    "    all_col_names = get_feature_names(pipeline)\n",
    "    print(\"all column names = \", all_col_names)\n",
    "    joblib.dump(all_col_names, os.path.join(model_save_path, 'feature_names.pkl'))\n",
    "    \n",
    "    return X_train_transformed, X_test_transformed, y_train, y_test\n",
    "\n",
    "# Model Training Pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2022\n",
    "    model_save_path = f'../data/models/season_{predict_season}'\n",
    "\n",
    "    \n",
    "    logger.debug(f\"Starting the pipeline for season {predict_season} with file: {file_path}\")\n",
    "    \n",
    "    # Load and preprocess the data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path, predict_season, model_save_path)\n",
    "    \n",
    "    # Train and save models\n",
    "    train_and_save_models(X_train, y_train, model_save_path)\n",
    "    \n",
    "    # Evaluate models on the test set\n",
    "    evaluated_models = evaluate_models(X_test, y_test, model_save_path)\n",
    "    print(\"metrics = \", evaluated_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/model_predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/model_predictor.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np  # Add this import for numpy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "\n",
    "# Add relative imports for functions and constants\n",
    "from .data_loader_preprocessor import preprocessed_datasets, filter_seasons, inverse_transform_injury_risk\n",
    "from .model_trainer import load_and_preprocess_data, train_and_save_models, evaluate_models  # Add this line\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "INJURY_RISK_MAP = {\n",
    "    'Low Risk': 1,\n",
    "    'Moderate Risk': 2,\n",
    "    'High Risk': 3\n",
    "}\n",
    "\n",
    "REVERSE_INJURY_RISK_MAP = {\n",
    "    1: 'Low Risk',\n",
    "    2: 'Moderate Risk',\n",
    "    3: 'High Risk'\n",
    "}\n",
    "\n",
    "# Define feature groups\n",
    "NUMERIC_FEATURES = ['Age', 'Years of Service', 'PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', \n",
    "                    'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', \n",
    "                    'PPG', 'APG', 'SPG', 'TPG', 'BPG', 'Availability', \n",
    "                    'Efficiency', 'Days_Injured_Percentage', 'ValueOverReplacement', 'ExperienceSquared']\n",
    "\n",
    "ONE_HOT_ENCODE_CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk', 'SalaryPct'] \n",
    "PIPELINE_LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk'] \n",
    "columns_to_add_back_later = ['Season', 'Salary_Cap_Inflated', 'Player', 'SalaryPct']  \n",
    "\n",
    "CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "PASSTHROUGH_FEATURES = ['Season', 'Injury_Risk']\n",
    "\n",
    "def load_models_and_pipeline(model_save_path, predict_season):\n",
    "    season_model_path = model_save_path\n",
    "    logger.debug(f\"Loading models and pipeline for season {predict_season} from {season_model_path}\")\n",
    "\n",
    "    rf_model = joblib.load(f\"{season_model_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{season_model_path}/best_xgb_model.pkl\")\n",
    "    pipeline = joblib.load(f\"{season_model_path}/preprocessing_pipeline.pkl\")\n",
    "    columns_to_re_add = joblib.load(f\"{season_model_path}/columns_to_re_add.pkl\")\n",
    "    feature_names = joblib.load(f\"{season_model_path}/feature_names.pkl\")\n",
    "    \n",
    "    return rf_model, xgb_model, pipeline, columns_to_re_add, feature_names\n",
    "\n",
    "def load_and_preprocess_test_data(file_path, predict_season, model_save_path):\n",
    "    logger.debug(\"Loading and preprocessing test data...\")\n",
    "    cleaned_data, engineered_data, pipeline_data, _ = preprocessed_datasets(file_path)\n",
    "\n",
    "    # Filter data for the prediction season\n",
    "    _, test_data = filter_seasons(pipeline_data, predict_season)\n",
    "\n",
    "    X_test = test_data.drop('SalaryPct', axis=1)\n",
    "    y_test = test_data['SalaryPct']\n",
    "\n",
    "    # Debugging the columns before transformation\n",
    "    logger.debug(f\"Test data shape before transformation: {X_test.shape}\")\n",
    "    logger.debug(f\"Test data columns before transformation: {X_test.columns.tolist()}\")\n",
    "\n",
    "    # Check unique values for Injury_Risk and Total_Days_Injured before transformation\n",
    "    logger.debug(f\"Unique values of 'Injury_Risk' before transformation: {X_test['Injury_Risk'].unique()}\")\n",
    "    logger.debug(f\"Unique values of 'Days_Injured_Percentage' before transformation: {test_data['Days_Injured_Percentage'].unique()}\")\n",
    "\n",
    "    rf_model, xgb_model, pipeline, columns_to_re_add, feature_names = load_models_and_pipeline(model_save_path, predict_season)\n",
    "\n",
    "    # Separate and log the numerical columns\n",
    "    X_test_numeric = X_test[NUMERIC_FEATURES]\n",
    "    logger.debug(f\"Numerical data before transformation (shape): {X_test_numeric.shape}\")\n",
    "    logger.debug(f\"Numerical data before transformation (columns): {X_test_numeric.columns.tolist()}\")\n",
    "    logger.debug(f\"Sample of numerical data: {X_test_numeric.head()}\")\n",
    "\n",
    "    # Transform the data\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # Debugging the transformed numerical data\n",
    "    numeric_transformer = pipeline.named_transformers_['num']['scaler']\n",
    "    transformed_numeric = numeric_transformer.transform(X_test_numeric)\n",
    "    logger.debug(f\"Transformed numerical data shape: {transformed_numeric.shape}\")\n",
    "    logger.debug(f\"Sample of transformed numerical data: {transformed_numeric[:5]}\")\n",
    "\n",
    "    # Check passthrough Injury_Risk after transformation (since it's not transformed)\n",
    "    logger.debug(f\"Unique values of 'Injury_Risk' after transformation (passthrough): {X_test['Injury_Risk'].unique()}\")\n",
    "\n",
    "    # Check Total_Days_Injured after transformation (it should be included in the numeric transformations)\n",
    "    logger.debug(f\"Transformed 'Total_Days_Injured' values (numeric feature): {transformed_numeric[:, NUMERIC_FEATURES.index('Days_Injured_Percentage')][:5]}\")\n",
    "\n",
    "    # Debug the final transformed data shape\n",
    "    logger.debug(f\"Shape of transformed data: {X_test_transformed.shape}\")\n",
    "    \n",
    "    return X_test, X_test_transformed, y_test, columns_to_re_add, feature_names, pipeline\n",
    "\n",
    "def inverse_transform_and_add_context(rf_predictions, xgb_predictions, X_test, X_test_transformed, columns_to_re_add, feature_names, pipeline):\n",
    "    logger.debug(f\"Shape of rf_predictions: {rf_predictions.shape}\")\n",
    "\n",
    "    # Convert predictions to DataFrame\n",
    "    rf_predictions_df = pd.DataFrame(rf_predictions, columns=['Predicted_SalaryPct'], index=X_test.index)\n",
    "    xgb_predictions_df = pd.DataFrame(xgb_predictions, columns=['Predicted_SalaryPct'], index=X_test.index)\n",
    "\n",
    "    # Inverse transform numerical features\n",
    "    numeric_transformer = pipeline.named_transformers_['num']['scaler']\n",
    "    X_test_numeric = X_test[NUMERIC_FEATURES]\n",
    "    X_test_numeric_inverse = pd.DataFrame(\n",
    "        numeric_transformer.inverse_transform(X_test_transformed[:, :len(NUMERIC_FEATURES)]),\n",
    "        columns=NUMERIC_FEATURES,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # Inverse transform categorical features\n",
    "    categorical_transformer = pipeline.named_transformers_['cat']['onehot']\n",
    "    transformed_cat_indices = slice(len(NUMERIC_FEATURES), -len(PASSTHROUGH_FEATURES))  # Indices of categorical features\n",
    "    X_test_categorical_inverse = pd.DataFrame(\n",
    "        categorical_transformer.inverse_transform(X_test_transformed[:, transformed_cat_indices]),\n",
    "        columns=ONE_HOT_ENCODE_CATEGORICAL_FEATURES,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # Handle passthrough features (Season, Injury_Risk) directly\n",
    "    X_test_passthrough = X_test[PASSTHROUGH_FEATURES]\n",
    "\n",
    "    # Concatenate inverse-transformed numeric, categorical, and passthrough columns\n",
    "    X_test_inverse_transformed = pd.concat([X_test_numeric_inverse, X_test_categorical_inverse, X_test_passthrough], axis=1)\n",
    "\n",
    "    # Re-add the context columns (e.g., Salary_Cap_Inflated, Total_Days_Injured)\n",
    "    context_columns_df = pd.DataFrame(columns_to_re_add, index=X_test.index)\n",
    "\n",
    "    # Inverse transform the Injury_Risk column back to original categories\n",
    "    X_test_inverse_transformed = inverse_transform_injury_risk(X_test_inverse_transformed)\n",
    "\n",
    "    # Final prediction DataFrames\n",
    "    final_rf_df = pd.concat([X_test_inverse_transformed, context_columns_df, rf_predictions_df], axis=1)\n",
    "    final_xgb_df = pd.concat([X_test_inverse_transformed, context_columns_df, xgb_predictions_df], axis=1)\n",
    "\n",
    "    # Add Predicted_Salary column (in millions) by multiplying Predicted_SalaryPct with Salary_Cap_Inflated\n",
    "    final_rf_df['Predicted_Salary'] = (final_rf_df['Predicted_SalaryPct'] * final_rf_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "    final_xgb_df['Predicted_Salary'] = (final_xgb_df['Predicted_SalaryPct'] * final_xgb_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "\n",
    "    # Add Predicted_Salary column (in millions) by multiplying Predicted_SalaryPct with Salary_Cap_Inflated\n",
    "    final_rf_df['Salary'] = (final_rf_df['SalaryPct'] * final_rf_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "    final_xgb_df['Salary'] = (final_xgb_df['SalaryPct'] * final_xgb_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "\n",
    "    \n",
    "    return final_rf_df, final_xgb_df\n",
    "\n",
    "\n",
    "def save_predictions(final_rf_df, final_xgb_df, model_save_path):\n",
    "    rf_save_path = f\"{model_save_path}/rf_predictions.csv\"\n",
    "    xgb_save_path = f\"{model_save_path}/xgb_predictions.csv\"\n",
    "\n",
    "    final_rf_df.to_csv(rf_save_path, index=False)\n",
    "    final_xgb_df.to_csv(xgb_save_path, index=False)\n",
    "\n",
    "    logger.info(f\"Predictions saved to {rf_save_path} and {xgb_save_path}\")\n",
    "\n",
    "\n",
    "# Main function to run the prediction pipeline\n",
    "def make_predictions(file_path, predict_season, model_save_path):\n",
    "    logger.debug(\"Starting prediction pipeline...\")\n",
    "\n",
    "    # Step 1: Load and preprocess test data\n",
    "    X_test, X_test_transformed, y_test, columns_to_re_add, feature_names, pipeline = load_and_preprocess_test_data(file_path, predict_season, model_save_path)\n",
    "\n",
    "    logger.debug(f\"Shape of X_test_transformed before predictions: {X_test_transformed.shape}\")\n",
    "\n",
    "    # Step 2: Load models\n",
    "    rf_model, xgb_model, _, _, _ = load_models_and_pipeline(model_save_path, predict_season)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    rf_predictions = rf_model.predict(X_test_transformed)\n",
    "    xgb_predictions = xgb_model.predict(X_test_transformed)\n",
    "\n",
    "    logger.debug(f\"RF Predictions: {rf_predictions[:5]}\")\n",
    "    logger.debug(f\"XGB Predictions: {xgb_predictions[:5]}\")\n",
    "\n",
    "    # Step 4: Inverse transform and add context\n",
    "    final_rf_df, final_xgb_df = inverse_transform_and_add_context(rf_predictions, xgb_predictions, X_test, X_test_transformed, columns_to_re_add, feature_names, pipeline)\n",
    "\n",
    "    # Drop one of the duplicate 'Season' columns\n",
    "    if 'Season' in final_rf_df.columns:\n",
    "        final_rf_df = final_rf_df.loc[:, ~final_rf_df.columns.duplicated()]\n",
    "    \n",
    "    if 'Season' in final_xgb_df.columns:\n",
    "        final_xgb_df = final_xgb_df.loc[:, ~final_xgb_df.columns.duplicated()]\n",
    "\n",
    "    # Step 5: Save predictions\n",
    "    save_predictions(final_rf_df, final_xgb_df, model_save_path)\n",
    "\n",
    "    return final_rf_df, final_xgb_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2022\n",
    "    model_save_path = f'../data/models/season_{predict_season}'\n",
    "\n",
    "    rf_final_df, xgb_final_df = make_predictions(file_path, predict_season, model_save_path)\n",
    "    print(rf_final_df)\n",
    "    print(rf_final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/util_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/util_functions.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from .data_loader_preprocessor import preprocessed_datasets\n",
    "from .model_trainer import load_and_preprocess_data, train_and_save_models, evaluate_models  # Add this line\n",
    "from .model_predictor import make_predictions\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "CATEGORICAL_FEATURES = ['Position_', 'Team_']\n",
    "\n",
    "def load_evaluation_metrics(model_save_path):\n",
    "    \"\"\"Load saved evaluation metrics.\"\"\"\n",
    "    eval_save_path = f\"{model_save_path}/evaluation_results.pkl\"\n",
    "    if os.path.exists(eval_save_path):\n",
    "        eval_results = joblib.load(eval_save_path)\n",
    "        return eval_results\n",
    "    else:\n",
    "        print(\"Evaluation results not found.\")\n",
    "        return None\n",
    "\n",
    "def check_or_train_model(file_path, model_save_path, season_year):\n",
    "    logger.debug(f\"Received season_year: {season_year}, Type: {type(season_year)}\")\n",
    "\n",
    "    # Convert season_year to an integer if it's a string\n",
    "    if isinstance(season_year, str):\n",
    "        season_year = int(season_year)\n",
    "        logger.debug(f\"Converted season_year to int: {season_year}, Type: {type(season_year)}\")\n",
    "\n",
    "    predictions_file_path = f'{model_save_path}/rf_predictions.csv'\n",
    "    if os.path.exists(predictions_file_path):\n",
    "        logger.debug(f\"Predictions file found for {season_year}.\")\n",
    "        predictions_df = pd.read_csv(predictions_file_path)\n",
    "    else:\n",
    "        logger.debug(f\"Predictions not available for {season_year}. Training the model now...\")\n",
    "        \n",
    "        # Train and predict\n",
    "        X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path, season_year, model_save_path)\n",
    "        train_and_save_models(X_train, y_train, model_save_path)\n",
    "        evaluate_models(X_test, y_test, model_save_path)\n",
    "\n",
    "        # Generate predictions\n",
    "        rf_final_df, xgb_final_df = make_predictions(file_path, season_year, model_save_path)\n",
    "        predictions_df = pd.concat([rf_final_df, xgb_final_df], axis=1)\n",
    "\n",
    "    return predictions_df\n",
    "\n",
    "\n",
    "\n",
    "def display_model_metrics(model_save_path):\n",
    "    \"\"\"Display saved model performance metrics for both Random Forest and XGBoost.\"\"\"\n",
    "    eval_results = load_evaluation_metrics(model_save_path)\n",
    "\n",
    "    if eval_results:\n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Random Forest RMSE: {eval_results['rf_rmse']:.4f}\")\n",
    "        print(f\"Random Forest MAE: {eval_results['rf_mae']:.4f}\")\n",
    "        print(f\"Random Forest R²: {eval_results['rf_r2']:.4f}\")\n",
    "        print(f\"Random Forest MSE: {eval_results['rf_mse']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nXGBoost RMSE: {eval_results['xgb_rmse']:.4f}\")\n",
    "        print(f\"XGBoost MAE: {eval_results['xgb_mae']:.4f}\")\n",
    "        print(f\"XGBoost R²: {eval_results['xgb_r2']:.4f}\")\n",
    "        print(f\"XGBoost MSE: {eval_results['xgb_mse']:.4f}\")\n",
    "    else:\n",
    "        print(\"No evaluation metrics found.\")\n",
    "\n",
    "def filter_categorical_features(importance_df, categorical_features):\n",
    "    \"\"\"Filter out categorical features from the importance dataframe.\"\"\"\n",
    "    filtered_df = importance_df[~importance_df['Feature'].str.startswith(tuple(categorical_features))]\n",
    "    return filtered_df\n",
    "\n",
    "def display_feature_importance(model, feature_names, categorical_features):\n",
    "    \"\"\"Displays feature importance for the selected model, filtering out categorical features.\"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        n_features = len(model.feature_importances_)\n",
    "        print(f\"Number of features in model: {n_features}\")\n",
    "        \n",
    "        # Create the DataFrame of feature importances\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names[:n_features],  # Adjust if feature names mismatch\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values(by=\"Importance\", ascending=False)\n",
    "        \n",
    "        # Filter out categorical features\n",
    "        filtered_importance_df = filter_categorical_features(importance_df, categorical_features)\n",
    "        return filtered_importance_df\n",
    "    else:\n",
    "        print(\"This model does not support feature importance visualization.\")\n",
    "        return None\n",
    "\n",
    "def plot_feature_importance(feature_importances_df, model_name):\n",
    "    \"\"\"Function to plot the feature importance as a bar chart.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances_df['Feature'], feature_importances_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(f'{model_name} Feature Importance')\n",
    "    plt.gca().invert_yaxis()  # Most important feature at the top\n",
    "    return plt\n",
    "\n",
    "def identify_overpaid_underpaid(predictions_df, top_n=10):\n",
    "    logger.debug(f\"Checking Salary and Predicted_Salary columns\")\n",
    "    \n",
    "    # Check for duplicate columns and remove them\n",
    "    predictions_df = predictions_df.loc[:, ~predictions_df.columns.duplicated()]\n",
    "    \n",
    "    logger.debug(f\"Salary type: {type(predictions_df['Salary'].iloc[0])}, Predicted_Salary type: {type(predictions_df['Predicted_Salary'].iloc[0])}\")\n",
    "    logger.debug(f\"First few Salary values: {predictions_df['Salary'].head()}\")\n",
    "    logger.debug(f\"First few Predicted_Salary values: {predictions_df['Predicted_Salary'].head()}\")\n",
    "    \n",
    "    # Calculate salary differences\n",
    "    predictions_df['Salary_Difference'] = predictions_df['Salary'] - predictions_df['Predicted_Salary']\n",
    "    \n",
    "    # Identify overpaid and underpaid players\n",
    "    overpaid = predictions_df[predictions_df['Salary_Difference'] > 0].sort_values('Salary_Difference', ascending=False).head(top_n)\n",
    "    underpaid = predictions_df[predictions_df['Salary_Difference'] < 0].sort_values('Salary_Difference').head(top_n)\n",
    "    \n",
    "    logger.debug(f\"Top overpaid: {overpaid[['Player', 'Salary', 'Predicted_Salary', 'Salary_Difference']].head()}\")\n",
    "    logger.debug(f\"Top underpaid: {underpaid[['Player', 'Salary', 'Predicted_Salary', 'Salary_Difference']].head()}\")\n",
    "    \n",
    "    return overpaid, underpaid\n",
    "\n",
    "\n",
    "\n",
    "def display_overpaid_underpaid(predictions_df, top_n=10):\n",
    "    \"\"\"Display top overpaid and underpaid players.\"\"\"\n",
    "    overpaid, underpaid = identify_overpaid_underpaid(predictions_df, top_n)\n",
    "\n",
    "    print(f\"\\nTop {top_n} Overpaid Players:\")\n",
    "    print(overpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "    print(f\"\\nTop {top_n} Underpaid Players:\")\n",
    "    print(underpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_distribution(data, feature):\n",
    "    \"\"\"Plot the distribution of a selected feature.\"\"\"\n",
    "    logger.debug(f\"Plotting distribution for feature: {feature}\")\n",
    "    fig, ax = plt.subplots()\n",
    "    data[feature].hist(ax=ax, bins=20)\n",
    "    ax.set_title(f\"Distribution of {feature}\")\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(data):\n",
    "    \"\"\"Plot a correlation heatmap of the numerical features in the dataset.\"\"\"\n",
    "    logger.debug(\"Plotting correlation heatmap for numeric features.\")\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    corr = numeric_data.corr()\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', ax=ax)\n",
    "    ax.set_title('Correlation Heatmap')\n",
    "    return fig\n",
    "\n",
    "def test_data_analysis_functions():\n",
    "    \"\"\"Test the data analysis utility functions.\"\"\"\n",
    "    # Load some test data\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    cleaned_data, engineered_data, pipeline_data, columns_to_re_add = preprocessed_datasets(file_path)\n",
    "\n",
    "    # Select a feature to test the distribution plot\n",
    "    feature = 'SalaryPct'  # Choose a numerical feature available in your dataset\n",
    "    logger.debug(f\"Testing feature distribution for: {feature}\")\n",
    "    \n",
    "    # Test the feature distribution function\n",
    "    fig = plot_feature_distribution(pipeline_data, feature)\n",
    "    fig.show()  # Show the plot to ensure it's working correctly\n",
    "\n",
    "    # Test the correlation heatmap function\n",
    "    logger.debug(\"Testing correlation heatmap plot.\")\n",
    "    fig = plot_correlation_heatmap(pipeline_data)\n",
    "    fig.show()  # Show the heatmap plot\n",
    "\n",
    "\n",
    "\n",
    "def main_test_function():\n",
    "    \"\"\"Main function to test all utility functions.\"\"\"\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    season_year = '2021'  # initially a string\n",
    "    logger.debug(f\"Original season_year: {season_year}, Type: {type(season_year)}\")\n",
    "\n",
    "    # Convert to integer if necessary\n",
    "    if isinstance(season_year, str):\n",
    "        season_year = int(season_year)\n",
    "        logger.debug(f\"Converted season_year to int: {season_year}, Type: {season_year}\")\n",
    "\n",
    "    model_save_path = f'../data/models/season_{season_year}'\n",
    "\n",
    "    # Test check_or_train_model\n",
    "    predictions_df = check_or_train_model(file_path, model_save_path, season_year)\n",
    "    logger.debug(f\"Predictions DataFrame:\\n{predictions_df.head()}\")\n",
    "\n",
    "    # Test display_model_metrics\n",
    "    display_model_metrics(model_save_path)\n",
    "\n",
    "    # Load a model for testing feature importance\n",
    "    rf_model_path = f'{model_save_path}/best_rf_model.pkl'\n",
    "    rf_model = joblib.load(rf_model_path)\n",
    "    feature_names_path = f'{model_save_path}/feature_names.pkl'\n",
    "    feature_names = joblib.load(feature_names_path)\n",
    "\n",
    "    # Test display_feature_importance with filtering categorical features\n",
    "    feature_importances_df = display_feature_importance(rf_model, feature_names, CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # Test plot_feature_importance\n",
    "    plot = plot_feature_importance(feature_importances_df, \"Random Forest\")\n",
    "    plot.show()\n",
    "\n",
    "    # Test display_overpaid_underpaid\n",
    "    display_overpaid_underpaid(predictions_df)\n",
    "\n",
    "    # Test the data analysis functions\n",
    "    test_data_analysis_functions()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_test_function()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
