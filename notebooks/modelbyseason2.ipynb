{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/data_loader_preprocessor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/data_loader_preprocessor.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "INJURY_RISK_MAP = {\n",
    "    'Low Risk': 1,\n",
    "    'Moderate Risk': 2,\n",
    "    'High Risk': 3\n",
    "}\n",
    "\n",
    "REVERSE_INJURY_RISK_MAP = {\n",
    "    1: 'Low Risk',\n",
    "    2: 'Moderate Risk',\n",
    "    3: 'High Risk'\n",
    "}\n",
    "\n",
    "# Define feature groups\n",
    "NUMERIC_FEATURES = ['Age', 'Years of Service', 'PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', \n",
    "                    'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', \n",
    "                    'PPG', 'APG', 'SPG', 'TPG', 'BPG', 'Availability', \n",
    "                    'Efficiency', 'Days_Injured_Percentage', 'ValueOverReplacement', 'ExperienceSquared']\n",
    "\n",
    "ONE_HOT_ENCODE_CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk', 'SalaryPct'] #SalaryPct included so it's included in engineer data filter\n",
    "PIPELINE_LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk'] #SalaryPct taken out because this goes through the pipeline. So it's included in engineer features, split into train/test and x/y datasets, then input through the pipeline where it shouldn't be used\n",
    "columns_to_add_back_later = ['Season', 'Salary_Cap_Inflated', 'Player', 'SalaryPct']  \n",
    "\n",
    "# Format Season Column\n",
    "def format_season(data):\n",
    "    \"\"\"Converts the 'Season' column from 'YYYY-YY' to 'YYYY' format.\"\"\"\n",
    "    try:\n",
    "        data['Season'] = data['Season'].apply(lambda x: int(x.split('-')[0]))\n",
    "        logger.info(f\"Seasons in data: {data['Season'].unique()}\")\n",
    "        logger.info(f\"Shape after season formatting: {data.shape}\")\n",
    "        logger.info(f\"Null values after season formatting:\\n{data.isnull().sum()}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to format season data: {e}\")\n",
    "        raise\n",
    "    \n",
    "def filter_seasons(data, predict_season):\n",
    "    \"\"\"Split the data into prior seasons (train) and the selected season (test).\"\"\"\n",
    "    prior_seasons_data = data[data['Season'] < predict_season]\n",
    "    target_season_data = data[data['Season'] == predict_season]\n",
    "    \n",
    "    logger.debug(f\"Data filtered. Prior seasons shape: {prior_seasons_data.shape}, Target season shape: {target_season_data.shape}\")\n",
    "    logger.debug(f\"Feature columns used for training: {prior_seasons_data.columns.tolist()}\")\n",
    "\n",
    "    return prior_seasons_data, target_season_data\n",
    "\n",
    "# Get Feature Names from Pipeline\n",
    "def get_feature_names(pipeline):\n",
    "    \"\"\"Extract feature names after applying transformations in the pipeline.\"\"\"\n",
    "    # Numeric feature names\n",
    "    num_col_names = NUMERIC_FEATURES\n",
    "    \n",
    "    # Categorical feature names (after one-hot encoding)\n",
    "    cat_col_names = pipeline.named_transformers_['cat']['onehot'].get_feature_names_out(ONE_HOT_ENCODE_CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # Combine all column names: numeric, one-hot encoded, and passthrough (without 'SalaryPct')\n",
    "    all_col_names = list(num_col_names) + list(cat_col_names) + PIPELINE_LEAVE_ALONE_FEATURES\n",
    "    \n",
    "    return all_col_names\n",
    "\n",
    "\n",
    "# Label Encoding Injury Risk\n",
    "def label_encode_injury_risk(data):\n",
    "    \"\"\"Encode Injury_Risk using predefined mapping.\"\"\"\n",
    "    logger.debug(\"Label encoding Injury_Risk...\")\n",
    "    logger.debug(f\"First few Injury_Risk values before encoding:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    # Encode Injury_Risk\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(INJURY_RISK_MAP)\n",
    "    logger.debug(f\"First few Injury_Risk values after encoding:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "def inverse_transform_injury_risk(data):\n",
    "    \"\"\"Inverse transform Injury_Risk using predefined reverse mapping.\"\"\"\n",
    "    logger.debug(\"Inverse transforming Injury_Risk...\")\n",
    "    logger.debug(f\"First few Injury_Risk values before inverse transformation:\\n{data['Injury_Risk'].head()}\")\n",
    "\n",
    "    # Inverse transform Injury_Risk\n",
    "    data['Injury_Risk'] = data['Injury_Risk'].map(REVERSE_INJURY_RISK_MAP)\n",
    "    logger.debug(f\"First few Injury_Risk values after inverse transformation:\\n{data['Injury_Risk'].head()}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: load and clean the data\n",
    "def clean_data(file_path):\n",
    "    \"\"\"Load and clean data.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logger.info(f\"Data loaded. Initial shape: {data.shape}\")\n",
    "\n",
    "        # Handle missing percentages and drop unnecessary columns\n",
    "        data['3P%'] = np.where(data['3PA'] != 0, data['3P'] / data['3PA'], np.nan)\n",
    "        data['FT%'] = np.where(data['FTA'] != 0, data['FT'] / data['FTA'], np.nan)\n",
    "        data['2P%'] = np.where(data['2PA'] != 0, data['2P'] / data['2PA'], np.nan)\n",
    "        data.drop(['3P%', 'FT%', '2P%'], axis=1, inplace=True)\n",
    "\n",
    "        columns_to_remove = ['Salary Cap', 'Luxury Tax', '1st Apron', 'BAE', 'Standard /Non-Taxpayer', \n",
    "                             'Taxpayer', 'Team Room /Under Cap', 'Wins', 'Losses', '2nd Apron', 'Injury_Periods']\n",
    "        data.drop(columns_to_remove, axis=1, inplace=True)\n",
    "\n",
    "        # Filter out rows with nulls in advanced stats\n",
    "        advanced_stats_columns = ['PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', \n",
    "                                  'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP']\n",
    "        data = data.dropna(subset=advanced_stats_columns)\n",
    "        \n",
    "        logger.info(f\"Final shape after processing: {data.shape}\")\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data cleaning failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Feature Engineering\n",
    "def engineer_features(data):\n",
    "    \"\"\"Feature engineering step where new features are derived from existing ones.\"\"\"\n",
    "    per_game_cols = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "    for col in per_game_cols:\n",
    "        data[f'{col[0]}PG'] = data[col] / data['GP']\n",
    "    \n",
    "    data['Availability'] = data['GP'] / 82\n",
    "    data['SalaryPct'] = data['Salary'] / data['Salary_Cap_Inflated']\n",
    "    data['Efficiency'] = (data['PTS'] + data['TRB'] + data['AST'] + data['STL'] + data['BLK']) / (data['FGA'] + data['FTA'] + data['TOV'] + 1)\n",
    "    data['ValueOverReplacement'] = data['VORP'] / data['GP'] \n",
    "    data['ExperienceSquared'] = data['Years of Service'] ** 2\n",
    "    data['Days_Injured_Percentage'] = data['Total_Days_Injured'] / data['GP']\n",
    "\n",
    "    engineered_data = data.copy()\n",
    "\n",
    "    columns_to_keep_for_pipeline = NUMERIC_FEATURES + ONE_HOT_ENCODE_CATEGORICAL_FEATURES + LEAVE_ALONE_FEATURES\n",
    "    pipeline_data = data[columns_to_keep_for_pipeline]\n",
    "    columns_to_re_add = data[columns_to_add_back_later]\n",
    "    \n",
    "    return engineered_data, pipeline_data, columns_to_re_add\n",
    "\n",
    "# After preprocessing, extract SalaryPct as the target (y)\n",
    "def preprocessed_datasets(file_path):\n",
    "    original_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    cleaned_data = clean_data(file_path)\n",
    "    cleaned_data = format_season(cleaned_data)\n",
    "    \n",
    "    # Get the pipeline data and columns to re-add\n",
    "    engineered_data, pipeline_data, columns_to_re_add = engineer_features(cleaned_data)\n",
    "    \n",
    "    # Label encode the pipeline data\n",
    "    pipeline_data = label_encode_injury_risk(pipeline_data)\n",
    "    \n",
    "    return cleaned_data, engineered_data, pipeline_data, columns_to_re_add\n",
    "\n",
    "# Split the dataset into train and test sets based on the season\n",
    "def filter_seasons(data, predict_season):\n",
    "    \"\"\"Split the data into prior seasons (train) and the selected season (test).\"\"\"\n",
    "    prior_seasons_data = data[data['Season'] < predict_season]\n",
    "    target_season_data = data[data['Season'] == predict_season]\n",
    "    \n",
    "    return prior_seasons_data, target_season_data\n",
    "\n",
    "# Build the Pipeline\n",
    "def build_pipeline():\n",
    "    \"\"\"Creates a data processing pipeline that applies encoding and scaling transformations.\"\"\"\n",
    "    numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "    categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, NUMERIC_FEATURES),\n",
    "            ('cat', categorical_transformer, ONE_HOT_ENCODE_CATEGORICAL_FEATURES),\n",
    "            ('passthrough', 'passthrough', PIPELINE_LEAVE_ALONE_FEATURES)  # Season and Injury_Risk passthrough\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "        season = 2022\n",
    "        original_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Step 1: Preprocess the dataset\n",
    "        cleaned_data, engineered_data, pipeline_data, columns_to_re_add = preprocessed_datasets(file_path)\n",
    "\n",
    "        # Step 2: Split data into train and test sets based on season\n",
    "        train_data, test_data = filter_seasons(pipeline_data, season)\n",
    "        print(\"days injured unique values = \", train_data['Days_Injured_Percentage'].unique())\n",
    "        print(\"days injured unique values = \", test_data['Days_Injured_Percentage'].unique())\n",
    "        # Step 3: Separate features (X) and target (y)\n",
    "        X_train = train_data.drop('SalaryPct', axis=1)\n",
    "        y_train = train_data['SalaryPct']\n",
    "        X_test = test_data.drop('SalaryPct', axis=1)\n",
    "        y_test = test_data['SalaryPct']\n",
    "\n",
    "        # Step 4: Build and apply the pipeline\n",
    "        pipeline = build_pipeline()\n",
    "        # Before and after pipeline debug\n",
    "        logger.debug(f\"Before pipeline transformation: {X_train.columns.tolist()}\")\n",
    "        X_train_transformed = pipeline.fit_transform(X_train)\n",
    "        logger.debug(f\"After pipeline transformation: {X_train_transformed.shape}\")\n",
    "        logger.debug(f\"Transformed feature names: {pipeline.get_feature_names_out()}\")\n",
    "        print(\"Sample of transformed data:\", X_train_transformed[:5])\n",
    "\n",
    "\n",
    "        # Save the fitted pipeline\n",
    "        joblib.dump(pipeline, f'../data/models/season_{season}/preprocessing_pipeline.pkl')\n",
    "        \n",
    "        columns_to_re_add_train_data, columns_to_re_add_test_data = filter_seasons(columns_to_re_add, season)\n",
    "        columns_to_re_add_train_data = columns_to_re_add_train_data.drop('Season', axis=1)\n",
    "        columns_to_re_add = columns_to_re_add_test_data.drop('Season', axis=1)\n",
    "        print(\"columns_to_re_add =\", columns_to_re_add)\n",
    "        # Save columns to re-add later\n",
    "        joblib.dump(columns_to_re_add, f'../data/models/season_{season}/columns_to_re_add.pkl')\n",
    "\n",
    "        all_col_names = get_feature_names(pipeline)\n",
    "        print(\"all column names = \", all_col_names)\n",
    "        joblib.dump(all_col_names, f'../data/models/season_{season}/feature_names.pkl')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical error in data processing pipeline: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/model_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/model_trainer.py\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from .data_loader_preprocessor import preprocessed_datasets, build_pipeline, filter_seasons\n",
    "\n",
    "# Set up logging for debugging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def perform_grid_search(model, param_grid, X_train, y_train):\n",
    "    \"\"\"Performs grid search for hyperparameter tuning.\"\"\"\n",
    "    logger.debug(f\"Starting grid search for {model.__class__.__name__}. Parameters: {param_grid}\")\n",
    "    logger.debug(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logger.info(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "    logger.info(f\"Best score for {model.__class__.__name__}: {-grid_search.best_score_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "def train_and_save_models(X_train, y_train, model_save_path):\n",
    "    \"\"\"Train models and save them along with preprocessing pipeline.\"\"\"\n",
    "    logger.debug(f\"Starting model training. Model save path: {model_save_path}\")\n",
    "    logger.debug(f\"Training data shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    \n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    xgb_model = xgb.XGBRegressor(random_state=42, enable_categorical=False)\n",
    "\n",
    "    rf_param_grid = {'n_estimators': [100, 200], 'max_depth': [None, 10], 'min_samples_split': [2, 5]}\n",
    "    xgb_param_grid = {'n_estimators': [50, 100], 'max_depth': [3], 'learning_rate': [0.01]}\n",
    "\n",
    "    logger.debug(f\"Performing grid search for RandomForestRegressor.\")\n",
    "    best_rf_model = perform_grid_search(rf_model, rf_param_grid, X_train, y_train)\n",
    "    \n",
    "    logger.debug(f\"Performing grid search for XGBoostRegressor.\")\n",
    "    best_xgb_model = perform_grid_search(xgb_model, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "    # Save the models\n",
    "    joblib.dump(best_rf_model, os.path.join(model_save_path, 'best_rf_model.pkl'))\n",
    "    joblib.dump(best_xgb_model, os.path.join(model_save_path, 'best_xgb_model.pkl'))\n",
    "    logger.info(f\"Models saved in {model_save_path}.\")\n",
    "\n",
    "def evaluate_models(X_test, y_test, model_save_path):\n",
    "    \"\"\"Evaluate models on the test set and save predictions.\"\"\"\n",
    "    rf_model = joblib.load(f\"{model_save_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{model_save_path}/best_xgb_model.pkl\")\n",
    "\n",
    "    logger.debug(f\"Loaded models for evaluation.\")\n",
    "    logger.debug(f\"Evaluating on test data. X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "    rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "    rf_r2 = r2_score(y_test, rf_predictions)\n",
    "    rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "\n",
    "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "    xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "    xgb_r2 = r2_score(y_test, xgb_predictions)\n",
    "    xgb_mse = mean_squared_error(y_test, xgb_predictions)\n",
    "\n",
    "    logger.info(f\"\\nRandom Forest RMSE: {rf_rmse}\")\n",
    "    logger.info(f\"Random Forest MAE: {rf_mae}\")\n",
    "    logger.info(f\"Random Forest R²: {rf_r2}\")\n",
    "    logger.info(f\"Random Forest MSE: {rf_mse}\")\n",
    "\n",
    "    logger.info(f\"\\nXGBoost RMSE: {xgb_rmse}\")\n",
    "    logger.info(f\"XGBoost MAE: {xgb_mae}\")\n",
    "    logger.info(f\"XGBoost R²: {xgb_r2}\")\n",
    "    logger.info(f\"XGBoost MSE: {xgb_mse}\")\n",
    "\n",
    "    eval_results = {\n",
    "        'rf_predictions': rf_predictions,\n",
    "        'xgb_predictions': xgb_predictions,\n",
    "        'rf_rmse': rf_rmse,\n",
    "        'rf_mae': rf_mae,\n",
    "        'rf_r2': rf_r2,\n",
    "        'rf_mse': rf_mse,\n",
    "        'xgb_rmse': xgb_rmse,\n",
    "        'xgb_mae': xgb_mae,\n",
    "        'xgb_r2': xgb_r2,\n",
    "        'xgb_mse': xgb_mse\n",
    "    }\n",
    "\n",
    "    eval_save_path = f\"{model_save_path}/evaluation_results.pkl\"\n",
    "    joblib.dump(eval_results, eval_save_path)\n",
    "    logger.info(f\"Evaluation results saved at {eval_save_path}\")\n",
    "    \n",
    "    return eval_results\n",
    "\n",
    "def load_and_preprocess_data(file_path, predict_season, model_save_path):\n",
    "    \"\"\"Load data, filter by seasons, and apply preprocessing pipeline.\"\"\"\n",
    "    logger.debug(f\"Loading data and preprocessing for season {predict_season}\")\n",
    "    \n",
    "    # Step 1: Preprocess the dataset\n",
    "    cleaned_data, engineered_data, pipeline_data, columns_to_re_add = preprocessed_datasets(file_path)\n",
    "    \n",
    "    # Step 2: Split data into train and test sets based on season\n",
    "    train_data, test_data = filter_seasons(pipeline_data, predict_season)\n",
    "\n",
    "    # Step 3: Separate features (X) and target (y)\n",
    "    X_train = train_data.drop('SalaryPct', axis=1)\n",
    "    y_train = train_data['SalaryPct']\n",
    "    X_test = test_data.drop('SalaryPct', axis=1)\n",
    "    y_test = test_data['SalaryPct']\n",
    "\n",
    "    # Step 4: Build and apply the pipeline\n",
    "    pipeline = build_pipeline()\n",
    "\n",
    "    X_train_transformed = pipeline.fit_transform(X_train)\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # Save the fitted pipeline\n",
    "    joblib.dump(pipeline, os.path.join(model_save_path, 'preprocessing_pipeline.pkl'))\n",
    "\n",
    "    # Save the columns to re-add later\n",
    "    joblib.dump(columns_to_re_add, os.path.join(model_save_path, 'columns_to_re_add.pkl'))\n",
    "\n",
    "    # Debug: Get feature names after transformation\n",
    "    feature_names = pipeline.get_feature_names_out()\n",
    "    logger.debug(f\"Transformed feature names: {feature_names}\")\n",
    "    logger.debug(f\"X_train_transformed shape: {X_train_transformed.shape}\")\n",
    "    logger.debug(f\"X_test_transformed shape: {X_test_transformed.shape}\")\n",
    "\n",
    "    logger.debug(f\"Data transformed successfully for training and testing.\")\n",
    "    \n",
    "    return X_train_transformed, X_test_transformed, y_train, y_test\n",
    "\n",
    "# Model Training Pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2022\n",
    "    model_save_path = f'../data/models/season_{predict_season}'\n",
    "\n",
    "    \n",
    "    logger.debug(f\"Starting the pipeline for season {predict_season} with file: {file_path}\")\n",
    "    \n",
    "    # Load and preprocess the data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path, predict_season, model_save_path)\n",
    "    \n",
    "    # Train and save models\n",
    "    train_and_save_models(X_train, y_train, model_save_path)\n",
    "    \n",
    "    # Evaluate models on the test set\n",
    "    evaluated_models = evaluate_models(X_test, y_test, model_save_path)\n",
    "    print(\"metrics = \", evaluated_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/model_predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/model_predictor.py\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np  # Add this import for numpy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "import logging\n",
    "\n",
    "# Add relative imports for functions and constants\n",
    "from .data_loader_preprocessor import preprocessed_datasets, filter_seasons, inverse_transform_injury_risk\n",
    "from .model_trainer import load_and_preprocess_data, train_and_save_models, evaluate_models  # Add this line\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "INJURY_RISK_MAP = {\n",
    "    'Low Risk': 1,\n",
    "    'Moderate Risk': 2,\n",
    "    'High Risk': 3\n",
    "}\n",
    "\n",
    "REVERSE_INJURY_RISK_MAP = {\n",
    "    1: 'Low Risk',\n",
    "    2: 'Moderate Risk',\n",
    "    3: 'High Risk'\n",
    "}\n",
    "\n",
    "# Define feature groups\n",
    "NUMERIC_FEATURES = ['Age', 'Years of Service', 'PER', 'TS%', 'ORB%', 'DRB%', 'TRB%', 'AST%', \n",
    "                    'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS', 'WS', 'WS/48', \n",
    "                    'PPG', 'APG', 'SPG', 'TPG', 'BPG', 'Availability', \n",
    "                    'Efficiency', 'Days_Injured_Percentage', 'ValueOverReplacement', 'ExperienceSquared']\n",
    "\n",
    "ONE_HOT_ENCODE_CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk', 'SalaryPct'] \n",
    "PIPELINE_LEAVE_ALONE_FEATURES = ['Season', 'Injury_Risk'] \n",
    "columns_to_add_back_later = ['Season', 'Salary_Cap_Inflated', 'Player', 'SalaryPct']  \n",
    "\n",
    "CATEGORICAL_FEATURES = ['Position', 'Team']\n",
    "PASSTHROUGH_FEATURES = ['Season', 'Injury_Risk']\n",
    "\n",
    "def load_models_and_pipeline(model_save_path, predict_season):\n",
    "    season_model_path = model_save_path\n",
    "    logger.debug(f\"Loading models and pipeline for season {predict_season} from {season_model_path}\")\n",
    "\n",
    "    rf_model = joblib.load(f\"{season_model_path}/best_rf_model.pkl\")\n",
    "    xgb_model = joblib.load(f\"{season_model_path}/best_xgb_model.pkl\")\n",
    "    pipeline = joblib.load(f\"{season_model_path}/preprocessing_pipeline.pkl\")\n",
    "    columns_to_re_add = joblib.load(f\"{season_model_path}/columns_to_re_add.pkl\")\n",
    "    feature_names = joblib.load(f\"{season_model_path}/feature_names.pkl\")\n",
    "    \n",
    "    return rf_model, xgb_model, pipeline, columns_to_re_add, feature_names\n",
    "\n",
    "def load_and_preprocess_test_data(file_path, predict_season, model_save_path):\n",
    "    logger.debug(\"Loading and preprocessing test data...\")\n",
    "    cleaned_data, engineered_data, pipeline_data, _ = preprocessed_datasets(file_path)\n",
    "\n",
    "    # Filter data for the prediction season\n",
    "    _, test_data = filter_seasons(pipeline_data, predict_season)\n",
    "\n",
    "    X_test = test_data.drop('SalaryPct', axis=1)\n",
    "    y_test = test_data['SalaryPct']\n",
    "\n",
    "    # Debugging the columns before transformation\n",
    "    logger.debug(f\"Test data shape before transformation: {X_test.shape}\")\n",
    "    logger.debug(f\"Test data columns before transformation: {X_test.columns.tolist()}\")\n",
    "\n",
    "    # Check unique values for Injury_Risk and Total_Days_Injured before transformation\n",
    "    logger.debug(f\"Unique values of 'Injury_Risk' before transformation: {X_test['Injury_Risk'].unique()}\")\n",
    "    logger.debug(f\"Unique values of 'Days_Injured_Percentage' before transformation: {test_data['Days_Injured_Percentage'].unique()}\")\n",
    "\n",
    "    rf_model, xgb_model, pipeline, columns_to_re_add, feature_names = load_models_and_pipeline(model_save_path, predict_season)\n",
    "\n",
    "    # Separate and log the numerical columns\n",
    "    X_test_numeric = X_test[NUMERIC_FEATURES]\n",
    "    logger.debug(f\"Numerical data before transformation (shape): {X_test_numeric.shape}\")\n",
    "    logger.debug(f\"Numerical data before transformation (columns): {X_test_numeric.columns.tolist()}\")\n",
    "    logger.debug(f\"Sample of numerical data: {X_test_numeric.head()}\")\n",
    "\n",
    "    # Transform the data\n",
    "    X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "    # Debugging the transformed numerical data\n",
    "    numeric_transformer = pipeline.named_transformers_['num']['scaler']\n",
    "    transformed_numeric = numeric_transformer.transform(X_test_numeric)\n",
    "    logger.debug(f\"Transformed numerical data shape: {transformed_numeric.shape}\")\n",
    "    logger.debug(f\"Sample of transformed numerical data: {transformed_numeric[:5]}\")\n",
    "\n",
    "    # Check passthrough Injury_Risk after transformation (since it's not transformed)\n",
    "    logger.debug(f\"Unique values of 'Injury_Risk' after transformation (passthrough): {X_test['Injury_Risk'].unique()}\")\n",
    "\n",
    "    # Check Total_Days_Injured after transformation (it should be included in the numeric transformations)\n",
    "    logger.debug(f\"Transformed 'Total_Days_Injured' values (numeric feature): {transformed_numeric[:, NUMERIC_FEATURES.index('Days_Injured_Percentage')][:5]}\")\n",
    "\n",
    "    # Debug the final transformed data shape\n",
    "    logger.debug(f\"Shape of transformed data: {X_test_transformed.shape}\")\n",
    "    \n",
    "    return X_test, X_test_transformed, y_test, columns_to_re_add, feature_names, pipeline\n",
    "\n",
    "def inverse_transform_and_add_context(rf_predictions, xgb_predictions, X_test, X_test_transformed, columns_to_re_add, feature_names, pipeline):\n",
    "    logger.debug(f\"Shape of rf_predictions: {rf_predictions.shape}\")\n",
    "\n",
    "    # Convert predictions to DataFrame\n",
    "    rf_predictions_df = pd.DataFrame(rf_predictions, columns=['Predicted_SalaryPct'], index=X_test.index)\n",
    "    xgb_predictions_df = pd.DataFrame(xgb_predictions, columns=['Predicted_SalaryPct'], index=X_test.index)\n",
    "\n",
    "    # Inverse transform numerical features\n",
    "    numeric_transformer = pipeline.named_transformers_['num']['scaler']\n",
    "    X_test_numeric = X_test[NUMERIC_FEATURES]\n",
    "    X_test_numeric_inverse = pd.DataFrame(\n",
    "        numeric_transformer.inverse_transform(X_test_transformed[:, :len(NUMERIC_FEATURES)]),\n",
    "        columns=NUMERIC_FEATURES,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # Inverse transform categorical features\n",
    "    categorical_transformer = pipeline.named_transformers_['cat']['onehot']\n",
    "    transformed_cat_indices = slice(len(NUMERIC_FEATURES), -len(PASSTHROUGH_FEATURES))  # Indices of categorical features\n",
    "    X_test_categorical_inverse = pd.DataFrame(\n",
    "        categorical_transformer.inverse_transform(X_test_transformed[:, transformed_cat_indices]),\n",
    "        columns=ONE_HOT_ENCODE_CATEGORICAL_FEATURES,\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # Handle passthrough features (Season, Injury_Risk) directly\n",
    "    X_test_passthrough = X_test[PASSTHROUGH_FEATURES]\n",
    "\n",
    "    # Concatenate inverse-transformed numeric, categorical, and passthrough columns\n",
    "    X_test_inverse_transformed = pd.concat([X_test_numeric_inverse, X_test_categorical_inverse, X_test_passthrough], axis=1)\n",
    "\n",
    "    # Re-add the context columns (e.g., Salary_Cap_Inflated, Total_Days_Injured)\n",
    "    context_columns_df = pd.DataFrame(columns_to_re_add, index=X_test.index)\n",
    "\n",
    "    # Inverse transform the Injury_Risk column back to original categories\n",
    "    X_test_inverse_transformed = inverse_transform_injury_risk(X_test_inverse_transformed)\n",
    "\n",
    "    # Final prediction DataFrames\n",
    "    final_rf_df = pd.concat([X_test_inverse_transformed, context_columns_df, rf_predictions_df], axis=1)\n",
    "    final_xgb_df = pd.concat([X_test_inverse_transformed, context_columns_df, xgb_predictions_df], axis=1)\n",
    "\n",
    "    # Add Predicted_Salary column (in millions) by multiplying Predicted_SalaryPct with Salary_Cap_Inflated\n",
    "    final_rf_df['Predicted_Salary'] = (final_rf_df['Predicted_SalaryPct'] * final_rf_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "    final_xgb_df['Predicted_Salary'] = (final_xgb_df['Predicted_SalaryPct'] * final_xgb_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "\n",
    "    # Add Predicted_Salary column (in millions) by multiplying Predicted_SalaryPct with Salary_Cap_Inflated\n",
    "    final_rf_df['Salary'] = (final_rf_df['SalaryPct'] * final_rf_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "    final_xgb_df['Salary'] = (final_xgb_df['SalaryPct'] * final_xgb_df['Salary_Cap_Inflated'] / 1_000_000).round(2)\n",
    "\n",
    "    \n",
    "    return final_rf_df, final_xgb_df\n",
    "\n",
    "\n",
    "def save_predictions(final_rf_df, final_xgb_df, model_save_path):\n",
    "    rf_save_path = f\"{model_save_path}/rf_predictions.csv\"\n",
    "    xgb_save_path = f\"{model_save_path}/xgb_predictions.csv\"\n",
    "\n",
    "    final_rf_df.to_csv(rf_save_path, index=False)\n",
    "    final_xgb_df.to_csv(xgb_save_path, index=False)\n",
    "\n",
    "    logger.info(f\"Predictions saved to {rf_save_path} and {xgb_save_path}\")\n",
    "\n",
    "\n",
    "# Main function to run the prediction pipeline\n",
    "def make_predictions(file_path, predict_season, model_save_path):\n",
    "    logger.debug(\"Starting prediction pipeline...\")\n",
    "\n",
    "    # Step 1: Load and preprocess test data\n",
    "    X_test, X_test_transformed, y_test, columns_to_re_add, feature_names, pipeline = load_and_preprocess_test_data(file_path, predict_season, model_save_path)\n",
    "\n",
    "    logger.debug(f\"Shape of X_test_transformed before predictions: {X_test_transformed.shape}\")\n",
    "\n",
    "    # Step 2: Load models\n",
    "    rf_model, xgb_model, _, _, _ = load_models_and_pipeline(model_save_path, predict_season)\n",
    "\n",
    "    # Step 3: Make predictions\n",
    "    rf_predictions = rf_model.predict(X_test_transformed)\n",
    "    xgb_predictions = xgb_model.predict(X_test_transformed)\n",
    "\n",
    "    logger.debug(f\"RF Predictions: {rf_predictions[:5]}\")\n",
    "    logger.debug(f\"XGB Predictions: {xgb_predictions[:5]}\")\n",
    "\n",
    "    # Step 4: Inverse transform and add context\n",
    "    final_rf_df, final_xgb_df = inverse_transform_and_add_context(rf_predictions, xgb_predictions, X_test, X_test_transformed, columns_to_re_add, feature_names, pipeline)\n",
    "\n",
    "    # Drop one of the duplicate 'Season' columns\n",
    "    if 'Season' in final_rf_df.columns:\n",
    "        final_rf_df = final_rf_df.loc[:, ~final_rf_df.columns.duplicated()]\n",
    "    \n",
    "    if 'Season' in final_xgb_df.columns:\n",
    "        final_xgb_df = final_xgb_df.loc[:, ~final_xgb_df.columns.duplicated()]\n",
    "\n",
    "    # Step 5: Save predictions\n",
    "    save_predictions(final_rf_df, final_xgb_df, model_save_path)\n",
    "\n",
    "    return final_rf_df, final_xgb_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    predict_season = 2022\n",
    "    model_save_path = f'../data/models/season_{predict_season}'\n",
    "\n",
    "    rf_final_df, xgb_final_df = make_predictions(file_path, predict_season, model_save_path)\n",
    "    print(rf_final_df)\n",
    "    print(rf_final_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/salary_model_training/util_functions.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/salary_model_training/util_functions.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from .model_trainer import load_and_preprocess_data, train_and_save_models, evaluate_models  # Add this line\n",
    "from .model_predictor import make_predictions\n",
    "\n",
    "\n",
    "CATEGORICAL_FEATURES = ['Position_', 'Team_']\n",
    "\n",
    "def load_evaluation_metrics(model_save_path):\n",
    "    \"\"\"Load saved evaluation metrics.\"\"\"\n",
    "    eval_save_path = f\"{model_save_path}/evaluation_results.pkl\"\n",
    "    if os.path.exists(eval_save_path):\n",
    "        eval_results = joblib.load(eval_save_path)\n",
    "        return eval_results\n",
    "    else:\n",
    "        print(\"Evaluation results not found.\")\n",
    "        return None\n",
    "\n",
    "def check_or_train_model(file_path, model_save_path, season_year):\n",
    "    \"\"\"Check for predictions, train the models if predictions are not found, and return predictions.\"\"\"\n",
    "    predictions_file_path = f'{model_save_path}/rf_predictions.csv'\n",
    "    \n",
    "    if os.path.exists(predictions_file_path):\n",
    "        print(f\"Predictions file found for {season_year}.\")\n",
    "        predictions_df = pd.read_csv(predictions_file_path)\n",
    "    else:\n",
    "        print(f\"Predictions not available for {season_year}. Training the model now...\")\n",
    "\n",
    "        # Train and predict\n",
    "        X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path, season_year, model_save_path)\n",
    "        train_and_save_models(X_train, y_train, model_save_path)\n",
    "        evaluate_models(X_test, y_test, model_save_path)\n",
    "\n",
    "        # Generate predictions\n",
    "        rf_final_df, xgb_final_df = make_predictions(file_path, season_year, model_save_path)\n",
    "        predictions_df = pd.concat([rf_final_df, xgb_final_df], axis=1)\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "def display_model_metrics(model_save_path):\n",
    "    \"\"\"Display saved model performance metrics for both Random Forest and XGBoost.\"\"\"\n",
    "    eval_results = load_evaluation_metrics(model_save_path)\n",
    "\n",
    "    if eval_results:\n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(f\"Random Forest RMSE: {eval_results['rf_rmse']:.4f}\")\n",
    "        print(f\"Random Forest MAE: {eval_results['rf_mae']:.4f}\")\n",
    "        print(f\"Random Forest R²: {eval_results['rf_r2']:.4f}\")\n",
    "        print(f\"Random Forest MSE: {eval_results['rf_mse']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nXGBoost RMSE: {eval_results['xgb_rmse']:.4f}\")\n",
    "        print(f\"XGBoost MAE: {eval_results['xgb_mae']:.4f}\")\n",
    "        print(f\"XGBoost R²: {eval_results['xgb_r2']:.4f}\")\n",
    "        print(f\"XGBoost MSE: {eval_results['xgb_mse']:.4f}\")\n",
    "    else:\n",
    "        print(\"No evaluation metrics found.\")\n",
    "\n",
    "def filter_categorical_features(importance_df, categorical_features):\n",
    "    \"\"\"Filter out categorical features from the importance dataframe.\"\"\"\n",
    "    filtered_df = importance_df[~importance_df['Feature'].str.startswith(tuple(categorical_features))]\n",
    "    return filtered_df\n",
    "\n",
    "def display_feature_importance(model, feature_names, categorical_features):\n",
    "    \"\"\"Displays feature importance for the selected model, filtering out categorical features.\"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        n_features = len(model.feature_importances_)\n",
    "        print(f\"Number of features in model: {n_features}\")\n",
    "        \n",
    "        # Create the DataFrame of feature importances\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names[:n_features],  # Adjust if feature names mismatch\n",
    "            'Importance': model.feature_importances_\n",
    "        }).sort_values(by=\"Importance\", ascending=False)\n",
    "        \n",
    "        # Filter out categorical features\n",
    "        filtered_importance_df = filter_categorical_features(importance_df, categorical_features)\n",
    "        return filtered_importance_df\n",
    "    else:\n",
    "        print(\"This model does not support feature importance visualization.\")\n",
    "        return None\n",
    "\n",
    "def plot_feature_importance(feature_importances_df, model_name):\n",
    "    \"\"\"Function to plot the feature importance as a bar chart.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances_df['Feature'], feature_importances_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(f'{model_name} Feature Importance')\n",
    "    plt.gca().invert_yaxis()  # Most important feature at the top\n",
    "    return plt\n",
    "\n",
    "def identify_overpaid_underpaid(predictions_df, top_n=10):\n",
    "    \"\"\"Identify overpaid and underpaid players based on salary differences.\"\"\"\n",
    "    predictions_df['Salary_Difference'] = predictions_df['Salary'] - predictions_df['Predicted_Salary']\n",
    "    \n",
    "    overpaid = predictions_df[predictions_df['Salary_Difference'] > 0].sort_values('Salary_Difference', ascending=False).head(top_n)\n",
    "    underpaid = predictions_df[predictions_df['Salary_Difference'] < 0].sort_values('Salary_Difference').head(top_n)\n",
    "    \n",
    "    return overpaid, underpaid\n",
    "\n",
    "def display_overpaid_underpaid(predictions_df, top_n=10):\n",
    "    \"\"\"Display top overpaid and underpaid players.\"\"\"\n",
    "    overpaid, underpaid = identify_overpaid_underpaid(predictions_df, top_n)\n",
    "\n",
    "    print(f\"\\nTop {top_n} Overpaid Players:\")\n",
    "    print(overpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "    print(f\"\\nTop {top_n} Underpaid Players:\")\n",
    "    print(underpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "def main_test_function():\n",
    "    \"\"\"Main function to test all utility functions.\"\"\"\n",
    "    file_path = '../data/processed/nba_player_data_final_inflated.csv'\n",
    "    season_year = '2023'\n",
    "    model_save_path = f'../data/models/season_{season_year}'\n",
    "\n",
    "    # Test check_or_train_model\n",
    "    predictions_df = check_or_train_model(file_path, model_save_path, season_year)\n",
    "    print(\"\\nPredictions DataFrame:\")\n",
    "    print(predictions_df.head())\n",
    "\n",
    "    # Test display_model_metrics\n",
    "    display_model_metrics(model_save_path)\n",
    "\n",
    "    # Load a model for testing feature importance\n",
    "    rf_model_path = f'{model_save_path}/best_rf_model.pkl'\n",
    "    rf_model = joblib.load(rf_model_path)\n",
    "    feature_names_path = f'{model_save_path}/feature_names.pkl'\n",
    "    feature_names = joblib.load(feature_names_path)\n",
    "\n",
    "    # Test display_feature_importance with filtering categorical features\n",
    "    feature_importances_df = display_feature_importance(rf_model, feature_names, CATEGORICAL_FEATURES)\n",
    "    \n",
    "    # Test plot_feature_importance\n",
    "    plot = plot_feature_importance(feature_importances_df, \"Random Forest\")\n",
    "    plot.show()\n",
    "\n",
    "    # Test display_overpaid_underpaid\n",
    "    display_overpaid_underpaid(predictions_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_test_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/app.py\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from nba_api.stats.static import teams, players\n",
    "\n",
    "#importing model utils\n",
    "from salary_model_training.data_loader_preprocessor import format_season\n",
    "from salary_model_training.util_functions import check_or_train_model, display_feature_importance, display_model_metrics, identify_overpaid_underpaid, plot_feature_importance\n",
    "# Importing Shot Chart Analysis functions\n",
    "from shot_chart.nba_helpers import get_team_abbreviation, categorize_shot, get_all_court_areas\n",
    "from shot_chart.nba_shots import fetch_shots_data, fetch_defensive_shots_data, fetch_shots_for_multiple_players\n",
    "from shot_chart.nba_plotting import plot_shot_chart_hexbin\n",
    "from shot_chart.nba_efficiency import create_mae_table, save_mae_table, load_mae_table, get_seasons_range, calculate_compatibility_between_players\n",
    "from shot_chart.shot_chart_main import run_scenario, preload_mae_tables, create_and_save_mae_table_specific, create_and_save_mae_table_all\n",
    "\n",
    "# Import functions from the small example app\n",
    "from advanced_metrics import plot_career_clusters, plot_injury_risk_vs_salary, plot_availability_vs_salary, plot_vorp_vs_salary, table_metric_salary, display_top_10_salary_per_metric, cluster_players_specialized, display_top_10_salary_per_metric_with_ws\n",
    "\n",
    "# Import New and improved Trade functions\n",
    "from trade_impact_section_st_app import trade_impact_simulator_app\n",
    "\n",
    "@st.cache_data\n",
    "def get_teams_list():\n",
    "    \"\"\"Get the list of NBA teams.\"\"\"\n",
    "    return [team['full_name'] for team in teams.get_teams()]\n",
    "\n",
    "@st.cache_data\n",
    "def get_players_list():\n",
    "    \"\"\"Get the list of NBA players.\"\"\"\n",
    "    return [player['full_name'] for player in players.get_players()]\n",
    "\n",
    "@st.cache_data\n",
    "def load_team_data():\n",
    "    nba_teams = teams.get_teams()\n",
    "    team_df = pd.DataFrame(nba_teams)\n",
    "    return team_df[['id', 'full_name', 'abbreviation']]\n",
    "\n",
    "@st.cache_data\n",
    "def load_player_data(start_year, end_year):\n",
    "    player_data = pd.DataFrame()\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        data = fetch_season_data_by_year(year)\n",
    "        if data is not None:\n",
    "            player_data = pd.concat([player_data, data], ignore_index=True)\n",
    "    return player_data\n",
    "\n",
    "# Advanced Metrics Analysis Function\n",
    "def advanced_metrics_analysis():\n",
    "    st.header(\"NBA Advanced Metrics and Salary Analysis\")\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_csv('data/processed/nba_player_data_final_inflated.csv')\n",
    "    \n",
    "    # Add a dropdown to select the season\n",
    "    seasons = sorted(data['Season'].unique(), reverse=True)\n",
    "    selected_season = st.selectbox(\"Select a Season\", seasons)\n",
    "    \n",
    "    # Filter the data by the selected season\n",
    "    data_season = data[data['Season'] == selected_season]\n",
    "    \n",
    "    # Cluster players based on the filtered data\n",
    "    data_season = cluster_players_specialized(data_season, n_clusters=7)\n",
    "    \n",
    "    st.header(\"Plots\")\n",
    "    \n",
    "    # Dropdown to select the plot\n",
    "    plot_choice = st.selectbox(\"Select a plot to view:\", \n",
    "                               [\"Career Clusters: Age vs Salary\", \n",
    "                                \"Injury Risk vs Salary\", \n",
    "                                \"Availability vs Salary\", \n",
    "                                \"VORP vs Salary\"])\n",
    "    \n",
    "    if plot_choice == \"Career Clusters: Age vs Salary\":\n",
    "        fig = plot_career_clusters(data_season)\n",
    "        st.pyplot(fig)\n",
    "    elif plot_choice == \"Injury Risk vs Salary\":\n",
    "        fig = plot_injury_risk_vs_salary(data_season)\n",
    "        st.pyplot(fig)\n",
    "    elif plot_choice == \"Availability vs Salary\":\n",
    "        fig = plot_availability_vs_salary(data_season)\n",
    "        st.pyplot(fig)\n",
    "    elif plot_choice == \"VORP vs Salary\":\n",
    "        fig = plot_vorp_vs_salary(data_season)\n",
    "        st.pyplot(fig)\n",
    "    \n",
    "    st.header(\"Top 10 Salary per Metric Tables\")\n",
    "    \n",
    "    # Calculate metrics table\n",
    "    metric_salary_table = table_metric_salary(data_season)\n",
    "    \n",
    "    # Dropdown to select the metric table\n",
    "    metric_choice = st.selectbox(\"Select a metric to view top 10:\", \n",
    "                                 [\"Salary_per_WS\", \n",
    "                                  \"Salary_per_VORP\", \n",
    "                                  \"Salary_per_OWS\", \n",
    "                                  \"Salary_per_DWS\"])\n",
    "    \n",
    "    # Display the selected top 10 table with WS included\n",
    "    top_10_table = display_top_10_salary_per_metric_with_ws(metric_salary_table, metric_choice)\n",
    "    st.write(f\"Top 10 {metric_choice}:\")\n",
    "    st.dataframe(top_10_table)\n",
    "\n",
    "# Shot Chart Analysis function\n",
    "def shot_chart_analysis():\n",
    "    st.header(\"Shot Chart Analysis\")\n",
    "\n",
    "    # Add guidelines and purpose explanation at the top\n",
    "    st.markdown(\"\"\"\n",
    "    ### Welcome to the NBA Shot Analysis App!\n",
    "    \n",
    "    This app allows you to analyze the offensive and defensive efficiency of NBA teams and players. \n",
    "    You can compare players or teams to identify the most efficient spots on the court, \n",
    "    analyze player compatibility based on shot area efficiency, and much more.\n",
    "    \n",
    "    **Options and Guidelines:**\n",
    "    - **Analysis Type**: Choose between offensive, defensive, or both types of analysis.\n",
    "    - **Team or Player**: Analyze a team or an individual player.\n",
    "    - **Court Areas**: Select specific court areas or analyze all areas.\n",
    "    - **Comparison**: Compare multiple players to see how their offensive efficiencies align or differ.\n",
    "    \"\"\")\n",
    "\n",
    "    analysis_type = st.selectbox(\"Select analysis type\", options=[\"offensive\", \"defensive\", \"both\"])\n",
    "\n",
    "    entity_type = st.selectbox(\"Analyze a Team or Player?\", options=[\"team\", \"player\"])\n",
    "\n",
    "    if entity_type == \"team\":\n",
    "        st.markdown(\"_**Team option is able to analyze both offense and defense by looking into the defense by shot detail from other teams' shot charts against the Opposing Team.**_\")\n",
    "        entity_name = st.selectbox(\"Select a Team\", options=get_teams_list())\n",
    "    else:\n",
    "        st.markdown(\"_**Player Option is only able to look at offense.**_\")\n",
    "        player_names = st.multiselect(\"Select Players to Analyze\", options=get_players_list())\n",
    "\n",
    "    season = st.selectbox(\"Select the season\", options=[\"2023-24\", \"2022-23\", \"2021-22\", \"2020-21\"])\n",
    "\n",
    "    opponent_type = st.selectbox(\"Compare against all teams or a specific team?\", options=[\"all\", \"specific\"])\n",
    "\n",
    "    opponent_name = None\n",
    "    if opponent_type == \"specific\":\n",
    "        opponent_name = st.selectbox(\"Select an Opponent Team\", options=get_teams_list())\n",
    "\n",
    "    court_areas = st.selectbox(\"Select court areas to analyze\", options=[\"all\", \"specific\"], index=0)\n",
    "\n",
    "    if court_areas == \"specific\":\n",
    "        court_areas = st.multiselect(\"Select specific court areas\", options=get_all_court_areas())\n",
    "    else:\n",
    "        court_areas = \"all\"\n",
    "\n",
    "    debug_mode = st.checkbox(\"Enable Debug Mode\", value=False)\n",
    "\n",
    "    if st.button(\"Run Analysis\"):\n",
    "        if entity_type == \"player\" and (not player_names or len(player_names) < 1):\n",
    "            st.error(\"Please select at least one player.\")\n",
    "        else:\n",
    "            if entity_type == \"player\":\n",
    "                if len(player_names) == 1:\n",
    "                    # Single player analysis\n",
    "                    run_scenario(\n",
    "                        entity_name=player_names[0],\n",
    "                        entity_type=entity_type,\n",
    "                        season=season,\n",
    "                        opponent_name=opponent_name,\n",
    "                        analysis_type=analysis_type,\n",
    "                        compare_players=False,\n",
    "                        player_names=None,\n",
    "                        court_areas=court_areas\n",
    "                    )\n",
    "                else:\n",
    "                    # Multiple players comparison\n",
    "                    player_shots = fetch_shots_for_multiple_players(player_names, season, court_areas, opponent_name, debug=debug_mode)\n",
    "\n",
    "                    for player, shots in player_shots.items():\n",
    "                        st.pyplot(plot_shot_chart_hexbin(shots['shots'], f'{player} Shot Chart', opponent=opponent_name if opponent_name else \"all teams\"))\n",
    "                        st.write(f\"Efficiency for {player}:\")\n",
    "                        st.write(shots['efficiency'])\n",
    "\n",
    "                    compatibility_df = calculate_compatibility_between_players(player_shots)\n",
    "                    st.write(\"Player Shooting Area Compatibility:\")\n",
    "                    st.write(compatibility_df)\n",
    "            else:\n",
    "                # Team analysis\n",
    "                run_scenario(\n",
    "                    entity_name=entity_name,\n",
    "                    entity_type=entity_type,\n",
    "                    season=season,\n",
    "                    opponent_name=opponent_name,\n",
    "                    analysis_type=analysis_type,\n",
    "                    compare_players=False,\n",
    "                    court_areas=court_areas\n",
    "                )\n",
    "\n",
    "    # Add explanation for shot chart MAE analysis\n",
    "    with st.expander(\"Understanding MAE in Player Analysis with context from their Shooting\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **MAE** is a metric that measures the average magnitude of errors between predicted values and actual values, without considering their direction.\n",
    "        \n",
    "        In our context, MAE is used to measure the difference between the shooting efficiencies of two players across various areas on the court.\n",
    "        \n",
    "        **Steps to Analyze MAE:**\n",
    "        1. **Define Common Areas**: The court is divided into areas like \"Left Corner 3\", \"Top of Key\", \"Paint\", etc.\n",
    "        2. **Calculate Individual Efficiencies**: Fetch shot data for each player and calculate their shooting efficiency in these areas.\n",
    "        3. **Identify Common Areas**: When comparing players, identify the areas where both players have taken shots.\n",
    "        4. **Calculate MAE**: Compute the absolute difference between efficiencies in each common area and average them.\n",
    "        5. **Interpret Compatibility**:\n",
    "            - **High MAE**: Indicates players excel in different areas (more compatible).\n",
    "            - **Low MAE**: Indicates similar efficiencies in the same areas (less compatible).\n",
    "        \n",
    "        **Use this metric to assess player compatibility based on where they excel on the court!**\n",
    "        \"\"\")\n",
    "\n",
    "    with st.expander(\"Understanding MAE in Team (offensive or defensive) in comparison to other Teams\"):\n",
    "        st.markdown(\"\"\"\n",
    "        **MAE** is a metric that measures the average magnitude of errors between predicted values and actual values, without considering their direction.\n",
    "        \n",
    "        In the context of team analysis, MAE is used to measure the difference between the shooting efficiencies of one team's offense and the defensive efficiencies of other teams.\n",
    "        \n",
    "        **Steps to Analyze MAE for Team Comparison:**\n",
    "        1. **Calculate Offensive Efficiency**: Fetch shot data for the team of interest and calculate their shooting efficiency across various areas on the court.\n",
    "        2. **Calculate Defensive Efficiency of Opponents**: For each opponent team, calculate their defensive efficiency by analyzing how well they defend these same areas on the court.\n",
    "        3. **Calculate MAE**: Compute the MAE between the offensive efficiency of the team of interest and the defensive efficiencies of each opponent team across the defined court areas.\n",
    "        4. **Interpret the Results**:\n",
    "            - **Low MAE**: Indicates that the opponent team is effective at defending the areas where the team of interest typically excels. This suggests that the opponent is a \"bad fit\" for the team of interest, as they defend well against their strengths.\n",
    "            - **High MAE**: Indicates that the opponent team struggles to defend the areas where the team of interest typically excels. This suggests that the opponent is a \"good fit\" for the team of interest, as their defense is less effective against the team's offensive strengths.\n",
    "        \n",
    "        **Use this analysis to identify which teams are tough matchups (bad fits) versus easier matchups (good fits) based on how well they can defend your team's key offensive areas!**\n",
    "        \"\"\")\n",
    "\n",
    "def convert_season_format(season_str):\n",
    "    try:\n",
    "        # Ensure we are splitting the season string correctly\n",
    "        if isinstance(season_str, str):\n",
    "            print(f\"Original season string: {season_str}\")  # Debug: Print original season string\n",
    "\n",
    "            # Split the season by '-' (e.g., '2023-24' -> ['2023', '24'])\n",
    "            year = season_str.split('-')[0]  # Get '2023'\n",
    "\n",
    "            print(f\"Formatted season string (year only): {year}\")  # Debug: Print year only\n",
    "\n",
    "            return year  # Return only the starting year\n",
    "        else:\n",
    "            raise TypeError(f\"Expected a string, but got {type(season_str)}\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        return season_str  # Fallback to original season if there's an issue\n",
    "    except Exception as e:\n",
    "        print(f\"Error formatting season: {e}\")\n",
    "        raise\n",
    "\n",
    "def plot_correlation_heatmap(data):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    corr = numeric_data.corr()\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', ax=ax)\n",
    "    ax.set_title('Correlation Heatmap')\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Main app logic\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"NBA Salary Prediction, Analysis, and Simulator\", layout=\"wide\")\n",
    "    st.title(\"NBA Salary Prediction, Data Analysis, and Trade Impact Simulator\")\n",
    "\n",
    "    # Load the data\n",
    "    file_path = 'data/processed/nba_player_data_final_inflated.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Get the unique seasons and exclude the earliest one\n",
    "    seasons = sorted(data['Season'].unique(), reverse=True)  # Sort in descending order\n",
    "    if len(seasons) > 1:\n",
    "        seasons = seasons[:-1]  # Remove the earliest season (the last element in the sorted list)\n",
    "\n",
    "    # Sidebar Navigation\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\"Go to\", [\n",
    "        \"Introduction\", \n",
    "        \"Data Analysis\", \n",
    "        \"Model Results\", \n",
    "        \"Salary Evaluation\", \n",
    "        \"Shot Chart Analysis\", \n",
    "        \"Advanced Metrics Analysis\", \n",
    "        \"Trade Impact Simulator\"\n",
    "    ])\n",
    "\n",
    "    # Season Selection (without the earliest season)\n",
    "    selected_season = st.selectbox(\"Select Season\", seasons)\n",
    "    season_year = selected_season.split('-')[0]\n",
    "\n",
    "    # File Paths\n",
    "    model_save_path = f'data/models/season_{season_year}'\n",
    "\n",
    "    # Load or train model and get predictions\n",
    "    predictions_df = check_or_train_model(file_path, model_save_path, season_year)\n",
    "\n",
    "    # Load models (to be reused across pages)\n",
    "    rf_model_path = f'{model_save_path}/best_rf_model.pkl'\n",
    "    xgb_model_path = f'{model_save_path}/best_xgb_model.pkl'\n",
    "\n",
    "    try:\n",
    "        rf_model = joblib.load(rf_model_path)\n",
    "        xgb_model = joblib.load(xgb_model_path)\n",
    "        feature_names = joblib.load(f'{model_save_path}/feature_names.pkl')\n",
    "    except FileNotFoundError:\n",
    "        st.error(\"Models or feature names not found for the selected season. Please ensure the models are trained.\")\n",
    "        return\n",
    "\n",
    "    if page == \"Introduction\":\n",
    "        st.title(\"Enhanced NBA Player Salary Analysis\")\n",
    "        st.write(\"Welcome to the NBA Salary Analysis and Prediction App! This project aims to provide comprehensive insights into NBA player salaries, advanced metrics, and future salary predictions based on historical data. Here's a detailed breakdown of the steps involved in creating this app:\")\n",
    "\n",
    "        st.subheader(\"Data Collection\")\n",
    "        \n",
    "        st.write(\"### Salary Data\")\n",
    "        st.write(\"- **Sources**:\")\n",
    "        st.write(\"  - [Basketball Reference Salary Cap History](https://www.basketball-reference.com/contracts/salary-cap-history.html)\")\n",
    "        st.write(\"- **Description**: Data on the NBA salary cap from various seasons, along with maximum salary details for players based on years of service.\")\n",
    "\n",
    "        st.write(\"### Add Injury Data (source will need to be updated**):\")\n",
    "        st.write(\"- **Source**: [Kaggle NBA Injury Stats 1951-2023](https://www.kaggle.com/datasets/loganlauton/nba-injury-stats-1951-2023/data)\")\n",
    "        st.write(\"- **Description**: This dataset provides detailed statistics on NBA injuries from 1951 to 2023, allowing for analysis of player availability and its impact on performance and salaries.\")\n",
    "\n",
    "        st.write(\"### Advanced Metrics\")\n",
    "        st.write(\"- **Source**: [Basketball Reference](https://www.basketball-reference.com)\")\n",
    "        st.write(\"- **Description**: Advanced player metrics such as Player Efficiency Rating (PER), True Shooting Percentage (TS%), and Value Over Replacement Player (VORP) were scraped using BeautifulSoup.\")\n",
    "\n",
    "        st.write(\"### Player Salaries and Team Data\")\n",
    "        st.write(\"- **Source**: [Hoopshype](https://hoopshype.com)\")\n",
    "        st.write(\"- **Description**: Player salary data was scraped for multiple seasons, with detailed information on individual player earnings and team salaries.\")\n",
    "\n",
    "        st.subheader(\"Data Processing\")\n",
    "\n",
    "        st.write(\"### Inflation Adjustment\")\n",
    "        st.write(\"- **Source**: [Adjusting for Inflation in Python](https://medium.com/analytics-vidhya/adjusting-for-inflation-when-analysing-historical-data-with-python-9d69a8dcbc27)\")\n",
    "        st.write(\"- **Description**: Adjusted historical salary data for inflation to provide a consistent basis for comparison.\")\n",
    "\n",
    "        st.write(\"### Data Aggregation\")\n",
    "        st.write(\"- Steps:\")\n",
    "        st.write(\"  1. Loaded salary data and combined it with team standings and advanced metrics.\")\n",
    "        st.write(\"  2. Merged multiple data sources to create a comprehensive dataset containing player performance, salaries, and advanced metrics.\")\n",
    "\n",
    "        st.subheader(\"Model Training and Prediction\")\n",
    "\n",
    "        st.write(\"### Data Preprocessing\")\n",
    "        st.write(\"- Implemented functions to handle missing values, perform feature engineering, and calculate key metrics such as points per game (PPG), assists per game (APG), and salary growth.\")\n",
    "\n",
    "        st.write(\"### Model Selection\")\n",
    "        st.write(\"- Utilized various machine learning models including Random Forest, Gradient Boosting, Ridge Regression, and others to predict future player salaries.\")\n",
    "        st.write(\"- Employed grid search for hyperparameter tuning and selected the best-performing models based on evaluation metrics like Mean Squared Error (MSE) and R² score.\")\n",
    "\n",
    "        st.write(\"### Feature Importance and Clustering\")\n",
    "        st.write(\"- Analyzed feature importance to understand the key factors influencing player salaries.\")\n",
    "        st.write(\"- Clustered players into categories based on career trajectories, providing insights into player development and value.\")\n",
    "\n",
    "        st.subheader(\"App Development\")\n",
    "\n",
    "        st.write(\"### Streamlit App\")\n",
    "        st.write(\"- Built an interactive app using Streamlit to visualize data, perform exploratory data analysis, and make salary predictions.\")\n",
    "        st.write(\"- **Features**:\")\n",
    "        st.write(\"  - **Data Overview**: Display raw and processed data.\")\n",
    "        st.write(\"  - **Exploratory Data Analysis**: Visualize salary distributions, age vs. salary, and other key metrics.\")\n",
    "        st.write(\"  - **Advanced Analytics**: Analyze VORP to salary ratio, career trajectory clusters, and other advanced metrics.\")\n",
    "        st.write(\"  - **Salary Predictions**: Predict future salaries and compare actual vs. predicted values.\")\n",
    "        st.write(\"  - **Player Comparisons**: Compare selected players based on predicted salaries and performance metrics.\")\n",
    "        st.write(\"  - **Model Evaluation**: Evaluate different models and display their performance metrics and feature importance.\")\n",
    "\n",
    "        st.write(\"### Data Files\")\n",
    "        st.write(\"- Stored processed data and model files in a structured format to facilitate easy loading and analysis within the app.\")\n",
    "\n",
    "        st.subheader(\"Improvements:\")\n",
    "        \n",
    "        st.subheader(\"Conclusion\")\n",
    "\n",
    "        st.write(\"This app provides a robust platform for analyzing NBA player salaries, understanding the factors influencing earnings, and predicting future salaries based on historical data and advanced metrics. Explore the app to gain insights into player performance, salary trends, and much more.\")\n",
    "        st.subheader(\"Original Data\")\n",
    "        original_df = pd.read_csv(file_path)\n",
    "        st.dataframe(original_df)\n",
    "\n",
    "        st.subheader(\"Predicted Data\")\n",
    "        st.write(\"Here are the salary predictions generated based on Random Forest and XGBoost models.\")\n",
    "        st.dataframe(predictions_df)\n",
    "\n",
    "    elif page == \"Data Analysis\":\n",
    "        st.header(\"Data Analysis\")\n",
    "        st.write(\"Analyze the player and team statistics in detail for each season.\")\n",
    "        # Debugging the data loading\n",
    "        st.write(\"Debugging: Verifying data columns before processing...\")\n",
    "        original_df = pd.read_csv(file_path)\n",
    "        st.write(\"Data columns:\", original_df.columns.tolist())\n",
    "        st.write(\"Basic Statistics for Selected Season\")\n",
    "        st.write(original_df.describe())\n",
    "\n",
    "\n",
    "    elif page == \"Model Results\":\n",
    "        st.header(\"Model Results\")\n",
    "        model_choice = st.selectbox(\"Select Model\", [\"Random Forest\", \"XGBoost\"])\n",
    "        st.subheader(f\"{model_choice} Model Results\")\n",
    "        display_model_metrics(model_save_path)\n",
    "        \n",
    "        # Feature importance\n",
    "        if model_choice == \"Random Forest\":\n",
    "            st.subheader(\"Random Forest Feature Importance\")\n",
    "            feature_importances_df = display_feature_importance(rf_model, feature_names, ['Position_', 'Team_'])\n",
    "        else:\n",
    "            st.subheader(\"XGBoost Feature Importance\")\n",
    "            feature_importances_df = display_feature_importance(xgb_model, feature_names, ['Position_', 'Team_'])\n",
    "\n",
    "        # Display the filtered feature importance dataframe\n",
    "        st.dataframe(feature_importances_df)\n",
    "        # Plot and display the feature importance bar chart\n",
    "        fig = plot_feature_importance(feature_importances_df, model_choice)\n",
    "        st.pyplot(fig)\n",
    "\n",
    "    elif page == \"Salary Evaluation\":\n",
    "        st.header(\"Salary Evaluation\")\n",
    "        num_players = st.slider(\"Select number of players to display\", min_value=5, max_value=20, value=10)\n",
    "        overpaid, underpaid = identify_overpaid_underpaid(predictions_df, top_n=num_players)\n",
    "        st.subheader(f\"Top {num_players} Overpaid Players\")\n",
    "        st.dataframe(overpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "        st.subheader(f\"Top {num_players} Underpaid Players\")\n",
    "        st.dataframe(underpaid[['Player', 'Team', 'Salary', 'Predicted_Salary', 'Salary_Difference']])\n",
    "\n",
    "\n",
    "    elif page == \"Shot Chart Analysis\":\n",
    "        shot_chart_analysis()\n",
    "\n",
    "    elif page == \"Advanced Metrics Analysis\":\n",
    "        advanced_metrics_analysis()\n",
    "\n",
    "    elif page == \"Trade Impact Simulator\":\n",
    "        st.header(\"Trade Impact Simulator\")\n",
    "        formatted_season = convert_season_format(selected_season)\n",
    "        trade_impact_simulator_app(formatted_season) #2023 or XXXX format is needed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
